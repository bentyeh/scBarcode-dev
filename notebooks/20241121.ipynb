{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce64bb11-30d6-4efc-a17d-f03536adb58c",
   "metadata": {},
   "source": [
    "Status: complete\n",
    "\n",
    "Data\n",
    "- Benchling notebook: [2024-11-07 Human-mouse mixing ChIP-seq](https://benchling.com/s/etr-GcNccQeNTC32BHI3mLna)\n",
    "- [Library Sheet](https://docs.google.com/spreadsheets/d/1TwqZjgeley2BaOh1xkQ5Pwzi_yxNvlc1KeaTBwyCLiU)\n",
    "- Sequencing runs:\n",
    "  - [20241121_ESS](https://docs.google.com/spreadsheets/d/1kV8gOaSSB9VktkTEqVO4W3izpBkpOZ6Du1kDDAOLh8c)\n",
    "\n",
    "Splitcode configs: https://docs.google.com/spreadsheets/d/1XrNNYC3ckBm_Ir2E3MWDkFMDMuHjL5Z7uOmD9kNKZOE\n",
    "\n",
    "Results\n",
    "\n",
    "Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb6266d-136c-424c-a247-34e544313c5c",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1c39f5-8261-404b-8776-79c27e96d51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b32658-a4f2-4832-8b19-81137c72aa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Standard Library modules\n",
    "import collections\n",
    "import copy\n",
    "import gc\n",
    "import gzip\n",
    "import importlib.util\n",
    "import itertools\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "\n",
    "# Basic SciPy packages\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization packages\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import IPython.display\n",
    "\n",
    "import pysam\n",
    "\n",
    "# ChIP-DIP modules\n",
    "path_chipdip_scripts = '/central/groups/guttman/projects/chip-dip/github_private/scripts/python'\n",
    "module_spec = importlib.util.spec_from_file_location('rename_and_filter_chr', os.path.join(path_chipdip_scripts, 'rename_and_filter_chr.py'))\n",
    "rename_and_filter_chr = importlib.util.module_from_spec(module_spec)\n",
    "module_spec.loader.exec_module(rename_and_filter_chr)\n",
    "\n",
    "# Custom modules\n",
    "sys.path.append('../scripts')\n",
    "import string_distances\n",
    "import parse_barcodes\n",
    "from helpers import fastq_parse\n",
    "sys.path.remove('../scripts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534a8f9e-aca6-4994-84d6-f65de05c9396",
   "metadata": {},
   "outputs": [],
   "source": [
    "%watermark --updated --iso8601 --python --conda --machine --iversions --watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa94217-0829-4e07-945e-2bcf4e87615b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "splitcode --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a306bf1-40af-4cb2-a4e4-b724d60d4b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_PROJECT = '/central/groups/guttman/btyeh/scBarcode'\n",
    "DIR_DATA = os.path.join(DIR_PROJECT, 'data', '20241121')\n",
    "DIR_AUX = os.path.join(DIR_PROJECT, 'data_aux', '20241121')\n",
    "DIR_PROC = os.path.join(DIR_PROJECT, 'data_proc', '20241121')\n",
    "DIR_RESULTS = os.path.join(DIR_PROJECT, 'results', '20241121')\n",
    "DIR_SCRIPTS = os.path.join(DIR_PROJECT, 'scripts', '20241121')\n",
    "\n",
    "os.makedirs(DIR_AUX, exist_ok=True)\n",
    "os.makedirs(DIR_PROC, exist_ok=True)\n",
    "os.makedirs(DIR_RESULTS, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5f79b7-c34c-471e-b7a4-ec407c6eddea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_library_complexity(count_total, count_dedup, ub=None, max_err=1e-3):\n",
    "    '''\n",
    "    See https://github.com/bentyeh/resources/blob/main/bioinformatics/models_genomics.md\n",
    "\n",
    "    Generative model: Poisson sampling (i.e., with replacement) count_total reads from\n",
    "    M unique molecules, such that count_dedup molecules were sampled at least once. Solve\n",
    "    for M.\n",
    "\n",
    "    Accurate when count_total << M.\n",
    "    '''\n",
    "    if ub is None:\n",
    "        ub = count_total*1e5\n",
    "    res = scipy.optimize.minimize_scalar(\n",
    "      fun=lambda M: (M * (1 - np.exp(-count_total/M)) - count_dedup)**2,\n",
    "      bracket=(count_dedup, ub)\n",
    "    )\n",
    "    assert res.fun < max_err\n",
    "    return res.x\n",
    "\n",
    "def estimate_library_complexity2(count_total, count_mean, ub=None, max_err=1e-3):\n",
    "    '''\n",
    "    See https://github.com/bentyeh/resources/blob/main/bioinformatics/models_genomics.md\n",
    "\n",
    "    Generative model: Poisson sampling (i.e., with replacement) count_total reads from\n",
    "    M unique molecules, yielding mean observed counts count_mean. Solve for M.\n",
    "    '''\n",
    "    ub = ub if ub is not None else count_total*1e5\n",
    "    res = scipy.optimize.minimize_scalar(\n",
    "      fun=lambda M: ((count_total / M) / (1 - np.exp(-count_total / M)) - count_mean)**2,\n",
    "      bracket=(count_total / count_mean, ub)\n",
    "    )\n",
    "    assert res.fun < max_err\n",
    "    return res.x\n",
    "\n",
    "def estimate_library_complexity_curve(\n",
    "    total_reads: np.ndarray,\n",
    "    M: int,\n",
    "    ci: tuple[float, float] = (0.025, 0.975)\n",
    ") -> pd.DataFrame:\n",
    "    '''\n",
    "    Args\n",
    "    - total_reads\n",
    "    - M: total number of unique molecules in the sample\n",
    "    - ci: confidence interval\n",
    "\n",
    "    Returns: pd.DataFrame\n",
    "    - Columns = total_reads, expected_distinct, lower_ci, upper_ci\n",
    "    '''\n",
    "    p_zero = scipy.stats.binom.pmf(0, total_reads, 1/M)\n",
    "    expected_distinct = M * (1 - p_zero)\n",
    "\n",
    "    # smallest d such that P(D < d) > ci[0]\n",
    "    lower_ci = scipy.stats.binom.ppf(ci[0], M, 1 - p_zero)\n",
    "\n",
    "    # smallest d such that P(D < d) > ci[1]\n",
    "    upper_ci = scipy.stats.binom.ppf(ci[1], M, 1 - p_zero)\n",
    "    return pd.DataFrame({\n",
    "        'total_reads': total_reads,\n",
    "        'expected_distinct': expected_distinct,\n",
    "        'lower_ci': lower_ci,\n",
    "        'upper_ci': upper_ci\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8548ef-8fbb-4999-a11c-37dddac8ecff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://docs.python.org/3/library/itertools.html\n",
    "def grouper(iterable, n, *, incomplete='fill', fillvalue=None):\n",
    "    \"Collect data into non-overlapping fixed-length chunks or blocks.\"\n",
    "    # grouper('ABCDEFG', 3, fillvalue='x') → ABC DEF Gxx\n",
    "    # grouper('ABCDEFG', 3, incomplete='strict') → ABC DEF ValueError\n",
    "    # grouper('ABCDEFG', 3, incomplete='ignore') → ABC DEF\n",
    "    iterators = [iter(iterable)] * n\n",
    "    match incomplete:\n",
    "        case 'fill':\n",
    "            return itertools.zip_longest(*iterators, fillvalue=fillvalue)\n",
    "        case 'strict':\n",
    "            return zip(*iterators, strict=True)\n",
    "        case 'ignore':\n",
    "            return zip(*iterators)\n",
    "        case _:\n",
    "            raise ValueError('Expected fill, strict, or ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605a3030-6fec-4b39-8c9c-c143c69619e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of processes/threads to use\n",
    "# either manually specify an integer, or automatically detect via something like os.cpu_count()\n",
    "n_proc = 4\n",
    "\n",
    "reprocess = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94df955-5ad2-4117-9301-f7784d83e9ef",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1021e1-58b6-4a4a-9f67-9537833222a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROUNDS = ['Odd', 'Even', 'Odd2', 'Even2', 'Odd3', 'Y']\n",
    "\n",
    "TARGETS = ['CTCF', 'H3K4me3']\n",
    "DTYPE_TARGET = pd.CategoricalDtype(categories=TARGETS)\n",
    "\n",
    "SPECIES = ['human', 'mouse']\n",
    "DTYPE_SPECIES = pd.CategoricalDtype(categories=SPECIES)\n",
    "DTYPE_SPECIES_ABBREV = pd.CategoricalDtype(categories=['h', 'm'])\n",
    "\n",
    "ALIGNMENT_TYPES = ['R1', 'PE']\n",
    "DTYPE_ALIGNMENT = pd.CategoricalDtype(categories=ALIGNMENT_TYPES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb417f1-c625-408b-9efd-57e5f4045ee4",
   "metadata": {},
   "source": [
    "Key paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c309c2e-1a5f-4de7-b73d-6b472b8c3170",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_bead_counts = os.path.join(DIR_PROC, 'bead_counts.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d2b493-ae2e-484a-8eb1-a0d46fd4a769",
   "metadata": {},
   "source": [
    "## Download human and mouse genome indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e0d536-a179-4a87-a5f7-c85bada20d30",
   "metadata": {},
   "source": [
    "Bowtie 2 human genome index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d432f9-dcc1-4645-9506-d0ac473d6e78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "PATH_SCRATCH='/central/scratch/btyeh'\n",
    "\n",
    "cd \"$PATH_SCRATCH\"\n",
    "\n",
    "if [ ! -f \"${PATH_SCRATCH}/index_hg38/GRCh38_noalt_as.1.bt2\" ] || [ ! -f \"${PATH_SCRATCH}/index_hg38/GRCh38_noalt_as.rev.2.bt2\" ]; then\n",
    "    mkdir -p index_hg38\n",
    "    wget -q https://genome-idx.s3.amazonaws.com/bt/GRCh38_noalt_as.zip\n",
    "    unzip -j -d index_hg38 GRCh38_noalt_as.zip \\*.bt2\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a9c5ef-4c27-4f23-a9e0-36ef30307160",
   "metadata": {},
   "source": [
    "Bowtie 2 mouse genome index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b40551-2156-4f3e-856e-a613542defbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "PATH_SCRATCH='/central/scratch/btyeh'\n",
    "\n",
    "cd \"$PATH_SCRATCH\"\n",
    "\n",
    "if [ ! -f \"${PATH_SCRATCH}/index_mm10/mm10.1.bt2\" ] || [ ! -f \"${PATH_SCRATCH}/index_mm10/mm10.rev.2.bt2\" ]; then\n",
    "    mkdir -p index_mm10\n",
    "    wget -q https://genome-idx.s3.amazonaws.com/bt/mm10.zip\n",
    "    unzip -j -d index_mm10 mm10.zip \\*.bt2\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6115703d-3ba7-40d1-867e-8232b0475058",
   "metadata": {},
   "source": [
    "## Build combined human-mouse genome index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda5ebae-2a85-492a-ab61-3607dd297a63",
   "metadata": {},
   "source": [
    "Download all FASTA files (1 file per chromosome) for human and mouse genomes. Rename human chromosomes from \"chr*\" to \"h_chr*\" and mouse chromosomes from \"chr*\" to \"m_chr*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e16d1d-10de-402c-a6bb-646cbc963e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "PATH_SCRATCH='/central/scratch/btyeh/hg38'\n",
    "PATH_INDEX='/central/scratch/btyeh/index_hg38_mm10'\n",
    "if [ ! -f \"$PATH_SCRATCH\"/h_chr1.fa ] && \\\n",
    "    ([ ! -f \"$PATH_INDEX\"/hg38_mm10.rev.1.bt2l ] || [ ! -f \"$PATH_SCRATCH\"/h_chr1.fa.fai ]); then\n",
    "    mkdir -p \"$PATH_SCRATCH\"\n",
    "    wget -nc -q -O - https://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/hg38.chromFa.tar.gz |\n",
    "        tar -xz -C \"$PATH_SCRATCH\"\n",
    "    mv \"$PATH_SCRATCH\"/chroms/*.fa \"$PATH_SCRATCH\"\n",
    "    \n",
    "    # remove alternate loci sequences\n",
    "    rm -r \"$PATH_SCRATCH\"/chroms \"$PATH_SCRATCH\"/*_alt.fa\n",
    "    \n",
    "    cd \"$PATH_SCRATCH\"\n",
    "    for file in chr*.fa; do\n",
    "        new_file=\"h_${file}\"\n",
    "        sed -e 's/^>chr/>h_chr/' \"$file\" > \"$new_file\"\n",
    "        rm \"$file\"\n",
    "    done\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7f9dc7-a0e9-44c4-8280-d5aa28320804",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "PATH_SCRATCH='/central/scratch/btyeh/mm10'\n",
    "PATH_INDEX='/central/scratch/btyeh/index_hg38_mm10'\n",
    "if [ ! -f \"$PATH_SCRATCH\"/m_chr1.fa ] && \\\n",
    "    ([ ! -f \"$PATH_INDEX\"/hg38_mm10.rev.1.bt2l ] || [ ! -f \"$PATH_SCRATCH\"/m_chr1.fa.fai ]); then\n",
    "    mkdir -p \"$PATH_SCRATCH\"\n",
    "    wget -nc -q -O - https://hgdownload.soe.ucsc.edu/goldenPath/mm10/bigZips/chromFa.tar.gz |\n",
    "        tar -xz -C \"$PATH_SCRATCH\"\n",
    "    \n",
    "    cd \"$PATH_SCRATCH\"\n",
    "    for file in chr*.fa; do\n",
    "        new_file=\"m_${file}\"\n",
    "        sed -e 's/^>chr/>m_chr/' \"$file\" > \"$new_file\"\n",
    "        rm \"$file\"\n",
    "    done\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c7dec6-72bd-4811-9ac6-c8da3756d11d",
   "metadata": {},
   "source": [
    "Build combined genome index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48b7a2b-f3dc-4f32-9e01-cf12395eb5ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash -s {DIR_PROJECT}\n",
    "DIR_PROJECT=\"$1\"\n",
    "\n",
    "PATH_SBATCH=\"${DIR_PROJECT}/scripts/20240625/build_index.sbatch\"\n",
    "PATH_INDEX='/central/scratch/btyeh/index_hg38_mm10'\n",
    "\n",
    "if [ ! -f \"$PATH_INDEX\"/hg38_mm10.rev.1.bt2l ]; then\n",
    "    sbatch --output=\"$PATH_INDEX\"/slurm.out --error=\"$PATH_INDEX\"/slurm.err \"$PATH_SBATCH\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6c261a-b271-476c-b8ce-7e493e44859b",
   "metadata": {},
   "source": [
    "### Create IGV Genome JSON file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9392791e-3133-4575-973d-cac2a39cffe5",
   "metadata": {},
   "source": [
    "Concatenate all reference chromosome FASTA files and build a FASTA index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4eea92-5dd2-4981-93de-027b9147e565",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "PATH_SCRATCH='/central/scratch/btyeh'\n",
    "PATH_INDEX=\"${PATH_SCRATCH}/index_hg38_mm10\"\n",
    "\n",
    "if [ ! -f \"$PATH_INDEX\"/hg38_mm10.fa.fai ]; then\n",
    "    source ~/.bashrc\n",
    "    conda activate chipdip\n",
    "    \n",
    "    cat \"$PATH_SCRATCH\"/hg38/*.fa \"$PATH_SCRATCH\"/mm10/*.fa > \"$PATH_INDEX\"/hg38_mm10.fa\n",
    "    samtools faidx \"$PATH_INDEX\"/hg38_mm10.fa\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38c6e5e-5d19-418d-b799-5260575ecef8",
   "metadata": {},
   "source": [
    "Download GENCODE annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192ad5bd-1883-435d-85ed-0a2f8cc5fe53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -e\n",
    "\n",
    "PATH_SCRATCH='/central/scratch/btyeh'\n",
    "PATH_ANNOT=\"$PATH_SCRATCH\"/annot\n",
    "\n",
    "if [ ! -f \"$PATH_ANNOT\"/hg38_mm10.gtf.gz.tbi ]; then\n",
    "    source ~/.bashrc\n",
    "    conda activate chipdip\n",
    "    mkdir -p \"$PATH_ANNOT\"\n",
    "    \n",
    "    # download human GENCODE GTF and rename chromosomes\n",
    "    wget -q -O - https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_46/gencode.v46.basic.annotation.gtf.gz |\n",
    "        unpigz -p 4 -c |\n",
    "        sort -k 1,1V -k 4,4V -k 5,5V |\n",
    "        sed -E -e 's/^chr/h_chr/' > \"$PATH_ANNOT\"/hg38.gtf\n",
    "    \n",
    "    # download mouse GENCODE GTF and rename chromosomes\n",
    "    wget -q -O - https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M25/gencode.vM25.basic.annotation.gtf.gz |\n",
    "        unpigz -p 4 -c |\n",
    "        sort -k 1,1V -k 4,4V -k 5,5V |\n",
    "        sed -E -e 's/^chr/m_chr/' > \"$PATH_ANNOT\"/mm10.gtf\n",
    "    \n",
    "    # concatenate human and mouse genome GTFs\n",
    "    cat \"$PATH_ANNOT\"/hg38.gtf \"$PATH_ANNOT\"/mm10.gtf |\n",
    "        bgzip --threads 4 -c /dev/stdin > \"$PATH_ANNOT\"/hg38_mm10.gtf.gz\n",
    "    \n",
    "    rm \"$PATH_ANNOT\"/hg38.gtf \"$PATH_ANNOT\"/mm10.gtf\n",
    "    \n",
    "    # index the combined GTF\n",
    "    tabix -f \"$PATH_ANNOT\"/hg38_mm10.gtf.gz\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89c7308-d92b-4573-be7c-afd7f79f2ce1",
   "metadata": {},
   "source": [
    "Using paths to these annotation files, I created an IGV genome JSON file manually at `data_aux/20240625/hg38_mm10.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c6fe6d-6005-47bb-b2a5-32ab036818c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DIR_AUX, 'hg38_mm10.json'), 'rt') as f:\n",
    "    print(json.dumps(json.load(f), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb378b5-8ba2-42b1-8ac9-e9cb1914b5eb",
   "metadata": {},
   "source": [
    "# FastQC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ecfb4a-1e48-43f1-a334-16718c109087",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s {DIR_DATA} {DIR_PROC} {reprocess}\n",
    "DIR_DATA=\"$1\"\n",
    "DIR_PROC=\"$2\"\n",
    "reprocess=\"$3\"\n",
    "DIR_FASTQC_OUT=\"${DIR_PROC}/fastqc\"\n",
    "if [ ! -d \"$DIR_FASTQC_OUT\" ] || [ \"$reprocess\" = \"True\" ]; then\n",
    "    mkdir -p \"${DIR_PROC}/fastqc\"\n",
    "    cd \"$DIR_DATA\"\n",
    "    source ~/.bashrc\n",
    "    conda activate chipdip\n",
    "    nohup fastqc *.fastq.gz -t 20 -q -o \"$DIR_FASTQC_OUT\" &> \"${DIR_PROC}/fastqc.log\" &\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bbacd3-d997-4d45-83a8-7975c0d6833c",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16303295-a850-4614-869a-9b91b76b1843",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_R1 = os.path.join(DIR_DATA, \"HEK-pSM44_mixing_CTCF_H3K4me3_ChIP-seq_R1.fastq.gz\")\n",
    "PATH_R2 = os.path.join(DIR_DATA, \"HEK-pSM44_mixing_CTCF_H3K4me3_ChIP-seq_R2.fastq.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6338fa-418b-4d88-8d1d-92248ea5c729",
   "metadata": {},
   "source": [
    "Final barcoded cell oligo structure: [Oligo (PC50_bc6 / PC50_bc7) + Odd + Even + Odd + Even + Odd + NYLigOdd](https://benchling.com/s/seq-JLjQnGxk3XhHueFGB5EQ?m=slm-x8jDl91Zo2EuS0W2OXJW)\n",
    "- Top strand: 154-157 nt (variable due to NYLigOddStg)\n",
    "- Bottom strand: 213-216 nt\n",
    "- Library size: 297-300 bp\n",
    "- Insert size for sequencing: 161-164 bp. A read 1 length of 121 bp would include the oligo barcode and all tags except the last Odd and NYLigOdd, while a read 2 length of 164 bp would include the entire oligo barcode.\n",
    "\n",
    "Final barcoded DNA structure: [DPM + Odd + Even + Odd + Even + Odd + NYLigOdd](https://benchling.com/s/seq-MnXp2h0SAJ8dfB3N4lzc?m=slm-Copp8W7WpeZkiRtBICFG)\n",
    "- Total added length (relative to genomic DNA): 308-311 bp (variable due to NYLigOddStg)\n",
    "- Read 2 barcode length (including dA tail): 165 bp\n",
    "- Read 1 DPM length: 10 bp\n",
    "\n",
    "Sequencing\n",
    "- Instrument and kit: AVITI Cloudbreak Freestyle\n",
    "- Read 1 length: 120 bp\n",
    "- Read 2 length: 180 bp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0000f9-3266-40d4-b307-6f7cf2300373",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "\n",
    "1. Identify and trim bead barcode for all reads (add barcode to read name). Discard reads without a complete bead barcode.\n",
    "2. Cell oligo processing\n",
    "   - Identify species barcode\n",
    "   - Deduplicate by species barcode and bead barcode\n",
    "3. Chromatin processing\n",
    "   - Trim DPM from chromatin reads, and check that DPM sequences match between Read 1 and Read 2\n",
    "   - Align to human-mouse mixed genome: try aligning read 1 alone or paired-end alignment\n",
    "   - Split by species to separate human and mouse BAM files\n",
    "   - Remove reads (or read pairs) that overlap ENCODE blacklist regions\n",
    "   - Deduplicate by alignment position and bead barcode\n",
    "   - Generate bigWigs\n",
    "\n",
    "Read counts\n",
    "\n",
    "| Stage | Read count | Proportion of parent stage | Proportion of total |\n",
    "| ----- | ---------: | -------------------------: | -------------------: |\n",
    "| Total | 77,012,366 | | |\n",
    "| `- Identifiable bead barcode` | 52,726,577 | 68.5% | 68.5% |\n",
    "| `  - Oligo` | 40,021,181 | 75.9% | 52.0% |\n",
    "| `    - Human (bc6)` | 19,581,303 |  |  |\n",
    "| `    - Mouse (bc7)` | 20,439,878 |  |  |\n",
    "| `  - Chromatin` |  |  |  |\n",
    "| `    - CTCF` | 4,355,241 |  |  |\n",
    "| `      - R1 aligned` |  |  |  |\n",
    "| `        - Deduplicated` |  |  |  |\n",
    "| `          - Human, not blacklisted` |  |  |  |\n",
    "| `          - Mouse, not blacklisted` |  |  |  |\n",
    "| `      - Paired-end aligned` |  |  |  |\n",
    "| `        - Deduplicated` |  |  |  |\n",
    "| `          - Human, not blacklisted` |  |  |  |\n",
    "| `          - Mouse, not blacklisted` |  |  |  |\n",
    "| `    - H3K4me3` | 4,001,469 |  |  |\n",
    "| `      - R1 aligned` |  |  |  |\n",
    "| `        - Deduplicated` |  |  |  |\n",
    "| `          - Human, not blacklisted` |  |  |  |\n",
    "| `          - Mouse, not blacklisted` |  |  |  |\n",
    "| `      - Paired-end aligned` |  |  |  |\n",
    "| `        - Deduplicated` |  |  |  |\n",
    "| `          - Human, not blacklisted` |  |  |  |\n",
    "| `          - Mouse, not blacklisted` |  |  |  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d749ff71-3717-4211-9317-3c733f2eaaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(path_bead_counts) and not reprocess:\n",
    "    df_beads = pd.DataFrame(\n",
    "        data=np.load(path_bead_counts)['values'],\n",
    "        index=pd.Index(np.load(path_bead_counts)['index'], name='bead'),\n",
    "        columns=['human oligo', 'mouse oligo', 'human H3K4me3', 'mouse H3K4me3', 'human CTCF', 'mouse CTCF'],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a882ac0-ccdd-4344-90a1-fca1540632e9",
   "metadata": {},
   "source": [
    "## Identify bead barcode from R2\n",
    "\n",
    "`R[1|2]_bead-barcode.fastq.gz`\n",
    "- Append `::bead=<bead number>` to read name\n",
    "- Trim the bead barcode sequence from R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d26513c-dd6a-497a-abae-473e7e90e1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_config_bead_barcode = os.path.join(DIR_AUX, 'splitcode_config-bead_barcode.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41960151-fa4e-401c-8622-450c7679852c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s {DIR_DATA} {DIR_PROC} {path_config_bead_barcode} {PATH_R1} {PATH_R2} {reprocess}\n",
    "DIR_DATA=\"$1\"\n",
    "DIR_PROC=\"$2\"\n",
    "PATH_CONFIG=\"$3\"\n",
    "PATH_R1=\"$4\"\n",
    "PATH_R2=\"$5\"\n",
    "reprocess=\"$6\"\n",
    "\n",
    "PATH_MAPPING=\"$DIR_PROC/mapping_bead-barcode.tsv\"\n",
    "PATH_SUMMARY=\"$DIR_PROC/summary_bead-barcode.json\"\n",
    "PATH_OUT1=\"$DIR_PROC/R1_bead-barcode.fastq.gz\"\n",
    "PATH_OUT2=\"$DIR_PROC/R2_bead-barcode.fastq.gz\"\n",
    "\n",
    "if [ \"$reprocess\" = True ] || [ ! -f \"${PATH_MAPPING}.gz\" ]; then\n",
    "    mkfifo pipe_R1 pipe_R2 pipe_mapping\n",
    "    pids=()\n",
    "\n",
    "    # modify read names so that there is no whitespace between the read name and bead barcode.\n",
    "    sed -E -e 's/^(@\\S+) BI:i:/\\1::bead=/' pipe_R1 | pigz -p 4 > \"$PATH_OUT1\" &\n",
    "    pids[0]=\"$!\"\n",
    "    sed -E -e 's/^(@\\S+) BI:i:/\\1::bead=/' pipe_R2 | pigz -p 4 > \"$PATH_OUT2\" &\n",
    "    pids[1]=\"$!\"\n",
    "    cut -f 2,3 pipe_mapping | pigz -p 4 > \"$PATH_MAPPING\" &\n",
    "    pids[2]=\"$!\"\n",
    "    \n",
    "    splitcode -c \"$PATH_CONFIG\" \\\n",
    "        --nFastqs=2 --com-names --assign --no-outb -t 20 \\\n",
    "        --mapping=pipe_mapping --summary=\"$PATH_SUMMARY\" --output=pipe_R1,pipe_R2 \\\n",
    "        \"$PATH_R1\" \"$PATH_R2\"\n",
    "\n",
    "    for pid in \"${pids[*]}\"; do\n",
    "        wait $pid\n",
    "    done\n",
    "    rm pipe_R1 pipe_R2\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814a52b6-7a7c-4837-b9ad-7d90974c8d67",
   "metadata": {},
   "source": [
    "Parse mapping into pandas DataFrame\n",
    "- Columns: `Odd`, `Even`, `Odd2`, `Even2`, `Odd3`, `Y`, `Count`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e859c6d-71f4-448f-8c53-0b14c5d6462d",
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_bead_barcode = (\n",
    "    'NYStgBot_(?P<Y>\\d+),'\n",
    "    'OddBot_(?P<Odd3>\\d+),'\n",
    "    'EvenBot_(?P<Even2>\\d+),'\n",
    "    'OddBot_(?P<Odd2>\\d+),'\n",
    "    'EvenBot_(?P<Even>\\d+),'\n",
    "    'OddBot_(?P<Odd>\\d+)'\n",
    ")\n",
    "df_bead_barcodes = pd.read_csv(\n",
    "    os.path.join(DIR_PROC, 'mapping_bead-barcode.tsv.gz'),\n",
    "    sep='\\t',\n",
    "    names=['barcode', 'count'],\n",
    "    dtype={'count': int}\n",
    ").pipe(lambda df: pd.concat(\n",
    "    (df, df['barcode'].str.extract(regex_bead_barcode).astype(np.uint8)),\n",
    "    axis=1\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7c7ecb-0934-493b-b9bb-50696022d5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bead_barcodes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1839b574-9dcf-4f3f-b45d-c6d1e83e2adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bead_barcodes['count'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd28fb3-fa51-4bb2-99c6-e32cef8a7e2e",
   "metadata": {},
   "source": [
    "### Verify indices of barcodes used each round"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33260c69-c49b-47bf-8c1f-adc30e9e4e39",
   "metadata": {},
   "source": [
    "Actual indices used:\n",
    "- Odd: rows A-D (indices 1-48)\n",
    "- Even: rows A-D (indices 1-48)\n",
    "- Odd2: rows E-H (indices 49-96)\n",
    "- Even2: rows E-H (indices 49-96)\n",
    "- Odd3: rows A-D (indices 1-48)\n",
    "- NYLigOdd: rows E-H (indices 49-96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8febc7fd-bf05-4e77-a029-44bce7ecd2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(\n",
    "    kind='bar',\n",
    "    data=(\n",
    "        pd.concat(\n",
    "            [\n",
    "                df_bead_barcodes.groupby(r)['count'].sum().rename(r).reindex(pd.Index(list(range(1, 97))), fill_value=0)\n",
    "                for r in ROUNDS\n",
    "            ],\n",
    "            axis=1\n",
    "        )\n",
    "        .reset_index(names='index')\n",
    "        .melt(id_vars='index', var_name='round', value_name='count')\n",
    "    ),\n",
    "    x='index',\n",
    "    y='count',\n",
    "    row='round',\n",
    "    row_order=ROUNDS,\n",
    "    sharex=True,\n",
    "    sharey=True,\n",
    "    facet_kws=dict(gridspec_kws=dict(hspace=0.6))\n",
    ")\n",
    "g.axes.flatten()[-1].tick_params(axis='x', labelsize='xx-small')\n",
    "g.figure.set_size_inches(10, 6)\n",
    "g.savefig(os.path.join(DIR_RESULTS, 'tag indices used per round.png'), dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839bb403-ed39-4311-bd52-06b471fb70cd",
   "metadata": {},
   "source": [
    "Since `df_bead_barcodes` is a very large (>2 GB) variable, and it is not used later in this analysis, we delete it to free up memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1d8d5e-9ffc-45db-8d19-bfc9901b4bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Size of df_bead_barcodes (in bytes):', sys.getsizeof(df_bead_barcodes))\n",
    "del df_bead_barcodes\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a211e2b-783c-4752-95e3-230e2d01bb64",
   "metadata": {},
   "source": [
    "## Oligo read processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0026580-adc8-4c26-bb55-29fedaa93481",
   "metadata": {},
   "source": [
    "1. Select only oligo read pairs\n",
    "2. Validate the read pair\n",
    "   - Since the oligo barcode (bc6 or bc7) is sequenced in both read 1 and read 2, make sure that it matches.\n",
    "4. Generate table with following columns: bead #, human oligo count, mouse oligo count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a622d2f-fe47-4a20-bd98-abfd12f4b7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_config_oligos = os.path.join(DIR_AUX, 'splitcode_config-oligos.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fda3f4-affc-4846-827a-cb26d64b3dd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash -s {DIR_PROC} {path_config_oligos} {path_bead_counts} {reprocess}\n",
    "DIR_PROC=\"$1\"\n",
    "PATH_CONFIG=\"$2\"\n",
    "PATH_BEAD_COUNTS=\"$3\"\n",
    "reprocess=\"$4\"\n",
    "\n",
    "PATH_R1=\"$DIR_PROC/R1_bead-barcode.fastq.gz\"\n",
    "PATH_R2=\"$DIR_PROC/R2_bead-barcode.fastq.gz\"\n",
    "\n",
    "if [ \"$reprocess\" = True ] || ([ ! -f \"$PATH_BEAD_COUNTS\" ] && [ ! -f \"$DIR_PROC/oligos.csv.gz\" ]); then\n",
    "    # I would like to put the \"keep\" directive into the config file, but currently there is a bug in splitcode\n",
    "    # parsing \"remove\" and \"keep\" directives in config files (https://github.com/pachterlab/splitcode/issues/33).\n",
    "    # Consequently, I currently use the keep directive as a command line argument as a workaround\n",
    "    splitcode -c \"$PATH_CONFIG\" \\\n",
    "        --nFastqs=2 --keep=<(echo -e \"human,human_rc\\nmouse,mouse_rc\") --mod-names --select=0 --out-fasta -t 8 --pipe \\\n",
    "        \"$PATH_R1\" \"$PATH_R2\" |\n",
    "        grep -E -e '^>' |\n",
    "        sed -E \\\n",
    "            -e 's/^>.*::bead=([0-9]+)::\\[(human|mouse)\\]\\[(human|mouse)_rc\\]/\\1,\\2,\\3/' \\\n",
    "            -e 's/human/h/g' -e 's/mouse/m/g' |\n",
    "        sort |\n",
    "        uniq -c |\n",
    "        sed -E -e 's/^\\s+([0-9]+)\\s+/\\1,/' |\n",
    "        pigz -p 4 > \"$DIR_PROC/oligos.csv.gz\"\n",
    "        # columns = count, bead, species, species2\n",
    "\n",
    "    # in theory, could convert this table into binary format for greater speed and space efficiency\n",
    "    # - for example, represent bead # and count values as unsigned 64-bit integers, and\n",
    "    #   species and species2 as booleans (0 = human, 1 = mouse).\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f1b3ec-955b-41b3-b005-acee4f276d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df_beads' not in locals().keys() or reprocess:\n",
    "    df_oligos = pd.read_csv(\n",
    "        os.path.join(DIR_PROC, 'oligos.csv.gz'),\n",
    "        sep=',',\n",
    "        header=None,\n",
    "        names=['count', 'bead', 'species', 'species2'],\n",
    "        index_col='bead',\n",
    "        dtype={\n",
    "            'count': int,\n",
    "            'bead': int,\n",
    "            'species': DTYPE_SPECIES_ABBREV,\n",
    "            'species2': DTYPE_SPECIES_ABBREV\n",
    "        }\n",
    "    )\n",
    "    assert (df_oligos['species'] == df_oligos['species2']).all()\n",
    "    df_oligos = (\n",
    "        df_oligos\n",
    "        .pivot(columns='species', values='count')\n",
    "        .fillna(0)\n",
    "        .astype(int)\n",
    "        .rename(columns={'h': 'human', 'm': 'mouse'})\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9210a557-cdb6-446b-85e8-2fa6ec339a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df_beads' not in locals().keys() or reprocess:\n",
    "    display(df_oligos.sum(axis=0))\n",
    "else:\n",
    "    display(df_beads[['human oligo', 'mouse oligo']].sum(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5300a3-8a01-4757-a233-b52a1078b59a",
   "metadata": {},
   "source": [
    "## Chromatin read processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c6b5ac-3a2e-4b0f-b278-f0f063e4264a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_config_split_chromatin = os.path.join(DIR_AUX, 'splitcode_config-chromatin.tsv')\n",
    "path_keep_chromatin = os.path.join(DIR_AUX, 'keep-chromatin.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da85d25-05b4-4a56-a28a-233bdc376467",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s {DIR_PROC} {path_config_split_chromatin} {path_keep_chromatin} {reprocess}\n",
    "DIR_PROC=\"$1\"\n",
    "PATH_CONFIG=\"$2\"\n",
    "PATH_KEEP=\"$3\"\n",
    "reprocess=\"$4\"\n",
    "\n",
    "PATH_R1=\"$DIR_PROC/R1_bead-barcode.fastq.gz\"\n",
    "PATH_R2=\"$DIR_PROC/R2_bead-barcode.fastq.gz\"\n",
    "\n",
    "if [ \"$reprocess\" = True ] || [ ! -f \"$DIR_PROC/CTCF_R1.fastq.gz\" ]; then\n",
    "    # change working directory to DIR_PROC so that the split files are generated in that directory\n",
    "    cd \"$DIR_PROC\"\n",
    "\n",
    "    splitcode -c \"$PATH_CONFIG\" \\\n",
    "        --nFastqs=2 -t 8 --keep=\"$PATH_KEEP\" --keep-r1-r2 --gzip --no-output --no-outb \\\n",
    "        \"$PATH_R1\" \"$PATH_R2\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fc9626-d310-4a06-9cf4-d554112578d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s {DIR_PROC} {DIR_AUX} {DIR_SCRIPTS}\n",
    "DIR_PROC=\"$1\"\n",
    "DIR_AUX=\"$2\"\n",
    "DIR_SCRIPTS=\"$3\"\n",
    "\n",
    "source ~/.bashrc\n",
    "conda activate snakemake\n",
    "\n",
    "snakemake \\\n",
    "    --snakefile \"${DIR_SCRIPTS}/Snakefile\" \\\n",
    "    --directory \"$DIR_PROC\" \\\n",
    "    --configfile \"${DIR_AUX}/config.yaml\" \\\n",
    "    --dag |\n",
    "dot -Tpdf > \"${DIR_SCRIPTS}/dag.pdf\"\n",
    "\n",
    "snakemake \\\n",
    "    --snakefile \"${DIR_SCRIPTS}/Snakefile\" \\\n",
    "    --directory \"$DIR_PROC\" \\\n",
    "    --configfile \"${DIR_AUX}/config.yaml\" \\\n",
    "    --filegraph |\n",
    "dot -Tpdf > \"${DIR_SCRIPTS}/filegraph.pdf\"\n",
    "\n",
    "snakemake \\\n",
    "    --snakefile \"${DIR_SCRIPTS}/Snakefile\" \\\n",
    "    --directory \"$DIR_PROC\" \\\n",
    "    --configfile \"${DIR_AUX}/config.yaml\" \\\n",
    "    --rulegraph |\n",
    "dot -Tpdf > \"${DIR_SCRIPTS}/rulegraph.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0371c1-d2eb-4fce-8fe3-a4bb24165235",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s {DIR_PROC} {DIR_AUX} {DIR_SCRIPTS}\n",
    "DIR_PROC=\"$1\"\n",
    "DIR_AUX=\"$2\"\n",
    "DIR_SCRIPTS=\"$3\"\n",
    "\n",
    "source ~/.bashrc\n",
    "conda activate snakemake\n",
    "\n",
    "snakemake \\\n",
    "    --snakefile \"${DIR_SCRIPTS}/Snakefile\" \\\n",
    "    --directory \"$DIR_PROC\" \\\n",
    "    --configfile \"${DIR_AUX}/config.yaml\" \\\n",
    "    --use-conda \\\n",
    "    --conda-frontend conda \\\n",
    "    --printshellcmds \\\n",
    "    --rerun-incomplete \\\n",
    "    -j 50 \\\n",
    "    --cluster-config \"${DIR_AUX}/cluster.yaml\" \\\n",
    "    --cluster \"sbatch -c {cluster.cpus} \\\n",
    "    -t {cluster.time} -N {cluster.nodes} \\\n",
    "    --mem {cluster.mem} \\\n",
    "    --output {cluster.output} \\\n",
    "    --error {cluster.error}\" \\\n",
    "    --cluster-cancel scancel \\\n",
    "    &> \"${DIR_PROC}/snakemake.log\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a25d17-cdcd-4608-b765-426e4e397c59",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29e98af-e4d8-4ecd-8a57-c57360617f00",
   "metadata": {},
   "source": [
    "Load filtered and deduplicated chromatin read alignment coordinates and counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cd6436-bc96-4a6b-a495-df6a2c78b303",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chromatin = []\n",
    "for target in TARGETS:\n",
    "    for species in SPECIES:\n",
    "        for alignment_type in ALIGNMENT_TYPES:\n",
    "            path_chromatin_counts = os.path.join(DIR_PROC, f'{target}-{alignment_type}_{species}_filtered_dedup_counts.bed.gz')\n",
    "            df_chromatin.append(\n",
    "                pd.read_csv(path_chromatin_counts, sep='\\t', names=['chr', 'start', 'end', 'bead', 'count'])\n",
    "                .assign(target=target, species=species, alignment_type=alignment_type)\n",
    "                .astype({'target': DTYPE_TARGET, 'species': DTYPE_SPECIES, 'alignment_type': DTYPE_ALIGNMENT})\n",
    "            )\n",
    "df_chromatin = pd.concat(df_chromatin, axis=0, ignore_index=True).astype({'chr': 'category'})\n",
    "df_chromatin['length'] = df_chromatin['end'] - df_chromatin['start']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd168a8-9a41-4444-96bc-21b8a629e031",
   "metadata": {},
   "source": [
    "Paired end vs. read 1-only alignment counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dad5cb-b91f-4517-afb3-04541c54cf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(\n",
    "    (\n",
    "        df_chromatin\n",
    "        .groupby(['target', 'species', 'alignment_type'], observed=True)\n",
    "        .size()\n",
    "        .rename('count')\n",
    "        .reset_index()\n",
    "        .pipe(lambda df: df.assign(**{'target-species': df['target'].str.cat(df['species'], sep='-')}))\n",
    "    ),\n",
    "    x='target-species',\n",
    "    y='count',\n",
    "    hue='alignment_type',\n",
    ")\n",
    "ax.set_title('Deduplicated reads per species, target, and alignment type')\n",
    "ax.figure.savefig(\n",
    "    os.path.join(DIR_RESULTS, 'paired-end vs. read 1-only alignment counts.png'),\n",
    "    dpi=300,\n",
    "    bbox_inches='tight'\n",
    ")\n",
    "ax.figure.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae32794-1120-4324-a898-4e87a19117c0",
   "metadata": {},
   "source": [
    "## Insert length distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af99239-7d48-4ce4-b31f-57a9d844eccc",
   "metadata": {},
   "source": [
    "Insert length distribution of aligned, properly paired reads after ENCODE blacklist filtering and deduplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14477211-79b6-42bc-ad6b-9d32466615b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, sharex=True, sharey='row', constrained_layout=True)\n",
    "\n",
    "mask_PE = df_chromatin['alignment_type'] == 'PE'\n",
    "\n",
    "# insert length by species\n",
    "sns.ecdfplot(\n",
    "    df_chromatin.loc[mask_PE],\n",
    "    x='length',\n",
    "    hue='species',\n",
    "    ax=axs[0, 0]\n",
    ")\n",
    "sns.histplot(\n",
    "    df_chromatin.loc[mask_PE],\n",
    "    x='length',\n",
    "    # auto binning can lead to artifactual periodic peaks in the histogram --> need to manually set binwidth\n",
    "    # - can verify no actual periodic peaks by manually looking at values in the df_chromatin table\n",
    "    binwidth=5,\n",
    "    hue='species',\n",
    "    ax=axs[1, 0]\n",
    ")\n",
    "\n",
    "# insert length by target\n",
    "sns.ecdfplot(\n",
    "    df_chromatin.loc[mask_PE],\n",
    "    x='length',\n",
    "    hue='target',\n",
    "    ax=axs[0, 1]\n",
    ")\n",
    "sns.histplot(\n",
    "    df_chromatin.loc[mask_PE],\n",
    "    x='length',\n",
    "    binwidth=5,\n",
    "    hue='target',\n",
    "    ax=axs[1, 1]\n",
    ")\n",
    "\n",
    "sns.move_legend(axs[0, 0], loc='lower right')\n",
    "sns.move_legend(axs[0, 1], loc='lower right')\n",
    "sns.move_legend(axs[1, 0], loc='upper right')\n",
    "sns.move_legend(axs[1, 1], loc='upper right')\n",
    "\n",
    "axs[1, 0].set_xlim(0, 1000)\n",
    "axs[1, 0].set_xlabel('length (bp)')\n",
    "axs[1, 0].set_ylabel('Count of deduplicated reads')\n",
    "axs[0, 0].set_title('Insert length by species')\n",
    "axs[0, 1].set_title('Insert length by target')\n",
    "\n",
    "fig.suptitle('Chromatin fragmentation size')\n",
    "fig.savefig(os.path.join(DIR_RESULTS, 'chromatin_fragmentation_size.png'), bbox_inches='tight', dpi=300)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e31189-b21a-4d69-bc77-514bca339882",
   "metadata": {},
   "source": [
    "## Visualize complexity estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80004f72-786a-4a92-bd11-322e66e7be09",
   "metadata": {},
   "source": [
    "Load complexity curves generated by preseq, and generate complexity curves using my own Poisson models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa29774-886f-4958-b7d3-a2ef2e8f3f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chromatin_complexity_curves = []\n",
    "df_chromatin_complexity_total = []\n",
    "for target in TARGETS:\n",
    "    for species in SPECIES:\n",
    "        for alignment_type in ALIGNMENT_TYPES:\n",
    "\n",
    "            # load complexity curves generated by preseq\n",
    "            path_chromatin_complexity_curve = os.path.join(\n",
    "                DIR_PROC,\n",
    "                f'{target}-{alignment_type}_{species}_filtered_dedup_complexity-curve.txt'\n",
    "            )\n",
    "            path_chromatin_complexity_total = os.path.join(\n",
    "                DIR_PROC,\n",
    "                f'{target}-{alignment_type}_{species}_filtered_dedup_complexity-total.txt'\n",
    "            )\n",
    "            df_chromatin_complexity_curves.append(\n",
    "                pd.read_csv(path_chromatin_complexity_curve, sep='\\t', header=0)\n",
    "                .rename(columns={\n",
    "                    'TOTAL_READS': 'total_reads',\n",
    "                    'EXPECTED_DISTINCT': 'expected_distinct',\n",
    "                    'LOWER_0.95CI': 'lower_ci',\n",
    "                    'UPPER_0.95CI': 'upper_ci'\n",
    "                })\n",
    "                .assign(target=target, species=species, alignment_type=alignment_type, model='preseq')\n",
    "            )\n",
    "            df_chromatin_complexity_total.append(\n",
    "                pd.read_csv(path_chromatin_complexity_total, sep='\\t', header=0)\n",
    "                .assign(target=target, species=species, alignment_type=alignment_type, model='preseq')\n",
    "                .squeeze()\n",
    "            )\n",
    "\n",
    "            # generate complexity curves using my own Poisson models\n",
    "            mask = (df_chromatin['species'] == species) & \\\n",
    "                   (df_chromatin['target'] == target) & \\\n",
    "                   (df_chromatin['alignment_type'] == alignment_type)\n",
    "            count_total = df_chromatin.loc[mask, 'count'].sum()\n",
    "            count_mean = df_chromatin.loc[mask, 'count'].mean()\n",
    "            M = int(estimate_library_complexity2(count_total, count_mean))\n",
    "            df_chromatin_complexity_total.append(\n",
    "                pd.Series(dict(\n",
    "                    target=target,\n",
    "                    species=species,\n",
    "                    alignment_type=alignment_type,\n",
    "                    model='zero-truncated Poisson',\n",
    "                    pop_size_estimate=M\n",
    "                ))\n",
    "            )\n",
    "            total_reads = np.linspace(1, int(3e7), 50, dtype=int)\n",
    "            df_chromatin_complexity_curves.append(\n",
    "                estimate_library_complexity_curve(total_reads, M)\n",
    "                .assign(target=target, species=species, alignment_type=alignment_type, model='Poisson')\n",
    "            )\n",
    "\n",
    "df_chromatin_complexity_curves = (\n",
    "    pd.concat(df_chromatin_complexity_curves, axis=0, ignore_index=True)\n",
    "    .astype({'target': DTYPE_TARGET, 'species': DTYPE_SPECIES, 'alignment_type': DTYPE_ALIGNMENT, 'model': 'category'})\n",
    ")\n",
    "df_chromatin_complexity_total = (\n",
    "    pd.concat(df_chromatin_complexity_total, axis=1, ignore_index=True).T\n",
    "    .astype({'target': DTYPE_TARGET, 'species': DTYPE_SPECIES, 'alignment_type': DTYPE_ALIGNMENT, 'model': 'category'})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c68300a-b98d-45c4-ab64-4698125ab4b3",
   "metadata": {},
   "source": [
    "Plot complexity curves, split by alignment type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece9e666-1378-4d9b-ba40-e54c59e4e4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 4), sharex=True, sharey=True, constrained_layout=True)\n",
    "axs[0].set_title('Alignment: paired end')\n",
    "axs[0].set_xlabel('Total reads')\n",
    "axs[0].set_ylabel('Expected unique reads')\n",
    "axs[1].set_title('Alignment: read 1 only')   \n",
    "\n",
    "def filter_df(df, filter_dict):\n",
    "    mask = np.ones(len(df), dtype=bool)\n",
    "    for col, value in filter_dict.items():\n",
    "        if col in df.columns:\n",
    "            mask &= (df[col] == value)\n",
    "    return df.loc[mask]\n",
    "\n",
    "i = 0\n",
    "for target in TARGETS:\n",
    "    for species in SPECIES:\n",
    "        color = f'C{i}'\n",
    "        i += 1\n",
    "        for model, ls in zip(('preseq', 'Poisson'), ('solid', 'dotted')):\n",
    "            mask_dict = dict(target=target, species=species, model=model, alignment_type='PE')\n",
    "            kwargs = dict(color=color, ls=ls, label=f'{target}, {species} ({model})')\n",
    "            axs[0].plot(\n",
    "                filter_df(df_chromatin_complexity_curves, mask_dict)['total_reads'],\n",
    "                filter_df(df_chromatin_complexity_curves, mask_dict)['expected_distinct'],\n",
    "                **kwargs\n",
    "            )\n",
    "            mask_dict = dict(target=target, species=species, model=model, alignment_type='R1')\n",
    "            axs[1].plot(\n",
    "                filter_df(df_chromatin_complexity_curves, mask_dict)['total_reads'],\n",
    "                filter_df(df_chromatin_complexity_curves, mask_dict)['expected_distinct'],\n",
    "                **kwargs\n",
    "            )\n",
    "            if model == 'Poisson':\n",
    "                kwargs = dict(color=color, ls='dashed', label=f'{target}, {species} (current reads)')\n",
    "                axs[0].axvline(\n",
    "                    filter_df(df_chromatin, mask_dict)['count'].sum(),\n",
    "                    **kwargs\n",
    "                )\n",
    "                axs[1].axvline(\n",
    "                    filter_df(df_chromatin, mask_dict)['count'].sum(),\n",
    "                    **kwargs\n",
    "                )\n",
    "axs[1].legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "fig.suptitle('Complexity curves')\n",
    "fig.savefig(\n",
    "    os.path.join(DIR_RESULTS, 'chromatin complexity curves.png'),\n",
    "    dpi=300,\n",
    "    bbox_inches='tight'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311770c4-0985-4fbc-9756-9f5deec316c6",
   "metadata": {},
   "source": [
    "Calculate estimated proportion of library complexity sequenced, based on paired-end alignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa9de45-6806-4d3b-89d2-d380665e3986",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "x = 1\n",
    "xlabels = []\n",
    "for target in TARGETS:\n",
    "    for species in SPECIES:\n",
    "        xlabels.append(f'{target}-{species}')\n",
    "        mask_dict = dict(target=target, species=species, alignment_type='PE', model='preseq')\n",
    "        complexity_estimate = filter_df(df_chromatin_complexity_total, mask_dict).squeeze()['pop_size_estimate']\n",
    "        complexity_observed = len(filter_df(df_chromatin, mask_dict))\n",
    "        ax.bar(x, complexity_observed, facecolor=f'C{x-1}')\n",
    "        ax.bar(x, complexity_estimate, facecolor=(0, 0, 0, 0), edgecolor=f'C{x-1}', linewidth=2, ls='dotted')\n",
    "        ax.text(\n",
    "            x,\n",
    "            complexity_observed + 0.2e6,\n",
    "            f'{complexity_observed / complexity_estimate:.1%}',\n",
    "            ha='center'\n",
    "        )\n",
    "        x += 1\n",
    "ax.set_xticks([1, 2, 3, 4], xlabels)\n",
    "ax.set_title('Proportion of estimated total chromatin molecules sequenced')\n",
    "\n",
    "legend_elements = [\n",
    "    matplotlib.patches.Patch(facecolor='black', label='sequenced'),\n",
    "    matplotlib.lines.Line2D([0], [0], color='black', lw=2, ls='dotted', label='estimated complexity')\n",
    "]\n",
    "ax.legend(handles=legend_elements, loc='best')\n",
    "\n",
    "fig.savefig(\n",
    "    os.path.join(DIR_RESULTS, 'proportion chromatin sequenced.png'),\n",
    "    dpi=300,\n",
    "    bbox_inches='tight'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d79f35-dad7-4b97-86ff-50a87f92c819",
   "metadata": {},
   "source": [
    "## Verify that alignment to combined human-mouse genome correctly distinguished chromatin species\n",
    "\n",
    "Note: I only perform this analysis on paired-end alignments, not on read 1-only alignments.\n",
    "\n",
    "Conclusion: alignment to the combined genome largely identified the correct species.\n",
    "- For >99.9% of read pairs, the alignment to the identified species genome gave an alignment score >= that of aligning to the combined genome, whereas alignment to the other species genome gave worse alignments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c267884-9f5f-45b2-8cde-e851a30059ef",
   "metadata": {},
   "source": [
    "Extract MAPQ and alignment scores (`AS:i:[#]` SAM tag) into table with columns:\n",
    "- aligned species using combined genome\n",
    "- protein target (CTCF or H3K4me3)\n",
    "- R1 MAPQ, combined genome\n",
    "- R2 MAPQ, combined genome\n",
    "- R1 MAPQ, human genome\n",
    "- R2 MAPQ, human genome\n",
    "- R1 MAPQ, mouse genome\n",
    "- R2 MAPQ, mouse genome\n",
    "- R1 AS, combined genome\n",
    "- R2 AS, combined genome\n",
    "- R1 AS, combined genome\n",
    "- R2 AS, combined genome\n",
    "- R1 AS, combined genome\n",
    "- R2 AS, combined genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b1b813-81ca-417a-b345-4f32ffa14062",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_r1_r2(\n",
    "    ref_r1: pysam.AlignedSegment,\n",
    "    ref_r2: pysam.AlignedSegment,\n",
    "    new_r1: pysam.AlignedSegment,\n",
    "    new_r2: pysam.AlignedSegment\n",
    "):\n",
    "    '''\n",
    "    Given the alignment of two read pairs of a query template (one pair as a reference alignment,\n",
    "    one pair as a new alignment), return reorder the reads from the new read pair (if necessary)\n",
    "    to match the order of reads from the reference alignment pair.\n",
    "\n",
    "    Approach\n",
    "    - Compare read sequence\n",
    "    - Compare read alignment orientations\n",
    "    '''\n",
    "    assert all(x.query_name == ref_r1.query_name for x in (ref_r2, new_r1, new_r2))\n",
    "    ref_seqs = (ref_r1.get_forward_sequence(), ref_r2.get_forward_sequence())\n",
    "    new_seqs = (new_r1.get_forward_sequence(), new_r2.get_forward_sequence())\n",
    "    if new_seqs[0] == new_seqs[1]:\n",
    "        # if read 1 and read 2 sequences are the same:\n",
    "        # - if both reads are unmapped, then the order is irrelevant\n",
    "        # - if only 1 read is mapped, then match it to the reference read 1 or read 2 by orientation\n",
    "        # - if both reads are mapped, then directly compare the alignments to the reference reads\n",
    "        if new_r1.is_unmapped and new_r2.is_unmapped:\n",
    "            return (new_r1, new_r2)\n",
    "        elif new_r1.is_unmapped:\n",
    "            if new_r2.is_reverse == ref_r1.is_reverse:\n",
    "                return (new_r2, new_r1)\n",
    "            else:\n",
    "                return (new_r1, new_r2)\n",
    "        elif new_r2.is_unmapped:\n",
    "            if new_r1.is_reverse == ref_r1.is_reverse:\n",
    "                return (new_r1, new_r2)\n",
    "            else:\n",
    "                return (new_r2, new_r1)\n",
    "        else:\n",
    "            if ref_r1.compare(new_r1) == 0:\n",
    "                return (new_r1, new_r2)\n",
    "            elif ref_r1.compare(new_r2) == 0:\n",
    "                return (new_r2, new_r1)\n",
    "            if new_r1.is_reverse and new_r2.is_reverse:\n",
    "                # no implementation yet for this edge case where read 1 and read 2 sequences are identical,\n",
    "                # they are both mapped using the same orientation, and their alignments are different from\n",
    "                # the reference alignments\n",
    "                raise ValueError\n",
    "    if new_seqs == ref_seqs:\n",
    "        # based on matching the read sequences, the ordering of the new read pair was already correct\n",
    "        return new_r1, new_r2\n",
    "    elif (new_seqs[1], new_seqs[0]) == ref_seqs:\n",
    "        # based on matching the read sequences, the ordering of the new read pair was flipped\n",
    "        return new_r2, new_r1\n",
    "    else:\n",
    "        # the code should never get here, which would mean that the new read sequences\n",
    "        # do not match the reference read sequences\n",
    "        raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a929c2cf-fe20-4671-b3e2-1b1345b955b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores = []\n",
    "for target in TARGETS:\n",
    "    for species in SPECIES:\n",
    "        scores = []\n",
    "        # these are all name-sorted BAM files\n",
    "        path_bam_combined = os.path.join(DIR_PROC, f'{target}-PE_{species}_filtered_dedup_sort-name.bam')\n",
    "        path_bam_human = os.path.join(DIR_PROC, f'{target}-PE_{species}_realign-human.bam')\n",
    "        path_bam_mouse = os.path.join(DIR_PROC, f'{target}-PE_{species}_realign-mouse.bam')\n",
    "        with pysam.AlignmentFile(path_bam_combined, 'rb', threads=n_proc) as fc, \\\n",
    "             pysam.AlignmentFile(path_bam_human, 'rb', threads=n_proc) as fh, \\\n",
    "             pysam.AlignmentFile(path_bam_mouse, 'rb', threads=n_proc) as fm:\n",
    "            for (r1c, r2c), (r1h, r2h), (r1m, r2m) in tqdm(zip(\n",
    "                grouper(fc.fetch(until_eof=True), 2, incomplete='strict'),\n",
    "                grouper(fh.fetch(until_eof=True), 2, incomplete='strict'),\n",
    "                grouper(fm.fetch(until_eof=True), 2, incomplete='strict'))):\n",
    "                r1h, r2h = match_r1_r2(r1c, r2c, r1h, r2h)\n",
    "                r1m, r2m = match_r1_r2(r1c, r2c, r1m, r2m)\n",
    "                scores.append(dict(\n",
    "                    MAPQ_combined_R1=r1c.mapping_quality,\n",
    "                    MAPQ_combined_R2=r2c.mapping_quality,\n",
    "                    MAPQ_human_R1=r1h.mapping_quality,\n",
    "                    MAPQ_human_R2=r2h.mapping_quality,\n",
    "                    MAPQ_mouse_R1=r1m.mapping_quality,\n",
    "                    MAPQ_mouse_R2=r2m.mapping_quality,\n",
    "                    AS_combined_R1=r1c.get_tag('AS') if r1c.has_tag('AS') else pd.NA,\n",
    "                    AS_combined_R2=r2c.get_tag('AS') if r2c.has_tag('AS') else pd.NA,\n",
    "                    AS_human_R1=r1h.get_tag('AS') if r1h.has_tag('AS') else pd.NA,\n",
    "                    AS_human_R2=r2h.get_tag('AS') if r2h.has_tag('AS') else pd.NA,\n",
    "                    AS_mouse_R1=r1m.get_tag('AS') if r1m.has_tag('AS') else pd.NA,\n",
    "                    AS_mouse_R2=r2m.get_tag('AS') if r2m.has_tag('AS') else pd.NA,\n",
    "                ))\n",
    "        scores = (\n",
    "            pd.DataFrame(scores)\n",
    "            .astype(pd.Int64Dtype())\n",
    "            .assign(target=target, species=species)\n",
    "            .astype(dict(target=DTYPE_TARGET, species=DTYPE_SPECIES))\n",
    "        )\n",
    "        df_scores.append(scores)\n",
    "df_scores = pd.concat(df_scores, axis=0, ignore_index=True)\n",
    "del scores\n",
    "gc.collect()\n",
    "df_scores.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08415d3-16fc-48c6-bee8-92c2482b2b5e",
   "metadata": {},
   "source": [
    "For read pairs aligned (via the combined genome) to **human chromosomes**, visualize relationship between **alignment scores** on the combined genome versus individual species genomes. Here, I calculate the alignment score for the read pair as the sum of alignment scores of read 1 and read 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65222e2-1598-4832-90bd-7d52f184d375",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(8, 5), sharex=True, sharey=True, constrained_layout=True)\n",
    "mask_human_CTCF = (df_scores['species'] == 'human') & (df_scores['target'] == 'CTCF')\n",
    "mask_human_H3K4me3 = (df_scores['species'] == 'human') & (df_scores['target'] == 'H3K4me3')\n",
    "\n",
    "axs[0, 0].set_title('CTCF ChIP')\n",
    "axs[0, 0] = sns.histplot(\n",
    "    (\n",
    "        df_scores.loc[mask_human_CTCF]\n",
    "        .pipe(lambda df: df.assign(**{\n",
    "            'combined genomes': df['AS_combined_R1'] + df['AS_combined_R2'],\n",
    "            'human genome': df['AS_human_R1'] + df['AS_human_R2']\n",
    "        }))\n",
    "    ),\n",
    "    x='combined genomes',\n",
    "    y='human genome',\n",
    "    bins=30,\n",
    "    discrete=(True, True),\n",
    "    cbar=True, cbar_kws=dict(shrink=1, format=\"%.e\"),\n",
    "    ax=axs[0, 0]\n",
    ")\n",
    "axs[1, 0] = sns.histplot(\n",
    "    (\n",
    "        df_scores.loc[mask_human_CTCF]\n",
    "        .pipe(lambda df: df.assign(**{\n",
    "            'combined genomes': df['AS_combined_R1'] + df['AS_combined_R2'],\n",
    "            'mouse genome': df['AS_mouse_R1'] + df['AS_mouse_R2']\n",
    "        }))\n",
    "    ),\n",
    "    x='combined genomes',\n",
    "    y='mouse genome',\n",
    "    bins=30,\n",
    "    discrete=(True, True),\n",
    "    cbar=True, cbar_kws=dict(shrink=1, format=\"%.e\"),\n",
    "    ax=axs[1, 0]\n",
    ")\n",
    "\n",
    "axs[0, 1].set_title('H3K4me3 ChIP')\n",
    "axs[0, 1] = sns.histplot(\n",
    "    (\n",
    "        df_scores.loc[mask_human_H3K4me3]\n",
    "        .pipe(lambda df: df.assign(**{\n",
    "            'combined genomes': df['AS_combined_R1'] + df['AS_combined_R2'],\n",
    "            'human genome': df['AS_human_R1'] + df['AS_human_R2']\n",
    "        }))\n",
    "    ),\n",
    "    x='combined genomes',\n",
    "    y='human genome',\n",
    "    bins=30,\n",
    "    discrete=(True, True),\n",
    "    cbar=True, cbar_kws=dict(shrink=1, format=\"%.e\"),\n",
    "    ax=axs[0, 1]\n",
    ")\n",
    "axs[1, 1] = sns.histplot(\n",
    "    (\n",
    "        df_scores.loc[mask_human_H3K4me3]\n",
    "        .pipe(lambda df: df.assign(**{\n",
    "            'combined genomes': df['AS_combined_R1'] + df['AS_combined_R2'],\n",
    "            'mouse genome': df['AS_mouse_R1'] + df['AS_mouse_R2']\n",
    "        }))\n",
    "    ),\n",
    "    x='combined genomes',\n",
    "    y='mouse genome',\n",
    "    bins=30,\n",
    "    discrete=(True, True),\n",
    "    cbar=True, cbar_kws=dict(shrink=1, format=\"%.e\"),\n",
    "    ax=axs[1, 1]\n",
    ")\n",
    "\n",
    "fig.suptitle('Distribution of paired-end alignment scores of human-assigned reads')\n",
    "fig.savefig(\n",
    "    os.path.join(DIR_RESULTS, 'paired-end alignment scores, human.png'),\n",
    "    dpi=300,\n",
    "    bbox_inches='tight'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd4f53a-77e1-487d-93a7-d283d44a25cc",
   "metadata": {},
   "source": [
    "For read pairs aligned (via the combined genome) to **mouse chromosomes**, visualize relationship between **alignment scores** on the combined genome versus individual species genomes. Here, I calculate the alignment score for the read pair as the sum of alignment scores of read 1 and read 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c6a04f-c10c-4a2d-adee-26207c291dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(8, 5), sharex=True, sharey=True, constrained_layout=True)\n",
    "mask_mouse_CTCF = (df_scores['species'] == 'mouse') & (df_scores['target'] == 'CTCF')\n",
    "mask_mouse_H3K4me3 = (df_scores['species'] == 'mouse') & (df_scores['target'] == 'H3K4me3')\n",
    "\n",
    "axs[0, 0].set_title('CTCF ChIP')\n",
    "axs[0, 0] = sns.histplot(\n",
    "    (\n",
    "        df_scores.loc[mask_mouse_CTCF]\n",
    "        .pipe(lambda df: df.assign(**{\n",
    "            'combined genomes': df['AS_combined_R1'] + df['AS_combined_R2'],\n",
    "            'human genome': df['AS_human_R1'] + df['AS_human_R2']\n",
    "        }))\n",
    "    ),\n",
    "    x='combined genomes',\n",
    "    y='human genome',\n",
    "    bins=30,\n",
    "    discrete=(True, True),\n",
    "    cbar=True, cbar_kws=dict(shrink=1, format=\"%.e\"),\n",
    "    ax=axs[0, 0]\n",
    ")\n",
    "axs[1, 0] = sns.histplot(\n",
    "    (\n",
    "        df_scores.loc[mask_mouse_CTCF]\n",
    "        .pipe(lambda df: df.assign(**{\n",
    "            'combined genomes': df['AS_combined_R1'] + df['AS_combined_R2'],\n",
    "            'mouse genome': df['AS_mouse_R1'] + df['AS_mouse_R2']\n",
    "        }))\n",
    "    ),\n",
    "    x='combined genomes',\n",
    "    y='mouse genome',\n",
    "    bins=30,\n",
    "    discrete=(True, True),\n",
    "    cbar=True, cbar_kws=dict(shrink=1, format=\"%.e\"),\n",
    "    ax=axs[1, 0]\n",
    ")\n",
    "\n",
    "axs[0, 1].set_title('H3K4me3 ChIP')\n",
    "axs[0, 1] = sns.histplot(\n",
    "    (\n",
    "        df_scores.loc[mask_mouse_H3K4me3]\n",
    "        .pipe(lambda df: df.assign(**{\n",
    "            'combined genomes': df['AS_combined_R1'] + df['AS_combined_R2'],\n",
    "            'human genome': df['AS_human_R1'] + df['AS_human_R2']\n",
    "        }))\n",
    "    ),\n",
    "    x='combined genomes',\n",
    "    y='human genome',\n",
    "    bins=30,\n",
    "    discrete=(True, True),\n",
    "    cbar=True, cbar_kws=dict(shrink=1, format=\"%.e\"),\n",
    "    ax=axs[0, 1]\n",
    ")\n",
    "axs[1, 1] = sns.histplot(\n",
    "    (\n",
    "        df_scores.loc[mask_mouse_H3K4me3]\n",
    "        .pipe(lambda df: df.assign(**{\n",
    "            'combined genomes': df['AS_combined_R1'] + df['AS_combined_R2'],\n",
    "            'mouse genome': df['AS_mouse_R1'] + df['AS_mouse_R2']\n",
    "        }))\n",
    "    ),\n",
    "    x='combined genomes',\n",
    "    y='mouse genome',\n",
    "    bins=30,\n",
    "    discrete=(True, True),\n",
    "    cbar=True, cbar_kws=dict(shrink=1, format=\"%.e\"),\n",
    "    ax=axs[1, 1]\n",
    ")\n",
    "\n",
    "fig.suptitle('Distribution of paired-end alignment scores of mouse-assigned reads')\n",
    "fig.savefig(\n",
    "    os.path.join(DIR_RESULTS, 'paired-end alignment scores, mouse.png'),\n",
    "    dpi=300,\n",
    "    bbox_inches='tight'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f63073-1b49-45f3-8d1c-0d471ef7f871",
   "metadata": {},
   "source": [
    "For read pairs aligned (via the combined genome) to **human chromosomes**, visualize relationship between **mapping quality (MAPQ) scores** on the combined genome versus individual species genomes. Here, I calculate the mapping quality score for the read pair as the sum of mapping quality scores of read 1 and read 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b693bfbb-bc2b-4cb4-869c-f8519ecdc451",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(8, 5), sharex=True, sharey=True, constrained_layout=True)\n",
    "mask_human_CTCF = (df_scores['species'] == 'human') & (df_scores['target'] == 'CTCF')\n",
    "mask_human_H3K4me3 = (df_scores['species'] == 'human') & (df_scores['target'] == 'H3K4me3')\n",
    "\n",
    "axs[0, 0].set_title('CTCF ChIP')\n",
    "axs[0, 0] = sns.histplot(\n",
    "    (\n",
    "        df_scores.loc[mask_human_CTCF]\n",
    "        .pipe(lambda df: df.assign(**{\n",
    "            'combined genomes': df['MAPQ_combined_R1'] + df['MAPQ_combined_R2'],\n",
    "            'human genome': df['MAPQ_human_R1'] + df['MAPQ_human_R2']\n",
    "        }))\n",
    "    ),\n",
    "    x='combined genomes',\n",
    "    y='human genome',\n",
    "    bins=30,\n",
    "    discrete=(True, True),\n",
    "    cbar=True, cbar_kws=dict(shrink=1, format=\"%.e\"),\n",
    "    ax=axs[0, 0]\n",
    ")\n",
    "axs[1, 0] = sns.histplot(\n",
    "    (\n",
    "        df_scores.loc[mask_human_CTCF]\n",
    "        .pipe(lambda df: df.assign(**{\n",
    "            'combined genomes': df['MAPQ_combined_R1'] + df['MAPQ_combined_R2'],\n",
    "            'mouse genome': df['MAPQ_mouse_R1'] + df['MAPQ_mouse_R2']\n",
    "        }))\n",
    "    ),\n",
    "    x='combined genomes',\n",
    "    y='mouse genome',\n",
    "    bins=30,\n",
    "    discrete=(True, True),\n",
    "    cbar=True, cbar_kws=dict(shrink=1, format=\"%.e\"),\n",
    "    ax=axs[1, 0]\n",
    ")\n",
    "\n",
    "axs[0, 1].set_title('H3K4me3 ChIP')\n",
    "axs[0, 1] = sns.histplot(\n",
    "    (\n",
    "        df_scores.loc[mask_human_H3K4me3]\n",
    "        .pipe(lambda df: df.assign(**{\n",
    "            'combined genomes': df['MAPQ_combined_R1'] + df['MAPQ_combined_R2'],\n",
    "            'human genome': df['MAPQ_human_R1'] + df['MAPQ_human_R2']\n",
    "        }))\n",
    "    ),\n",
    "    x='combined genomes',\n",
    "    y='human genome',\n",
    "    bins=30,\n",
    "    discrete=(True, True),\n",
    "    cbar=True, cbar_kws=dict(shrink=1, format=\"%.e\"),\n",
    "    ax=axs[0, 1]\n",
    ")\n",
    "axs[1, 1] = sns.histplot(\n",
    "    (\n",
    "        df_scores.loc[mask_human_H3K4me3]\n",
    "        .pipe(lambda df: df.assign(**{\n",
    "            'combined genomes': df['MAPQ_combined_R1'] + df['MAPQ_combined_R2'],\n",
    "            'mouse genome': df['MAPQ_mouse_R1'] + df['MAPQ_mouse_R2']\n",
    "        }))\n",
    "    ),\n",
    "    x='combined genomes',\n",
    "    y='mouse genome',\n",
    "    bins=30,\n",
    "    discrete=(True, True),\n",
    "    cbar=True, cbar_kws=dict(shrink=1, format=\"%.e\"),\n",
    "    ax=axs[1, 1]\n",
    ")\n",
    "\n",
    "fig.suptitle('Distribution of paired-end MAPQ scores of human-assigned reads')\n",
    "fig.savefig(\n",
    "    os.path.join(DIR_RESULTS, 'paired-end MAPQ scores, human.png'),\n",
    "    dpi=300,\n",
    "    bbox_inches='tight'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60365052-05e3-4a44-88e7-a5fae0333982",
   "metadata": {},
   "source": [
    "For read pairs aligned (via the combined genome) to **mouse chromosomes**, visualize relationship between **mapping quality (MAPQ) scores** on the combined genome versus individual species genomes. Here, I calculate the mapping quality score for the read pair as the sum of mapping quality scores of read 1 and read 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d79790-d0be-467f-8306-1bcb6a127d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(8, 5), sharex=True, sharey=True, constrained_layout=True)\n",
    "mask_mouse_CTCF = (df_scores['species'] == 'mouse') & (df_scores['target'] == 'CTCF')\n",
    "mask_mouse_H3K4me3 = (df_scores['species'] == 'mouse') & (df_scores['target'] == 'H3K4me3')\n",
    "\n",
    "axs[0, 0].set_title('CTCF ChIP')\n",
    "axs[0, 0] = sns.histplot(\n",
    "    (\n",
    "        df_scores.loc[mask_mouse_CTCF]\n",
    "        .pipe(lambda df: df.assign(**{\n",
    "            'combined genomes': df['MAPQ_combined_R1'] + df['MAPQ_combined_R2'],\n",
    "            'human genome': df['MAPQ_human_R1'] + df['MAPQ_human_R2']\n",
    "        }))\n",
    "    ),\n",
    "    x='combined genomes',\n",
    "    y='human genome',\n",
    "    bins=30,\n",
    "    discrete=(True, True),\n",
    "    cbar=True, cbar_kws=dict(shrink=1, format=\"%.e\"),\n",
    "    ax=axs[0, 0]\n",
    ")\n",
    "axs[1, 0] = sns.histplot(\n",
    "    (\n",
    "        df_scores.loc[mask_mouse_CTCF]\n",
    "        .pipe(lambda df: df.assign(**{\n",
    "            'combined genomes': df['MAPQ_combined_R1'] + df['MAPQ_combined_R2'],\n",
    "            'mouse genome': df['MAPQ_mouse_R1'] + df['MAPQ_mouse_R2']\n",
    "        }))\n",
    "    ),\n",
    "    x='combined genomes',\n",
    "    y='mouse genome',\n",
    "    bins=30,\n",
    "    discrete=(True, True),\n",
    "    cbar=True, cbar_kws=dict(shrink=1, format=\"%.e\"),\n",
    "    ax=axs[1, 0]\n",
    ")\n",
    "\n",
    "axs[0, 1].set_title('H3K4me3 ChIP')\n",
    "axs[0, 1] = sns.histplot(\n",
    "    (\n",
    "        df_scores.loc[mask_mouse_H3K4me3]\n",
    "        .pipe(lambda df: df.assign(**{\n",
    "            'combined genomes': df['MAPQ_combined_R1'] + df['MAPQ_combined_R2'],\n",
    "            'human genome': df['MAPQ_human_R1'] + df['MAPQ_human_R2']\n",
    "        }))\n",
    "    ),\n",
    "    x='combined genomes',\n",
    "    y='human genome',\n",
    "    bins=30,\n",
    "    discrete=(True, True),\n",
    "    cbar=True, cbar_kws=dict(shrink=1, format=\"%.e\"),\n",
    "    ax=axs[0, 1]\n",
    ")\n",
    "axs[1, 1] = sns.histplot(\n",
    "    (\n",
    "        df_scores.loc[mask_mouse_H3K4me3]\n",
    "        .pipe(lambda df: df.assign(**{\n",
    "            'combined genomes': df['MAPQ_combined_R1'] + df['MAPQ_combined_R2'],\n",
    "            'mouse genome': df['MAPQ_mouse_R1'] + df['MAPQ_mouse_R2']\n",
    "        }))\n",
    "    ),\n",
    "    x='combined genomes',\n",
    "    y='mouse genome',\n",
    "    bins=30,\n",
    "    discrete=(True, True),\n",
    "    cbar=True, cbar_kws=dict(shrink=1, format=\"%.e\"),\n",
    "    ax=axs[1, 1]\n",
    ")\n",
    "\n",
    "fig.suptitle('Distribution of paired-end MAPQ scores of mouse-assigned reads')\n",
    "fig.savefig(\n",
    "    os.path.join(DIR_RESULTS, 'paired-end MAPQ scores, mouse.png'),\n",
    "    dpi=300,\n",
    "    bbox_inches='tight'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0dcf76-11af-4294-ac4c-946c2d5a1ed1",
   "metadata": {},
   "source": [
    "Proportion of read pairs with lower alignment scores (summed across read 1 and read 2) when aligned to their assigned genome than aligned to the combined genome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f19e5c-d6fc-443b-9f1f-743bda285628",
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_lower_score = []\n",
    "for species in SPECIES:\n",
    "    mask_denom = (df_scores['species'] == species)\n",
    "    mask_num = mask_denom & \\\n",
    "        ((df_scores[f'AS_{species}_R1'] + df_scores[f'AS_{species}_R2'] < df_scores['AS_combined_R1'] + df_scores['AS_combined_R2']) |\n",
    "         (df_scores[f'AS_{species}_R1'].isna() | df_scores[f'AS_{species}_R2'].isna()))\n",
    "    prop_lower_score.append({'species': species, 'lower score count': mask_num.sum(), 'total': mask_denom.sum(), 'new genome': species})\n",
    "    species2 = 'mouse' if species == 'human' else 'human'\n",
    "    mask_num2 = mask_denom & \\\n",
    "        ((df_scores[f'AS_{species2}_R1'] + df_scores[f'AS_{species2}_R2'] < df_scores['AS_combined_R1'] + df_scores['AS_combined_R2']) |\n",
    "         (df_scores[f'AS_{species2}_R1'].isna() | df_scores[f'AS_{species2}_R2'].isna()))\n",
    "    prop_lower_score.append({'species': species, 'lower score count': mask_num2.sum(), 'total': mask_denom.sum(), 'new genome': species2})\n",
    "prop_lower_score = pd.DataFrame(prop_lower_score)\n",
    "prop_lower_score['proportion'] = prop_lower_score['lower score count'] / prop_lower_score['total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf7eee2-d462-4492-860c-2b2cccf0a5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(6, 5), sharey=True, constrained_layout=True)\n",
    "sns.barplot(\n",
    "    prop_lower_score.loc[prop_lower_score['species'] == prop_lower_score['new genome']],\n",
    "    x='species',\n",
    "    y='proportion',\n",
    "    ax=axs[0]\n",
    ")\n",
    "axs[0].set_ylabel('\\n'.join((\n",
    "    'proportion of read pairs with lower alignment scores',\n",
    "    'to species-specific genome than to combined genome'\n",
    ")))\n",
    "axs[0].set_xlabel('species assigned\\nand used for realignment')\n",
    "\n",
    "sns.barplot(\n",
    "    prop_lower_score.loc[prop_lower_score['species'] != prop_lower_score['new genome']],\n",
    "    x='species',\n",
    "    y='proportion',\n",
    "    ax=axs[1]\n",
    ")\n",
    "axs[1].set_xlabel('species used for realignment\\n(opposite assigned)')\n",
    "\n",
    "for ax in axs:\n",
    "    for container in ax.containers:\n",
    "        ax.bar_label(container, fmt='{:.3%}')\n",
    "\n",
    "fig.savefig(\n",
    "    os.path.join(DIR_RESULTS, 'proportion of read pairs with lower alignment scores.png'),\n",
    "    dpi=300,\n",
    "    bbox_inches='tight'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e95f88-8a55-4915-9b3c-8ebc4b55c446",
   "metadata": {},
   "source": [
    "**For a read pair that Bowtie 2 aligned to a chromosome of species X in the combined genome, why would the read pair yield a lower alignment score when aligned directly to the genome of species X?**\n",
    "\n",
    "If the read pair truly came from species X, one possibility is that when read seeds were aligned to the combined genome, the number of seed hits exceeded the \"repetitive seeds\" threshold, prompting Bowtie 2 to use different (perhaps more optimal) seeds that eventually led to a better alignment to the species X genome. The initial seeds never exceeded the \"repetitive seeds\" threshold when aligned only against the species X genome, such that the more optimal seeds were never used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5cfa6a-4e9b-4c73-af8c-f760c4d5625a",
   "metadata": {},
   "source": [
    "## Molecules per bead"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28903cf5-5de4-4b78-9544-8389aa33ed8f",
   "metadata": {},
   "source": [
    "### Beads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03423d3f-84ec-4bcc-a486-83b4497c09b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_bead_counts = os.path.join(DIR_PROC, 'bead_counts.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d316d5-537f-4531-887a-c50be3335f16",
   "metadata": {},
   "source": [
    "Total number of bead barcodes identified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b183b5d-7a19-4c10-8540-160659d2a723",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unpigz -c {os.path.join(DIR_PROC, 'mapping_bead-barcode.tsv.gz')} | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2555748-189d-436f-b83d-f2762c4f7cb8",
   "metadata": {},
   "source": [
    "Number of beads with oligos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb65b2d-e1cb-4809-9622-d1415162fcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df_beads' not in locals().keys() or reprocess:\n",
    "    display(len(df_oligos))\n",
    "else:\n",
    "    display(((df_beads['human oligo'] > 0) | (df_beads['mouse oligo'] > 0)).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4329a610-6539-4999-9814-fcd2f8de322c",
   "metadata": {},
   "source": [
    "Number of beads with aligned, species-specific, non-blacklisted chromatin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658211d1-dab1-49f0-ad21-35a4d5382a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_chromatin['bead'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f93bd79-b35a-4cf7-a123-22cab6142ea3",
   "metadata": {},
   "source": [
    "Create table of oligo and chromatin counts for each bead.\n",
    "- The chromatin counts are deduplicated.\n",
    "- The oligo counts are not, since they do not have UMIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047c3cf5-cc7e-402a-91ba-86b5bb0450a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(path_bead_counts) or reprocess:\n",
    "    df_chromatin_counts = (\n",
    "        df_chromatin\n",
    "        .loc[df_chromatin['alignment_type'] == 'PE']\n",
    "        .groupby(['bead', 'target', 'species'], observed=True)\n",
    "        .size()\n",
    "        .rename('count')\n",
    "        .reset_index()\n",
    "        .pivot(index='bead', columns=['species', 'target'], values='count')\n",
    "        .fillna(0)\n",
    "        .astype(int)\n",
    "    )\n",
    "    df_chromatin_counts.columns = [' '.join(col).strip() for col in df_chromatin_counts.columns.values]\n",
    "\n",
    "    df_beads = (\n",
    "        df_oligos\n",
    "        .rename(columns={'human': 'human oligo', 'mouse': 'mouse oligo'})\n",
    "        .join(df_chromatin_counts, how='outer')\n",
    "        .fillna(0)\n",
    "        .astype(np.int32)\n",
    "    )\n",
    "\n",
    "    # because of its sparsity, saving this DataFrame in a compressed .npz format saves significant space\n",
    "    np.savez_compressed(\n",
    "        path_bead_counts,\n",
    "        index=df_beads.index.values,\n",
    "        values=df_beads.values\n",
    "    )\n",
    "else:\n",
    "    df_beads = pd.DataFrame(\n",
    "        data=np.load(path_bead_counts)['values'],\n",
    "        index=pd.Index(np.load(path_bead_counts)['index'], name='bead'),\n",
    "        columns=['human oligo', 'mouse oligo', 'human H3K4me3', 'mouse H3K4me3', 'human CTCF', 'mouse CTCF'],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb4a199-2e71-4f17-a1b0-2e7690157394",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_beads.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5473b0f3-54e1-4e0a-9e8d-47dab119da9c",
   "metadata": {},
   "source": [
    "Sparsity (proportion of values that are zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c137b3-714e-4bb0-8b9f-b58f891199ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_beads.values == 0).sum().sum() / (15519769 * 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4fa9bf-c95c-4d6c-b7bb-0586af3dc411",
   "metadata": {},
   "source": [
    "### Bivariate distribution of oligos and chromatin per bead"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b83bfd-9550-4435-84b9-bfe2b6a90ebf",
   "metadata": {},
   "source": [
    "### Chromatin per bead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17a4372-2c37-499a-966e-9cdf11bd4082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index = bead\n",
    "# columns = human (proportion), mouse (proportion), total (count), chromatin molecules per bead (binned count)\n",
    "df_chromatin_species_per_bead = (\n",
    "    df_chromatin\n",
    "    .loc[df_chromatin['alignment_type'] == 'PE']\n",
    "    .groupby(['bead', 'species'], observed=True)\n",
    "    .size()\n",
    "    .rename('count')\n",
    "    .reset_index()\n",
    "    .pivot(index='bead', values='count', columns='species')\n",
    "    .fillna(0)\n",
    "    .astype(int)\n",
    "    .pipe(lambda df: df.assign(total=df['human'] + df['mouse']))\n",
    "    .pipe(lambda df: df.assign(human=df['human']/df['total'], mouse=df['mouse']/df['total']))\n",
    ")\n",
    "\n",
    "df_chromatin_species_per_bead = df_chromatin_species_per_bead.assign(**{\n",
    "    'chromatin molecules per bead': pd.cut(\n",
    "        df_chromatin_species_per_bead['total'],\n",
    "        bins=[0, 1, 4, 16, 64, 256, 1024, np.inf],\n",
    "        right=True,\n",
    "        labels=['1', '2-4', '5-16', '17-64', '65-256', '257-1024', '1025+']\n",
    "    )})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21805d8c-3e36-4640-885d-bb04e0309893",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(12, 6), sharex=True, constrained_layout=True)\n",
    "sns.ecdfplot(df_chromatin_species_per_bead, x='total', log_scale=True, ax=axs[0, 0])\n",
    "axs[0, 0].set_ylabel('proportion of beads')\n",
    "sns.ecdfplot(df_chromatin_species_per_bead, x='total', weights='total', log_scale=True, ax=axs[0, 1])\n",
    "axs[0, 1].set_ylabel('proportion of chromatin reads')\n",
    "sns.histplot(df_chromatin_species_per_bead, x='total', bins=40, log_scale=(True, True), ax=axs[1, 0])\n",
    "axs[1, 0].set_ylabel('number of beads')\n",
    "sns.histplot(df_chromatin_species_per_bead, x='total', weights='total', bins=40, log_scale=(True, True), ax=axs[1, 1])\n",
    "axs[1, 1].set_ylabel('number of chromatin reads')\n",
    "axs[1, 0].set_xlabel(None)\n",
    "fig.supxlabel('number of chromatin molecules per bead')\n",
    "fig.suptitle('Distribution of chromatin molecules per bead\\n(on chromatin-containing beads)')\n",
    "fig.savefig(\n",
    "    os.path.join(DIR_RESULTS, 'chromatin molecules per bead.png'),\n",
    "    dpi=300,\n",
    "    bbox_inches='tight'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4733aa59-52f6-4c20-8539-fdd587b60213",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, sharex=True, constrained_layout=True)\n",
    "sns.histplot(\n",
    "    df_chromatin_species_per_bead.loc[df_chromatin_species_per_bead['total'] > 1]\n",
    "    .pipe(lambda df: df.assign(**{\n",
    "        'chromatin molecules per bead': df['chromatin molecules per bead'].cat.remove_categories('1')\n",
    "    })),\n",
    "    x='human',\n",
    "    stat='proportion',\n",
    "    multiple='stack',\n",
    "    common_norm=False,\n",
    "    hue='chromatin molecules per bead',\n",
    "    palette='viridis',\n",
    "    ax=axs[0]\n",
    ")\n",
    "sns.ecdfplot(\n",
    "    df_chromatin_species_per_bead.loc[df_chromatin_species_per_bead['total'] > 1]\n",
    "    .pipe(lambda df: df.assign(**{\n",
    "        'chromatin molecules per bead': df['chromatin molecules per bead'].cat.remove_categories('1')\n",
    "    })),\n",
    "    x='human',\n",
    "    hue='chromatin molecules per bead',\n",
    "    palette='viridis',\n",
    "    legend=False,\n",
    "    ax=axs[1]\n",
    ")\n",
    "axs[0].set_ylabel('proportion of beads')\n",
    "axs[1].set_ylabel('proportion of beads')\n",
    "axs[1].set_xlabel('proportion of chromatin molecules on a bead\\nfrom human genome (vs. mouse genome)')\n",
    "axs[0].set_title('Distribution of chromatin species on beads')\n",
    "fig.savefig(\n",
    "    os.path.join(DIR_RESULTS, 'chromatin species on beads.png'),\n",
    "    dpi=300,\n",
    "    bbox_inches='tight'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6118b7-db50-4530-95ae-bac665c2d3ba",
   "metadata": {},
   "source": [
    "#### CTCF vs. H3K4me3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4855a1-a30b-483d-90ba-61f85c3b9ecb",
   "metadata": {},
   "source": [
    "#### Human vs. mouse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff4872a-1f0f-4279-96b6-6f3f8c4cd97f",
   "metadata": {},
   "source": [
    "### Oligos per bead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c072a9-0daa-42dd-a166-3fd48f255a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oligo_species_per_bead = (\n",
    "    df_oligos\n",
    "    .assign(total=df_oligos.sum(axis=1))\n",
    "    .pipe(lambda df: df.assign(**{\n",
    "        'human': df['human'] / df['total'],\n",
    "        'mouse': df['mouse'] / df['total']\n",
    "    }))\n",
    ")\n",
    "\n",
    "df_oligo_species_per_bead = df_oligo_species_per_bead.assign(**{\n",
    "    'oligo molecules per bead': pd.cut(\n",
    "        df_oligo_species_per_bead['total'],\n",
    "        bins=[0, 1, 4, 16, 64, 256, 1024, np.inf],\n",
    "        right=True,\n",
    "        labels=['1', '2-4', '5-16', '17-64', '65-256', '257-1024', '1025+']\n",
    "    )})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ee50a4-2569-4451-9275-b54f1b467fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(12, 6), sharex=True, constrained_layout=True)\n",
    "\n",
    "df_oligos_long = (\n",
    "    df_oligos\n",
    "    .assign(total=df_oligos.sum(axis=1))\n",
    "    .melt(ignore_index=False, var_name='oligo species', value_name='count')\n",
    ")\n",
    "\n",
    "xscale = matplotlib.scale.SymmetricalLogScale(None, base=10, linthresh=1, linscale=0.1)\n",
    "symlog_transform = xscale.get_transform()\n",
    "symlog_transform_inverse = symlog_transform.inverted()\n",
    "bins = symlog_transform_inverse.transform(np.linspace(\n",
    "    symlog_transform.transform(-0.6),\n",
    "    symlog_transform.transform(df_oligos_long['count'].max()),\n",
    "    30\n",
    "))\n",
    "\n",
    "# re-implementing the == operator of Numpy array to bypass a seaborn bug in sns.histplot\n",
    "# when using weights and user-specific bins\n",
    "# https://github.com/mwaskom/seaborn/issues/3801\n",
    "class myclass(np.ndarray):\n",
    "    def __eq__(self, other):\n",
    "        if type(other) is str and other == 'auto':\n",
    "            return False\n",
    "        else:\n",
    "            return super().__eq__(other)\n",
    "bins = myclass(bins.shape, buffer=bins, dtype=float)\n",
    "\n",
    "sns.ecdfplot(\n",
    "    df_oligos_long,\n",
    "    x='count',\n",
    "    hue='oligo species',\n",
    "    ax=axs[0, 0]\n",
    ")\n",
    "axs[0, 0].set_ylabel('proportion of beads')\n",
    "sns.move_legend(axs[0, 0], loc='lower right')\n",
    "\n",
    "sns.ecdfplot(\n",
    "    df_oligos_long,\n",
    "    x='count',\n",
    "    weights='count',\n",
    "    hue='oligo species',\n",
    "    ax=axs[0, 1]\n",
    ")\n",
    "axs[0, 1].set_ylabel('proportion of oligo reads')\n",
    "sns.move_legend(axs[0, 1], loc='lower right')\n",
    "\n",
    "sns.histplot(\n",
    "    df_oligos_long,\n",
    "    x='count',\n",
    "    hue='oligo species',\n",
    "    bins=bins,\n",
    "    alpha=0.3,\n",
    "    ax=axs[1, 0]\n",
    ")\n",
    "axs[1, 0].set_yscale('symlog', linthresh=10)\n",
    "axs[1, 0].set_ylabel('number of beads')\n",
    "axs[1, 0].set_xlabel(None)\n",
    "sns.move_legend(axs[1, 0], loc='upper right')\n",
    "\n",
    "sns.histplot(\n",
    "    df_oligos_long,\n",
    "    x='count',\n",
    "    weights='count',\n",
    "    hue='oligo species',\n",
    "    bins=bins,\n",
    "    alpha=0.3,\n",
    "    ax=axs[1, 1]\n",
    ")\n",
    "axs[1, 1].set_xscale(xscale)\n",
    "axs[1, 1].set_xlim(-1, None)\n",
    "axs[1, 1].set_yscale('symlog', linthresh=10)\n",
    "axs[1, 1].set_ylabel('number of oligo reads')\n",
    "sns.move_legend(axs[1, 1], loc='upper right')\n",
    "\n",
    "fig.supxlabel('number of oligo molecules per bead')\n",
    "fig.suptitle('Distribution of oligo molecules per bead\\n(on oligo-containing beads)')\n",
    "fig.savefig(\n",
    "    os.path.join(DIR_RESULTS, 'oligo molecules per bead.png'),\n",
    "    dpi=300,\n",
    "    bbox_inches='tight'\n",
    ")\n",
    "\n",
    "del df_oligos_long\n",
    "gc.collect()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f6338e-b4d7-4675-9a13-b6a979a14ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, sharex=True, constrained_layout=True)\n",
    "sns.histplot(\n",
    "    df_oligo_species_per_bead.loc[df_oligo_species_per_bead['total'] > 1]\n",
    "    .pipe(lambda df: df.assign(**{\n",
    "        'oligo molecules per bead': df['oligo molecules per bead'].cat.remove_categories('1')\n",
    "    })),\n",
    "    x='human',\n",
    "    stat='proportion',\n",
    "    multiple='stack',\n",
    "    common_norm=False,\n",
    "    hue='oligo molecules per bead',\n",
    "    palette='viridis',\n",
    "    ax=axs[0]\n",
    ")\n",
    "sns.ecdfplot(\n",
    "    df_oligo_species_per_bead.loc[df_oligo_species_per_bead['total'] > 1]\n",
    "    .pipe(lambda df: df.assign(**{\n",
    "        'oligo molecules per bead': df['oligo molecules per bead'].cat.remove_categories('1')\n",
    "    })),\n",
    "    x='human',\n",
    "    hue='oligo molecules per bead',\n",
    "    palette='viridis',\n",
    "    legend=False,\n",
    "    ax=axs[1]\n",
    ")\n",
    "axs[0].set_ylabel('proportion of beads')\n",
    "axs[1].set_ylabel('proportion of beads')\n",
    "axs[1].set_xlabel('proportion of oligo molecules on a bead\\nfrom human genome (vs. mouse genome)')\n",
    "axs[0].set_title('Distribution of oligo species on beads with >= 2 oligos')\n",
    "fig.savefig(\n",
    "    os.path.join(DIR_RESULTS, 'oligo species on beads.png'),\n",
    "    dpi=300,\n",
    "    bbox_inches='tight'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fa6eb3-0a12-4f72-9bfd-13beb6fabfa2",
   "metadata": {},
   "source": [
    "## Mixing analysis\n",
    "\n",
    "Note: only performed using paired-end alignments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b24423-d8fb-46d0-b77e-8c44f92bf1b4",
   "metadata": {},
   "source": [
    "### Beads with only 1 chromatin species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f9147b-843b-4996-ad7f-5aa579fb94da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index = bead\n",
    "# columns = chromatin species, chromatin count, human oligo count, mouse oligo count\n",
    "df_single_chromatin_species_beads = (\n",
    "    df_chromatin.loc[df_chromatin['alignment_type'] == 'PE', ['bead', 'species']]\n",
    "    .groupby('bead')\n",
    "    .filter(lambda g: len(g['species'].unique()) == 1)\n",
    "    .groupby('bead')\n",
    "    ['species'].agg(['first', 'size'])\n",
    "    .rename(columns={'size': 'chromatin count', 'first': 'chromatin species'})\n",
    "    .merge(df_oligos, how='left', left_index=True, right_index=True)\n",
    "    .fillna({'human': 0, 'mouse': 0})\n",
    "    .astype({'human': int, 'mouse': int})\n",
    "    .rename(columns={'human': 'human oligo count', 'mouse': 'mouse oligo count'})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62d568d-4ebd-4e0b-ab31-28bf4ba8014b",
   "metadata": {},
   "source": [
    "Oligo counts for single-chromatin-species beads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3bc70f-4243-42b8-adf3-2c9c65602f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "ax = sns.scatterplot(\n",
    "    (\n",
    "        df_single_chromatin_species_beads\n",
    "        .groupby(['chromatin species', 'human oligo count', 'mouse oligo count'], observed=True)\n",
    "        .size()\n",
    "        .rename('bead count')\n",
    "        .reset_index()\n",
    "        .rename(columns={'chromatin species': 'bead chromatin species'})\n",
    "        # x-jitter human oligo counts for visualization\n",
    "        .pipe(lambda df: df.assign(**{\n",
    "            'human oligo count': df['human oligo count'] + 0.2 * (df['bead chromatin species'] == 'human').astype(float) - 0.1\n",
    "        }))\n",
    "    ),\n",
    "    x='human oligo count',\n",
    "    y='mouse oligo count',\n",
    "    hue='bead chromatin species',\n",
    "    size='bead count',\n",
    "    sizes=(10, 50),\n",
    "    ax=ax\n",
    ")\n",
    "# ax.set_aspect('equal')\n",
    "ax.set_title('Oligo counts for single-chromatin-species beads')\n",
    "ax.xaxis.set_major_locator(matplotlib.ticker.MaxNLocator(integer=True))\n",
    "sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 1))\n",
    "ax.figure.savefig(\n",
    "    os.path.join(DIR_RESULTS, 'single-chromatin-species-beads_mixing.png'),\n",
    "    bbox_inches='tight',\n",
    "    dpi=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dfa892-3ac3-41c3-bfa4-e351abcb8c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(\n",
    "    (\n",
    "        df_single_chromatin_species_beads\n",
    "        .groupby(['chromatin species', 'human oligo count', 'mouse oligo count'], observed=True)\n",
    "        .size()\n",
    "        .rename('bead count')\n",
    "        .reset_index()\n",
    "        .rename(columns={'chromatin species': 'bead chromatin species'})\n",
    "        # remove beads with no oligos\n",
    "        .pipe(lambda df: df.loc[(df['human oligo count'] + df['mouse oligo count']) > 0])\n",
    "        # x-jitter human oligo counts for visualization\n",
    "        .pipe(lambda df: df.assign(**{\n",
    "            'human oligo count': df['human oligo count'] + 0.2 * (df['bead chromatin species'] == 'human').astype(float) - 0.1\n",
    "        }))\n",
    "    ),\n",
    "    x='human oligo count',\n",
    "    y='mouse oligo count',\n",
    "    hue='bead chromatin species',\n",
    "    size='bead count',\n",
    "    sizes=(10, 150)\n",
    ")\n",
    "ax.set_xlim((-0.5, 10.5))\n",
    "ax.set_ylim((-0.5, 10.5))\n",
    "ax.set_aspect('equal')\n",
    "ax.set_title('Oligo counts for single-chromatin-species beads')\n",
    "ax.xaxis.set_major_locator(matplotlib.ticker.MaxNLocator(integer=True))\n",
    "sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 1))\n",
    "ax.figure.savefig(\n",
    "    os.path.join(DIR_RESULTS, 'single-chromatin-species-beads_mixing-zoom.png'),\n",
    "    bbox_inches='tight',\n",
    "    dpi=300\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea6c357-ec7c-4b2e-94ec-df2e6f4feda3",
   "metadata": {},
   "source": [
    "Distribution of oligos on beads with single chromatin species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0654aa-33fe-4812-aa8d-292560086fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 4), constrained_layout=True)\n",
    "for i, species in enumerate(SPECIES):\n",
    "    axs[i].set_title(f'beads with {species}-only chromatin')\n",
    "    sns.barplot(\n",
    "        # bead, chromatin count, oligo count, oligo species\n",
    "        (\n",
    "            df_single_chromatin_species_beads\n",
    "            .loc[df_single_chromatin_species_beads['chromatin species'] == species]\n",
    "            .reset_index()\n",
    "            .rename(columns={'human oligo count': 'human', 'mouse oligo count': 'mouse'})\n",
    "            .melt(\n",
    "                id_vars=['bead', 'chromatin count'],\n",
    "                value_vars=['human', 'mouse'],\n",
    "                var_name='oligo species',\n",
    "                value_name='oligo count'\n",
    "            )\n",
    "        ),\n",
    "        x='chromatin count',\n",
    "        y='oligo count',\n",
    "        hue='oligo species',\n",
    "        errorbar='se',\n",
    "        ax=axs[i]\n",
    "    )\n",
    "fig.savefig(\n",
    "    os.path.join(DIR_RESULTS, 'single-chromatin-species-beads_oligo-counts.png'),\n",
    "    bbox_inches='tight',\n",
    "    dpi=300\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc1e322-1eae-4b71-a2ed-4fc25668d51c",
   "metadata": {},
   "source": [
    "### Beads with only 1 chromatin species and 1 chromatin target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129c9fdc-7e92-4651-80e1-e80616ac829a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_single_chromatin_species_target_beads = (\n",
    "    df_chromatin.loc[df_chromatin['alignment_type'] == 'PE', ['bead', 'species', 'target']]\n",
    "    .groupby('bead')\n",
    "    .filter(lambda g: (len(g['species'].unique()) == 1) and (len(g['target'].unique()) == 1))\n",
    "    .rename(columns={'species': 'chromatin species'})\n",
    "    .groupby(['bead', 'chromatin species', 'target'], observed=True)\n",
    "    .size()\n",
    "    .rename('chromatin count')\n",
    "    .reset_index()\n",
    "    .merge(df_oligos, how='left', left_on='bead', right_index=True)\n",
    "    .fillna({'human': 0, 'mouse': 0})\n",
    "    .astype({'human': int, 'mouse': int})\n",
    "    .rename(columns={'human': 'human oligo count', 'mouse': 'mouse oligo count'})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614d7f44-9b12-4b7c-930d-0e817a68f446",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oligos['human']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013378a6-7895-4228-a4ec-cf0271bf5ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6), sharex=True, sharey=True, constrained_layout=True)\n",
    "axs[0] = sns.scatterplot(\n",
    "    (\n",
    "        df_single_chromatin_species_target_beads\n",
    "        .loc[df_single_chromatin_species_target_beads['target'] == 'CTCF']\n",
    "        .groupby(['chromatin species', 'human oligo count', 'mouse oligo count'], observed=True)\n",
    "        .size()\n",
    "        .rename('bead count')\n",
    "        .reset_index()\n",
    "        .rename(columns={'chromatin species': 'bead chromatin species'})\n",
    "        # x-jitter human oligo counts for visualization\n",
    "        .pipe(lambda df: df.assign(**{\n",
    "            'human oligo count': df['human oligo count'] + 0.2 * (df['bead chromatin species'] == 'human').astype(float) - 0.1\n",
    "        }))\n",
    "    ),\n",
    "    x='human oligo count',\n",
    "    y='mouse oligo count',\n",
    "    hue='bead chromatin species',\n",
    "    size='bead count',\n",
    "    sizes=(10, 50),\n",
    "    ax=axs[0]\n",
    ")\n",
    "# ax.set_aspect('equal')\n",
    "axs[0].set_title('Oligo counts for single-chromatin-species CTCF beads')\n",
    "axs[0].xaxis.set_major_locator(matplotlib.ticker.MaxNLocator(integer=True))\n",
    "sns.move_legend(axs[0], \"upper left\", bbox_to_anchor=(1, 1))\n",
    "\n",
    "axs[1] = sns.scatterplot(\n",
    "    (\n",
    "        df_single_chromatin_species_target_beads\n",
    "        .loc[df_single_chromatin_species_target_beads['target'] == 'H3K4me3']\n",
    "        .groupby(['chromatin species', 'human oligo count', 'mouse oligo count'], observed=True)\n",
    "        .size()\n",
    "        .rename('bead count')\n",
    "        .reset_index()\n",
    "        .rename(columns={'chromatin species': 'bead chromatin species'})\n",
    "        # x-jitter human oligo counts for visualization\n",
    "        .pipe(lambda df: df.assign(**{\n",
    "            'human oligo count': df['human oligo count'] + 0.2 * (df['bead chromatin species'] == 'human').astype(float) - 0.1\n",
    "        }))\n",
    "    ),\n",
    "    x='human oligo count',\n",
    "    y='mouse oligo count',\n",
    "    hue='bead chromatin species',\n",
    "    size='bead count',\n",
    "    sizes=(10, 50),\n",
    "    ax=axs[1]\n",
    ")\n",
    "axs[1].set_title('Oligo counts for single-chromatin-species H3K4me3 beads')\n",
    "axs[1].xaxis.set_major_locator(matplotlib.ticker.MaxNLocator(integer=True))\n",
    "sns.move_legend(axs[1], \"upper left\", bbox_to_anchor=(1, 1))\n",
    "\n",
    "fig.show()\n",
    "ax.figure.savefig(\n",
    "    os.path.join(DIR_RESULTS, 'single-chromatin-species_single-target_beads_mixing.png'),\n",
    "    bbox_inches='tight',\n",
    "    dpi=300\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25225136-0822-437b-a5d0-06005043c84c",
   "metadata": {},
   "source": [
    "## Motif analysis\n",
    "\n",
    "1. If I have enough reads for peak calling: makeTagDirectory --> findPeaks --> findMotifsGenome.pl\n",
    "2. If not enough reads for peak calling: findMotifsGenome.pl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f77f1f-1b93-45b6-94a0-c194677a1d76",
   "metadata": {},
   "source": [
    "Potential concern: reads aligning to highly conserved regions between mouse and human genomes (which may include conserved CTCF binding sites or promoter regions normally marked by H3K4me3) may have been filtered out by the pipeline. Consequently, motif analysis performed on reads filtered for with high mapping quality to the combined genome is likely extremely conservative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6401c953-8e5c-434f-9c3b-284c3e75385e",
   "metadata": {},
   "source": [
    "# Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fce4141-410c-4add-b868-8c2d067a2f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sizeof_fmt(num, suffix='B'):\n",
    "    ''' by Fred Cirera,  https://stackoverflow.com/a/1094933/1870254, modified'''\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f %s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f %s%s\" % (num, 'Yi', suffix)\n",
    "\n",
    "for name, size in sorted(((name, sys.getsizeof(value)) for name, value in list(\n",
    "                          globals().items())), key= lambda x: -x[1])[:20]:\n",
    "    print(\"{:>30}: {:>8}\".format(name, sizeof_fmt(size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60451bc-f5a5-4df4-8cbc-0482a97335b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash -s {DIR_PROC} {DIR_AUX} {DIR_SCRIPTS}\n",
    "# DIR_PROC=\"$1\"\n",
    "# DIR_AUX=\"$2\"\n",
    "# DIR_SCRIPTS=\"$3\"\n",
    "\n",
    "# source ~/.bashrc\n",
    "# conda activate snakemake\n",
    "\n",
    "# snakemake \\\n",
    "# --snakefile \"${DIR_SCRIPTS}/Snakefile\" \\\n",
    "# --configfile \"${DIR_AUX}/config.yaml\" \\\n",
    "# -j 1 \\\n",
    "# clean"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
