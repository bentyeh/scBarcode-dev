{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce64bb11-30d6-4efc-a17d-f03536adb58c",
   "metadata": {},
   "source": [
    "Status: complete\n",
    "\n",
    "Data\n",
    "- Benchling notebook: [2024-11-07 Human-mouse mixing ChIP-seq](https://benchling.com/s/etr-GcNccQeNTC32BHI3mLna)\n",
    "- [Library Sheet](https://docs.google.com/spreadsheets/d/1TwqZjgeley2BaOh1xkQ5Pwzi_yxNvlc1KeaTBwyCLiU)\n",
    "- Sequencing runs:\n",
    "  - [20241121_ESS](https://docs.google.com/spreadsheets/d/1kV8gOaSSB9VktkTEqVO4W3izpBkpOZ6Du1kDDAOLh8c)\n",
    "    - Aliquot(s): 4.0% (2)\n",
    "\n",
    "Splitcode configs: https://docs.google.com/spreadsheets/d/1XrNNYC3ckBm_Ir2E3MWDkFMDMuHjL5Z7uOmD9kNKZOE\n",
    "\n",
    "Results\n",
    "- Sequencing coverage of chromatin: ~22%\n",
    "- Sequencing coverage of oligos: unknown (no UMIs)\n",
    "- Average oligos per bead: 2.58 (median = 2) (compare with 0.78 estimated from library prep)\n",
    "- Average uniquely mapping, non-blacklisted chromatin per bead: 0.27 (median = 0) (compare with 0.75 estimated from library prep)\n",
    "- Mixing between CTCF antibody beads and H3K4me3 antibody beads: minimal\n",
    "  - Only 1645 beads (out of 15519769 total beads, or 3593363 beads with chromatin) have chromatin from both ChIPs\n",
    "- Mixing of oligos: significant\n",
    "  - Out of 3,364,467 single-chromatin-species single-target beads, 483,480 (14.4%) contain oligos of the incorrect species.\n",
    "  - Out of 1,604,404 single-chromatin-species single-target beads with >= 1 oligo, 988,106 beads (61.6%) do not have the correct oligo representating >= 80% of oligos.\n",
    "\n",
    "Conclusion\n",
    "- Pairing species oligo with chromatin: too much mixing\n",
    "- ChIP\n",
    "  - CTCF ChIP was successful: peaks are visible in the bigWig tracks, and >70% of othem contain a known CTCF motif.\n",
    "  - H3K4me3 ChIP quality was less clear\n",
    "    - Peaks over promoters are not obvious in the bigWig tracks\n",
    "    - GREAT did not find any signficant GO term enrichment of nearby genes.\n",
    "    - TSS and metagene profiles perhaps match expected H3K4me3 peaks.\n",
    "\n",
    "Potential improvements\n",
    "- Use GRCm39 (mm39) instead GRCm38 (mm10) for aligning mouse reads\n",
    "  - Beyond a more polished genome, Ensembl/GENCODE also provide an Ensembl Canonical transcript set for GRCm39 (mm39).\n",
    "- Use \"analysis set\" genome sequences and indices for alignment\n",
    "- Perform additional peak annotation analyses (e.g., GREAT) to validate CTCF and H3K4me3 ChIP quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883d94e0-6230-43be-b480-1663428c474f",
   "metadata": {},
   "source": [
    "Notes\n",
    "- Running the entire notebook requires a LOT of RAM: >40 GB. This appears to be due to memory used by pandas DataFrames not being released (see https://stackoverflow.com/questions/39100971/how-do-i-release-memory-used-by-a-pandas-dataframe).\n",
    "- Much of the ChIP analysis is performed within a Snakemake pipeline.\n",
    "  - See the `scripts/20241121` directory in this repository for the Snakefile, config.yaml, and cluster.yaml.\n",
    "- For TSS and metagene ChIP enrichment profiles in this notebook of mouse genes, there was no Ensembl Canonical set available for GRCm38 (mm10). Consequently, the \"canonical\" set that I used was simply the entire GENCODE vM25 GTF annotation set filtered for transcripts tagged with transcript support level 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb6266d-136c-424c-a247-34e544313c5c",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1c39f5-8261-404b-8776-79c27e96d51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b32658-a4f2-4832-8b19-81137c72aa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Standard Library modules\n",
    "import gc\n",
    "import gzip\n",
    "import itertools\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "\n",
    "# Basic SciPy packages\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization packages\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import IPython.display\n",
    "\n",
    "import pysam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "534a8f9e-aca6-4994-84d6-f65de05c9396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: 2025-02-04T15:18:12.213709-08:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.11.9\n",
      "IPython version      : 8.14.0\n",
      "\n",
      "conda environment: py3\n",
      "\n",
      "Compiler    : GCC 12.3.0\n",
      "OS          : Linux\n",
      "Release     : 5.14.0-362.24.1.el9_3.x86_64\n",
      "Machine     : x86_64\n",
      "Processor   : x86_64\n",
      "CPU cores   : 32\n",
      "Architecture: 64bit\n",
      "\n",
      "json      : 2.0.9\n",
      "sys       : 3.11.9 | packaged by conda-forge | (main, Apr 19 2024, 18:36:13) [GCC 12.3.0]\n",
      "re        : 2.2.1\n",
      "matplotlib: 3.9.0\n",
      "numpy     : 1.26.4\n",
      "pandas    : 2.2.1\n",
      "scipy     : 1.14.0\n",
      "IPython   : 8.14.0\n",
      "pysam     : 0.22.1\n",
      "seaborn   : 0.13.2\n",
      "\n",
      "Watermark: 2.4.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark --updated --iso8601 --python --conda --machine --iversions --watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fa94217-0829-4e07-945e-2bcf4e87615b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitcode, version 0.30.0\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "splitcode --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbe0d62-16d6-47f5-beb5-5089cf871b9d",
   "metadata": {},
   "source": [
    "## Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a306bf1-40af-4cb2-a4e4-b724d60d4b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_PROJECT = '/central/groups/guttman/btyeh/scBarcode'\n",
    "DIR_DATA = os.path.join(DIR_PROJECT, 'data', '20241121')\n",
    "DIR_AUX = os.path.join(DIR_PROJECT, 'data_aux', '20241121')\n",
    "DIR_PROC = os.path.join(DIR_PROJECT, 'data_proc', '20241121')\n",
    "DIR_RESULTS = os.path.join(DIR_PROJECT, 'results', '20241121')\n",
    "DIR_SCRIPTS = os.path.join(DIR_PROJECT, 'scripts', '20241121')\n",
    "\n",
    "os.makedirs(DIR_AUX, exist_ok=True)\n",
    "os.makedirs(DIR_PROC, exist_ok=True)\n",
    "os.makedirs(DIR_RESULTS, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605a3030-6fec-4b39-8c9c-c143c69619e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of processes/threads to use\n",
    "# either manually specify an integer, or automatically detect via something like os.cpu_count()\n",
    "n_proc = 4\n",
    "\n",
    "reprocess = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffc990b-c95c-47d7-ba03-3fbd14753cd2",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5f79b7-c34c-471e-b7a4-ec407c6eddea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_library_complexity(count_total, count_dedup, ub=None, max_err=1e-3):\n",
    "    '''\n",
    "    See https://github.com/bentyeh/resources/blob/main/bioinformatics/models_genomics.md\n",
    "\n",
    "    Generative model: Poisson sampling (i.e., with replacement) count_total reads from\n",
    "    M unique molecules, such that count_dedup molecules were sampled at least once. Solve\n",
    "    for M.\n",
    "\n",
    "    Accurate when count_total << M.\n",
    "    '''\n",
    "    if ub is None:\n",
    "        ub = count_total*1e5\n",
    "    res = scipy.optimize.minimize_scalar(\n",
    "      fun=lambda M: (M * (1 - np.exp(-count_total/M)) - count_dedup)**2,\n",
    "      bracket=(count_dedup, ub)\n",
    "    )\n",
    "    assert res.fun < max_err\n",
    "    return res.x\n",
    "\n",
    "def estimate_library_complexity2(count_total, count_mean, ub=None, max_err=1e-3):\n",
    "    '''\n",
    "    See https://github.com/bentyeh/resources/blob/main/bioinformatics/models_genomics.md\n",
    "\n",
    "    Generative model: Poisson sampling (i.e., with replacement) count_total reads from\n",
    "    M unique molecules, yielding mean observed counts count_mean. Solve for M.\n",
    "    '''\n",
    "    ub = ub if ub is not None else count_total*1e5\n",
    "    res = scipy.optimize.minimize_scalar(\n",
    "      fun=lambda M: ((count_total / M) / (1 - np.exp(-count_total / M)) - count_mean)**2,\n",
    "      bracket=(count_total / count_mean, ub)\n",
    "    )\n",
    "    assert res.fun < max_err\n",
    "    return res.x\n",
    "\n",
    "def estimate_library_complexity_curve(\n",
    "    total_reads: np.ndarray,\n",
    "    M: int,\n",
    "    ci: tuple[float, float] = (0.025, 0.975)\n",
    ") -> pd.DataFrame:\n",
    "    '''\n",
    "    Args\n",
    "    - total_reads\n",
    "    - M: total number of unique molecules in the sample\n",
    "    - ci: confidence interval\n",
    "\n",
    "    Returns: pd.DataFrame\n",
    "    - Columns = total_reads, expected_distinct, lower_ci, upper_ci\n",
    "    '''\n",
    "    p_zero = scipy.stats.binom.pmf(0, total_reads, 1/M)\n",
    "    expected_distinct = M * (1 - p_zero)\n",
    "\n",
    "    # smallest d such that P(D < d) > ci[0]\n",
    "    lower_ci = scipy.stats.binom.ppf(ci[0], M, 1 - p_zero)\n",
    "\n",
    "    # smallest d such that P(D < d) > ci[1]\n",
    "    upper_ci = scipy.stats.binom.ppf(ci[1], M, 1 - p_zero)\n",
    "    return pd.DataFrame({\n",
    "        'total_reads': total_reads,\n",
    "        'expected_distinct': expected_distinct,\n",
    "        'lower_ci': lower_ci,\n",
    "        'upper_ci': upper_ci\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8548ef-8fbb-4999-a11c-37dddac8ecff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://docs.python.org/3/library/itertools.html\n",
    "def grouper(iterable, n, *, incomplete='fill', fillvalue=None):\n",
    "    \"Collect data into non-overlapping fixed-length chunks or blocks.\"\n",
    "    # grouper('ABCDEFG', 3, fillvalue='x') → ABC DEF Gxx\n",
    "    # grouper('ABCDEFG', 3, incomplete='strict') → ABC DEF ValueError\n",
    "    # grouper('ABCDEFG', 3, incomplete='ignore') → ABC DEF\n",
    "    iterators = [iter(iterable)] * n\n",
    "    match incomplete:\n",
    "        case 'fill':\n",
    "            return itertools.zip_longest(*iterators, fillvalue=fillvalue)\n",
    "        case 'strict':\n",
    "            return zip(*iterators, strict=True)\n",
    "        case 'ignore':\n",
    "            return zip(*iterators)\n",
    "        case _:\n",
    "            raise ValueError('Expected fill, strict, or ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105ffe2d-4103-41fa-a958-44554775fb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-implementing the == operator of Numpy array to bypass a seaborn bug in sns.histplot\n",
    "# when using weights and user-specific bins\n",
    "# https://github.com/mwaskom/seaborn/issues/3801\n",
    "class myclass(np.ndarray):\n",
    "    def __eq__(self, other):\n",
    "        if type(other) is str and other == 'auto':\n",
    "            return False\n",
    "        else:\n",
    "            return super().__eq__(other)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94df955-5ad2-4117-9301-f7784d83e9ef",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1021e1-58b6-4a4a-9f67-9537833222a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "REF_CHROMS_HUMAN = [f'chr{i}' for i in range(1, 23)] + ['chrX', 'chrY', 'chrM']\n",
    "REF_CHROMS_MOUSE = [f'chr{i}' for i in range(1, 20)] + ['chrX', 'chrY', 'chrM']\n",
    "\n",
    "ROUNDS = ['Odd', 'Even', 'Odd2', 'Even2', 'Odd3', 'Y']\n",
    "\n",
    "TARGETS = ['CTCF', 'H3K4me3']\n",
    "DTYPE_TARGET = pd.CategoricalDtype(categories=TARGETS)\n",
    "\n",
    "SPECIES = ['human', 'mouse']\n",
    "DTYPE_SPECIES = pd.CategoricalDtype(categories=SPECIES)\n",
    "DTYPE_SPECIES_ABBREV = pd.CategoricalDtype(categories=['h', 'm'])\n",
    "\n",
    "ALIGNMENT_TYPES = ['R1', 'PE']\n",
    "DTYPE_ALIGNMENT = pd.CategoricalDtype(categories=ALIGNMENT_TYPES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb417f1-c625-408b-9efd-57e5f4045ee4",
   "metadata": {},
   "source": [
    "Key paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c309c2e-1a5f-4de7-b73d-6b472b8c3170",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_bead_counts = os.path.join(DIR_PROC, 'bead_counts.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d2b493-ae2e-484a-8eb1-a0d46fd4a769",
   "metadata": {},
   "source": [
    "## Download human and mouse genome indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e0d536-a179-4a87-a5f7-c85bada20d30",
   "metadata": {},
   "source": [
    "Bowtie 2 human genome index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d432f9-dcc1-4645-9506-d0ac473d6e78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "PATH_SCRATCH='/central/scratch/btyeh'\n",
    "\n",
    "cd \"$PATH_SCRATCH\"\n",
    "\n",
    "if [ ! -f \"${PATH_SCRATCH}/index_hg38/GRCh38_noalt_as.1.bt2\" ] || [ ! -f \"${PATH_SCRATCH}/index_hg38/GRCh38_noalt_as.rev.2.bt2\" ]; then\n",
    "    mkdir -p index_hg38\n",
    "    wget -q https://genome-idx.s3.amazonaws.com/bt/GRCh38_noalt_as.zip\n",
    "    unzip -j -d index_hg38 GRCh38_noalt_as.zip \\*.bt2\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a9c5ef-4c27-4f23-a9e0-36ef30307160",
   "metadata": {},
   "source": [
    "Bowtie 2 mouse genome index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b40551-2156-4f3e-856e-a613542defbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "PATH_SCRATCH='/central/scratch/btyeh'\n",
    "\n",
    "cd \"$PATH_SCRATCH\"\n",
    "\n",
    "if [ ! -f \"${PATH_SCRATCH}/index_mm10/mm10.1.bt2\" ] || [ ! -f \"${PATH_SCRATCH}/index_mm10/mm10.rev.2.bt2\" ]; then\n",
    "    mkdir -p index_mm10\n",
    "    wget -q https://genome-idx.s3.amazonaws.com/bt/mm10.zip\n",
    "    unzip -j -d index_mm10 mm10.zip \\*.bt2\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6115703d-3ba7-40d1-867e-8232b0475058",
   "metadata": {},
   "source": [
    "## Build combined human-mouse genome index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda5ebae-2a85-492a-ab61-3607dd297a63",
   "metadata": {},
   "source": [
    "Download all FASTA files (1 file per chromosome) for human and mouse genomes. Rename human chromosomes from \"chr*\" to \"h_chr*\" and mouse chromosomes from \"chr*\" to \"m_chr*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e16d1d-10de-402c-a6bb-646cbc963e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "PATH_SCRATCH='/central/scratch/btyeh/hg38'\n",
    "PATH_INDEX='/central/scratch/btyeh/index_hg38_mm10'\n",
    "if [ ! -f \"$PATH_SCRATCH\"/h_chr1.fa ] && \\\n",
    "    ([ ! -f \"$PATH_INDEX\"/hg38_mm10.rev.1.bt2l ] || [ ! -f \"$PATH_SCRATCH\"/h_chr1.fa.fai ]); then\n",
    "    mkdir -p \"$PATH_SCRATCH\"\n",
    "    wget -nc -q -O - https://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/hg38.chromFa.tar.gz |\n",
    "        tar -xz -C \"$PATH_SCRATCH\"\n",
    "    mv \"$PATH_SCRATCH\"/chroms/*.fa \"$PATH_SCRATCH\"\n",
    "    \n",
    "    # remove alternate loci sequences\n",
    "    rm -r \"$PATH_SCRATCH\"/chroms \"$PATH_SCRATCH\"/*_alt.fa\n",
    "    \n",
    "    cd \"$PATH_SCRATCH\"\n",
    "    for file in chr*.fa; do\n",
    "        new_file=\"h_${file}\"\n",
    "        sed -e 's/^>chr/>h_chr/' \"$file\" > \"$new_file\"\n",
    "        rm \"$file\"\n",
    "    done\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7f9dc7-a0e9-44c4-8280-d5aa28320804",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "PATH_SCRATCH='/central/scratch/btyeh/mm10'\n",
    "PATH_INDEX='/central/scratch/btyeh/index_hg38_mm10'\n",
    "if [ ! -f \"$PATH_SCRATCH\"/m_chr1.fa ] && \\\n",
    "    ([ ! -f \"$PATH_INDEX\"/hg38_mm10.rev.1.bt2l ] || [ ! -f \"$PATH_SCRATCH\"/m_chr1.fa.fai ]); then\n",
    "    mkdir -p \"$PATH_SCRATCH\"\n",
    "    wget -nc -q -O - https://hgdownload.soe.ucsc.edu/goldenPath/mm10/bigZips/chromFa.tar.gz |\n",
    "        tar -xz -C \"$PATH_SCRATCH\"\n",
    "    \n",
    "    cd \"$PATH_SCRATCH\"\n",
    "    for file in chr*.fa; do\n",
    "        new_file=\"m_${file}\"\n",
    "        sed -e 's/^>chr/>m_chr/' \"$file\" > \"$new_file\"\n",
    "        rm \"$file\"\n",
    "    done\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c7dec6-72bd-4811-9ac6-c8da3756d11d",
   "metadata": {},
   "source": [
    "Build combined genome index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48b7a2b-f3dc-4f32-9e01-cf12395eb5ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash -s {DIR_PROJECT}\n",
    "DIR_PROJECT=\"$1\"\n",
    "\n",
    "PATH_SBATCH=\"${DIR_PROJECT}/scripts/20240625/build_index.sbatch\"\n",
    "PATH_INDEX='/central/scratch/btyeh/index_hg38_mm10'\n",
    "\n",
    "if [ ! -f \"$PATH_INDEX\"/hg38_mm10.rev.1.bt2l ]; then\n",
    "    sbatch --output=\"$PATH_INDEX\"/slurm.out --error=\"$PATH_INDEX\"/slurm.err \"$PATH_SBATCH\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24e7a6c-c52f-4dd4-88ad-ff2fb1803bef",
   "metadata": {},
   "source": [
    "## Create genome annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78bddb9-e1f4-433e-9db4-d8a5c9ed3463",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_ANNOT = '/central/scratch/btyeh/annot'\n",
    "os.makedirs(DIR_ANNOT, exist_ok=True)\n",
    "\n",
    "path_gencode_human = os.path.join(DIR_ANNOT, 'gencode.v47.primary_assembly.annotation.gtf.gz')\n",
    "path_gencode_mouse = os.path.join(DIR_ANNOT, 'gencode.vM25.primary_assembly.annotation.gtf.gz')\n",
    "\n",
    "path_ucsc_human = os.path.join(DIR_ANNOT, 'hg38.gtf')\n",
    "path_ucsc_mouse = os.path.join(DIR_ANNOT, 'mm10.gtf')\n",
    "\n",
    "path_ucsc_human_canonical = os.path.join(DIR_ANNOT, 'hg38_canonical_transcripts.gtf')\n",
    "path_ucsc_mouse_canonical = os.path.join(DIR_ANNOT, 'mm10_canonical_transcripts.gtf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38c6e5e-5d19-418d-b799-5260575ecef8",
   "metadata": {},
   "source": [
    "Download GENCODE annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192ad5bd-1883-435d-85ed-0a2f8cc5fe53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash -s {DIR_ANNOT} {path_gencode_human} {path_gencode_mouse}\n",
    "set -e\n",
    "\n",
    "PATH_ANNOT=\"$1\"\n",
    "PATH_GENCODE_HUMAN=\"$2\"\n",
    "PATH_GENCODE_MOUSE=\"$3\"\n",
    "\n",
    "if [ ! -f \"$PATH_ANNOT\"/hg38_mm10.gtf.gz.tbi ] || [ ! -f \"$PATH_ANNOT/hg38.gtf\" ] || [ ! -f \"$PATH_ANNOT/mm10_canonical_transcripts.gtf\" ]; then\n",
    "    # download mouse and human primary assembly (chromosomes and scaffolds) annotations\n",
    "    wget -q -O \"$PATH_GENCODE_HUMAN\" \\\n",
    "        'https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_47/gencode.v47.primary_assembly.annotation.gtf.gz'\n",
    "    wget -q -O \"$PATH_GENCODE_MOUSE\" \\\n",
    "        'https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M25/gencode.vM25.primary_assembly.annotation.gtf.gz'\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03304e92-c650-4363-b22a-bd00ac5e35ad",
   "metadata": {},
   "source": [
    "### Rename chromosomes to match UCSC names\n",
    "\n",
    "Notes\n",
    "- I remove comment lines starting with `#` in the processed GTF files.\n",
    "- If providing a GTF file (instead of BED file) to deepTools `computeMatrix`, the GTF file must be [topologically sorted](https://agat.readthedocs.io/en/latest/topological-sorting-of-gff-features.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94accf95-85e1-4d03-a5fd-5255bfa44163",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_tmp = os.path.join(DIR_ANNOT, 'tmp.gtf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a634ed68-8b9b-4756-ba4d-907ca8407041",
   "metadata": {},
   "source": [
    "Rename human chromosomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635ce945-b230-461d-8c76-a0fdaff5a7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(path_ucsc_human):\n",
    "    df_chromAlias_hg38 = pd.read_csv(\n",
    "        'https://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/latest/hg38.chromAlias.txt',\n",
    "        sep='\\t',\n",
    "        header=None,\n",
    "        comment='#',\n",
    "        names=['UCSC', 'assembly', 'Ensembl', 'GenBank', 'RefSeq']\n",
    "    )\n",
    "    \n",
    "    gencode_to_ucsc_hg38 = {x: x for x in REF_CHROMS_HUMAN}\n",
    "    gencode_to_ucsc_hg38.update(df_chromAlias_hg38.loc[~df_chromAlias_hg38['UCSC'].isin(REF_CHROMS_HUMAN)].set_index('GenBank')['UCSC'].to_dict())\n",
    "    with gzip.open(path_gencode_human, 'rt') as f_in, \\\n",
    "        open(path_tmp, 'wt') as f_out:\n",
    "        for line in tqdm(f_in):\n",
    "            if line.startswith('#'):\n",
    "                continue\n",
    "            chrom, rest = line.split('\\t', maxsplit=1)\n",
    "            f_out.write('\\t'.join((gencode_to_ucsc_hg38[chrom], rest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5add50-f65b-445b-b7a5-953fe5e19e8a",
   "metadata": {},
   "source": [
    "Sort human GTF. Maintain topological order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783e6a2c-16fb-4576-9ec5-4c37a1e3272a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s {path_tmp} {path_ucsc_human}\n",
    "set -e\n",
    "PATH_TMP=\"$1\"\n",
    "PATH_UCSC_HUMAN=\"$2\"\n",
    "\n",
    "if [ ! -f \"$PATH_UCSC_HUMAN\" ]; then\n",
    "    source ~/.bashrc\n",
    "    conda activate genomics\n",
    "\n",
    "    gtfsort -i \"$PATH_TMP\" -o \"$PATH_UCSC_HUMAN\"\n",
    "    rm \"$PATH_TMP\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6070205-08c2-4c1e-91c4-d376c2655b59",
   "metadata": {},
   "source": [
    "Rename mouse chromosomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe7f741-832c-4f67-b315-9654a6428f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(path_ucsc_mouse):\n",
    "    df_chromAlias_mm10 = pd.read_csv(\n",
    "        'https://hgdownload.soe.ucsc.edu/goldenPath/mm10/bigZips/latest/mm10.chromAlias.txt',\n",
    "        sep='\\t',\n",
    "        header=None,\n",
    "        comment='#',\n",
    "        names=['UCSC', 'assembly', 'GenBank', 'RefSeq']\n",
    "    )\n",
    "    \n",
    "    gencode_to_ucsc_mm10 = {x: x for x in REF_CHROMS_MOUSE}\n",
    "    gencode_to_ucsc_mm10.update(df_chromAlias_mm10.loc[~df_chromAlias_mm10['UCSC'].isin(REF_CHROMS_MOUSE)].set_index('GenBank')['UCSC'].to_dict())\n",
    "    with gzip.open(path_gencode_mouse, 'rt') as f_in, \\\n",
    "        open(path_tmp, 'wt') as f_out:\n",
    "        for line in tqdm(f_in):\n",
    "            if line.startswith('#'):\n",
    "                f_out.write(line)\n",
    "            else:\n",
    "                chrom, rest = line.split('\\t', maxsplit=1)\n",
    "                f_out.write('\\t'.join((gencode_to_ucsc_mm10[chrom], rest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f07576-0f00-4ff9-9040-6e36053e5be0",
   "metadata": {},
   "source": [
    "Sort mouse GTF. Maintain topological order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e85265-12c0-499f-a75d-e5846301a02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s {path_tmp} {path_ucsc_mouse}\n",
    "set -e\n",
    "PATH_TMP=\"$1\"\n",
    "PATH_UCSC_MOUSE=\"$2\"\n",
    "\n",
    "if [ ! -f \"$PATH_UCSC_MOUSE\" ]; then\n",
    "    source ~/.bashrc\n",
    "    conda activate genomics\n",
    "\n",
    "    gtfsort -i \"$PATH_TMP\" -o \"$PATH_UCSC_MOUSE\"\n",
    "    rm \"$PATH_TMP\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d173bf46-082a-4db4-8e9e-ca708bf67e10",
   "metadata": {},
   "source": [
    "### Extract Ensembl Canonical transcript subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b601ec-1739-455d-b360-63b91ebb9987",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash -s {path_ucsc_human} {path_ucsc_mouse} {path_ucsc_human_canonical} {path_ucsc_mouse_canonical}\n",
    "set -e\n",
    "PATH_HUMAN=\"$1\"\n",
    "PATH_MOUSE=\"$2\"\n",
    "PATH_HUMAN_CANONICAL=\"$3\"\n",
    "PATH_MOUSE_CANONICAL=\"$4\"\n",
    "\n",
    "if [ ! -f \"$PATH_HUMAN_CANONICAL\" ]; then\n",
    "    awk '{if ($3 == \"transcript\") {print $0}}' \"$PATH_HUMAN\" |\n",
    "        grep 'tag \"Ensembl_canonical\"' > \"$PATH_HUMAN_CANONICAL\"\n",
    "fi\n",
    "\n",
    "if [ ! -f \"$PATH_MOUSE_CANONICAL\" ]; then\n",
    "    # GENCODE vM25 does not have Ensembl canonical tags --> we filter for transcripts with TSL1\n",
    "    awk '{if ($3 == \"transcript\") {print $0}}' \"$PATH_MOUSE\" |\n",
    "        grep -e 'transcript_support_level \"1\"' > \"$PATH_MOUSE_CANONICAL\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6c261a-b271-476c-b8ce-7e493e44859b",
   "metadata": {},
   "source": [
    "### Create IGV Genome JSON file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9392791e-3133-4575-973d-cac2a39cffe5",
   "metadata": {},
   "source": [
    "Concatenate all reference chromosome FASTA files and build a FASTA index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4eea92-5dd2-4981-93de-027b9147e565",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "PATH_SCRATCH='/central/scratch/btyeh'\n",
    "PATH_INDEX=\"${PATH_SCRATCH}/index_hg38_mm10\"\n",
    "\n",
    "if [ ! -f \"$PATH_INDEX\"/hg38_mm10.fa.fai ]; then\n",
    "    source ~/.bashrc\n",
    "    conda activate chipdip\n",
    "    \n",
    "    cat \"$PATH_SCRATCH\"/hg38/*.fa \"$PATH_SCRATCH\"/mm10/*.fa > \"$PATH_INDEX\"/hg38_mm10.fa\n",
    "    samtools faidx \"$PATH_INDEX\"/hg38_mm10.fa\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a599917-6d0c-491a-951c-34d8f371fb57",
   "metadata": {},
   "source": [
    "Concatenate human and mouse genome annotations with modified chromosome names (`h_chr` for human, `m_chr` for mouse) and index the combined GTF file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a00a2f-08c1-42b7-bcda-d89103490c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -e\n",
    "\n",
    "PATH_ANNOT='/central/scratch/btyeh/annot'\n",
    "\n",
    "if [ ! -f \"$PATH_ANNOT\"/hg38_mm10.gtf.gz.tbi ]; then\n",
    "    source ~/.bashrc\n",
    "    conda activate chipdip\n",
    "    \n",
    "    # concatenate human and mouse genome GTFs\n",
    "    cat <(sed -E -e 's/^chr/h_chr/' \"$PATH_ANNOT\"/hg38.gtf | sort -k 1,1V -k 4,4V -k 5,5V) \\\n",
    "        <(sed -E -e 's/^chr/m_chr/' \"$PATH_ANNOT\"/mm10.gtf | sort -k 1,1V -k 4,4V -k 5,5V) |\n",
    "        bgzip --threads 4 -c /dev/stdin > \"$PATH_ANNOT\"/hg38_mm10.gtf.gz\n",
    "\n",
    "    # index the combined GTF\n",
    "    tabix -f \"$PATH_ANNOT\"/hg38_mm10.gtf.gz\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89c7308-d92b-4573-be7c-afd7f79f2ce1",
   "metadata": {},
   "source": [
    "Using paths to these annotation files, I created an IGV genome JSON file manually at `data_aux/20240625/hg38_mm10.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c6fe6d-6005-47bb-b2a5-32ab036818c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DIR_AUX, 'hg38_mm10.json'), 'rt') as f:\n",
    "    print(json.dumps(json.load(f), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08c2753-0447-4e8b-ab6f-5dd72bab68f2",
   "metadata": {},
   "source": [
    "## Download MEME Suite Motif Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5456c2-d938-48d5-8e7a-499babe6ae17",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "PATH_SCRATCH='/central/scratch/btyeh'\n",
    "\n",
    "if [ ! -d \"$PATH_SCRATCH/motif_databases\" ] || [ ! -f \"$PATH_SCRATCH/motif_databases/motif_db.csv\" ]; then\n",
    "    wget -q -O \"$PATH_SCRATCH/motif_databases.12.25.tgz\" \\\n",
    "        'https://meme-suite.org/meme/meme-software/Databases/motifs/motif_databases.12.25.tgz'\n",
    "    mkdir -p \"$PATH_SCRATCH/motif_databases\"\n",
    "    tar -xzf \"$PATH_SCRATCH/motif_databases.12.25.tgz\" \\\n",
    "        --directory \"$PATH_SCRATCH/motif_databases/\" \\\n",
    "        --strip-components=1\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb378b5-8ba2-42b1-8ac9-e9cb1914b5eb",
   "metadata": {},
   "source": [
    "# FastQC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ecfb4a-1e48-43f1-a334-16718c109087",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s {DIR_DATA} {DIR_PROC} {reprocess}\n",
    "DIR_DATA=\"$1\"\n",
    "DIR_PROC=\"$2\"\n",
    "reprocess=\"$3\"\n",
    "DIR_FASTQC_OUT=\"${DIR_PROC}/fastqc\"\n",
    "if [ ! -d \"$DIR_FASTQC_OUT\" ] || [ \"$reprocess\" = \"True\" ]; then\n",
    "    mkdir -p \"${DIR_PROC}/fastqc\"\n",
    "    cd \"$DIR_DATA\"\n",
    "    source ~/.bashrc\n",
    "    conda activate chipdip\n",
    "    nohup fastqc *.fastq.gz -t 20 -q -o \"$DIR_FASTQC_OUT\" &> \"${DIR_PROC}/fastqc.log\" &\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bbacd3-d997-4d45-83a8-7975c0d6833c",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16303295-a850-4614-869a-9b91b76b1843",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_R1 = os.path.join(DIR_DATA, \"HEK-pSM44_mixing_CTCF_H3K4me3_ChIP-seq_R1.fastq.gz\")\n",
    "PATH_R2 = os.path.join(DIR_DATA, \"HEK-pSM44_mixing_CTCF_H3K4me3_ChIP-seq_R2.fastq.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6338fa-418b-4d88-8d1d-92248ea5c729",
   "metadata": {},
   "source": [
    "Final barcoded cell oligo structure: [Oligo (PC50_bc6 / PC50_bc7) + Odd + Even + Odd + Even + Odd + NYLigOdd](https://benchling.com/s/seq-JLjQnGxk3XhHueFGB5EQ?m=slm-x8jDl91Zo2EuS0W2OXJW)\n",
    "- Top strand: 154-157 nt (variable due to NYLigOddStg)\n",
    "- Bottom strand: 213-216 nt\n",
    "- Library size: 297-300 bp\n",
    "- Insert size for sequencing: 161-164 bp. A read 1 length of 121 bp would include the oligo barcode and all tags except the last Odd and NYLigOdd, while a read 2 length of 164 bp would include the entire oligo barcode.\n",
    "\n",
    "Final barcoded DNA structure: [DPM + Odd + Even + Odd + Even + Odd + NYLigOdd](https://benchling.com/s/seq-MnXp2h0SAJ8dfB3N4lzc?m=slm-Copp8W7WpeZkiRtBICFG)\n",
    "- Total added length (relative to genomic DNA): 308-311 bp (variable due to NYLigOddStg)\n",
    "- Read 2 barcode length (including dA tail): 165 bp\n",
    "- Read 1 DPM length: 10 bp\n",
    "\n",
    "Sequencing\n",
    "- Instrument and kit: AVITI Cloudbreak Freestyle\n",
    "- Read 1 length: 120 bp\n",
    "- Read 2 length: 180 bp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0000f9-3266-40d4-b307-6f7cf2300373",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "\n",
    "1. Identify and trim bead barcode for all reads (add barcode to read name). Discard reads without a complete bead barcode.\n",
    "2. Cell oligo processing\n",
    "   - Identify species barcode\n",
    "   - Deduplicate by species barcode and bead barcode\n",
    "3. Chromatin processing\n",
    "   - Trim DPM from chromatin reads, and check that DPM sequences match between Read 1 and Read 2\n",
    "   - Align to human-mouse mixed genome: try aligning read 1 alone or paired-end alignment\n",
    "   - Split by species to separate human and mouse BAM files\n",
    "   - Remove reads (or read pairs) that overlap ENCODE blacklist regions\n",
    "   - Deduplicate by alignment position and bead barcode\n",
    "   - Generate bigWigs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d749ff71-3717-4211-9317-3c733f2eaaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the chromatin data used for df_beads is from paired-end alignment\n",
    "if os.path.exists(path_bead_counts) and not reprocess:\n",
    "    df_beads = pd.DataFrame(\n",
    "        data=np.load(path_bead_counts)['values'],\n",
    "        index=pd.Index(np.load(path_bead_counts)['index'], name='bead'),\n",
    "        columns=['human oligo', 'mouse oligo', 'human H3K4me3', 'mouse H3K4me3', 'human CTCF', 'mouse CTCF'],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a882ac0-ccdd-4344-90a1-fca1540632e9",
   "metadata": {},
   "source": [
    "## Identify bead barcode from R2\n",
    "\n",
    "`R[1|2]_bead-barcode.fastq.gz`\n",
    "- Append `::bead=<bead number>` to read name\n",
    "- Trim the bead barcode sequence from R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d26513c-dd6a-497a-abae-473e7e90e1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_config_bead_barcode = os.path.join(DIR_AUX, 'splitcode_config-bead_barcode.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41960151-fa4e-401c-8622-450c7679852c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s {DIR_DATA} {DIR_PROC} {path_config_bead_barcode} {PATH_R1} {PATH_R2} {reprocess}\n",
    "DIR_DATA=\"$1\"\n",
    "DIR_PROC=\"$2\"\n",
    "PATH_CONFIG=\"$3\"\n",
    "PATH_R1=\"$4\"\n",
    "PATH_R2=\"$5\"\n",
    "reprocess=\"$6\"\n",
    "\n",
    "PATH_MAPPING=\"$DIR_PROC/mapping_bead-barcode.tsv\"\n",
    "PATH_SUMMARY=\"$DIR_PROC/summary_bead-barcode.json\"\n",
    "PATH_OUT1=\"$DIR_PROC/R1_bead-barcode.fastq.gz\"\n",
    "PATH_OUT2=\"$DIR_PROC/R2_bead-barcode.fastq.gz\"\n",
    "\n",
    "if [ \"$reprocess\" = True ] || [ ! -f \"${PATH_MAPPING}.gz\" ]; then\n",
    "    mkfifo pipe_R1 pipe_R2 pipe_mapping\n",
    "    pids=()\n",
    "\n",
    "    # modify read names so that there is no whitespace between the read name and bead barcode.\n",
    "    sed -E -e 's/^(@\\S+) BI:i:/\\1::bead=/' pipe_R1 | pigz -p 4 > \"$PATH_OUT1\" &\n",
    "    pids[0]=\"$!\"\n",
    "    sed -E -e 's/^(@\\S+) BI:i:/\\1::bead=/' pipe_R2 | pigz -p 4 > \"$PATH_OUT2\" &\n",
    "    pids[1]=\"$!\"\n",
    "    cut -f 2,3 pipe_mapping | pigz -p 4 > \"$PATH_MAPPING\" &\n",
    "    pids[2]=\"$!\"\n",
    "    \n",
    "    splitcode -c \"$PATH_CONFIG\" \\\n",
    "        --nFastqs=2 --com-names --assign --no-outb -t 20 \\\n",
    "        --mapping=pipe_mapping --summary=\"$PATH_SUMMARY\" --output=pipe_R1,pipe_R2 \\\n",
    "        \"$PATH_R1\" \"$PATH_R2\"\n",
    "\n",
    "    for pid in \"${pids[*]}\"; do\n",
    "        wait $pid\n",
    "    done\n",
    "    rm pipe_R1 pipe_R2\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814a52b6-7a7c-4837-b9ad-7d90974c8d67",
   "metadata": {},
   "source": [
    "Parse mapping into pandas DataFrame\n",
    "- Columns: `Odd`, `Even`, `Odd2`, `Even2`, `Odd3`, `Y`, `Count`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e859c6d-71f4-448f-8c53-0b14c5d6462d",
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_bead_barcode = (\n",
    "    'NYStgBot_(?P<Y>\\d+),'\n",
    "    'OddBot_(?P<Odd3>\\d+),'\n",
    "    'EvenBot_(?P<Even2>\\d+),'\n",
    "    'OddBot_(?P<Odd2>\\d+),'\n",
    "    'EvenBot_(?P<Even>\\d+),'\n",
    "    'OddBot_(?P<Odd>\\d+)'\n",
    ")\n",
    "df_bead_barcodes = pd.read_csv(\n",
    "    os.path.join(DIR_PROC, 'mapping_bead-barcode.tsv.gz'),\n",
    "    sep='\\t',\n",
    "    names=['barcode', 'count'],\n",
    "    dtype={'count': int}\n",
    ").pipe(lambda df: pd.concat(\n",
    "    (df, df['barcode'].str.extract(regex_bead_barcode).astype(np.uint8)),\n",
    "    axis=1\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7c7ecb-0934-493b-b9bb-50696022d5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bead_barcodes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1839b574-9dcf-4f3f-b45d-c6d1e83e2adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bead_barcodes['count'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd28fb3-fa51-4bb2-99c6-e32cef8a7e2e",
   "metadata": {},
   "source": [
    "### Verify indices of barcodes used each round"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33260c69-c49b-47bf-8c1f-adc30e9e4e39",
   "metadata": {},
   "source": [
    "Actual indices used:\n",
    "- Odd: rows A-D (indices 1-48)\n",
    "- Even: rows A-D (indices 1-48)\n",
    "- Odd2: rows E-H (indices 49-96)\n",
    "- Even2: rows E-H (indices 49-96)\n",
    "- Odd3: rows A-D (indices 1-48)\n",
    "- NYLigOdd: rows E-H (indices 49-96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8febc7fd-bf05-4e77-a029-44bce7ecd2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(\n",
    "    kind='bar',\n",
    "    data=(\n",
    "        pd.concat(\n",
    "            [\n",
    "                df_bead_barcodes.groupby(r)['count'].sum().rename(r).reindex(pd.Index(list(range(1, 97))), fill_value=0)\n",
    "                for r in ROUNDS\n",
    "            ],\n",
    "            axis=1\n",
    "        )\n",
    "        .reset_index(names='index')\n",
    "        .melt(id_vars='index', var_name='round', value_name='count')\n",
    "    ),\n",
    "    x='index',\n",
    "    y='count',\n",
    "    row='round',\n",
    "    row_order=ROUNDS,\n",
    "    sharex=True,\n",
    "    sharey=True,\n",
    "    facet_kws=dict(gridspec_kws=dict(hspace=0.6))\n",
    ")\n",
    "g.axes.flatten()[-1].tick_params(axis='x', labelsize='xx-small')\n",
    "g.figure.set_size_inches(10, 6)\n",
    "g.savefig(os.path.join(DIR_RESULTS, 'tag indices used per round.png'), dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839bb403-ed39-4311-bd52-06b471fb70cd",
   "metadata": {},
   "source": [
    "Since `df_bead_barcodes` is a very large (>2 GB) variable, and it is not used later in this analysis, we delete it to free up memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1d8d5e-9ffc-45db-8d19-bfc9901b4bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Size of df_bead_barcodes (in bytes):', sys.getsizeof(df_bead_barcodes))\n",
    "del df_bead_barcodes\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a211e2b-783c-4752-95e3-230e2d01bb64",
   "metadata": {},
   "source": [
    "## Oligo read processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0026580-adc8-4c26-bb55-29fedaa93481",
   "metadata": {},
   "source": [
    "1. Select only oligo read pairs\n",
    "2. Validate the read pair\n",
    "   - Since the oligo barcode (bc6 or bc7) is sequenced in both read 1 and read 2, make sure that it matches.\n",
    "4. Generate table with following columns: bead #, human oligo count, mouse oligo count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a622d2f-fe47-4a20-bd98-abfd12f4b7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_config_oligos = os.path.join(DIR_AUX, 'splitcode_config-oligos.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fda3f4-affc-4846-827a-cb26d64b3dd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash -s {DIR_PROC} {path_config_oligos} {path_bead_counts} {reprocess}\n",
    "DIR_PROC=\"$1\"\n",
    "PATH_CONFIG=\"$2\"\n",
    "PATH_BEAD_COUNTS=\"$3\"\n",
    "reprocess=\"$4\"\n",
    "\n",
    "PATH_R1=\"$DIR_PROC/R1_bead-barcode.fastq.gz\"\n",
    "PATH_R2=\"$DIR_PROC/R2_bead-barcode.fastq.gz\"\n",
    "\n",
    "if [ \"$reprocess\" = True ] || ([ ! -f \"$PATH_BEAD_COUNTS\" ] && [ ! -f \"$DIR_PROC/oligos.csv.gz\" ]); then\n",
    "    # I would like to put the \"keep\" directive into the config file, but currently there is a bug in splitcode\n",
    "    # parsing \"remove\" and \"keep\" directives in config files (https://github.com/pachterlab/splitcode/issues/33).\n",
    "    # Consequently, I currently use the keep directive as a command line argument as a workaround\n",
    "    splitcode -c \"$PATH_CONFIG\" \\\n",
    "        --nFastqs=2 --keep=<(echo -e \"human,human_rc\\nmouse,mouse_rc\") --mod-names --select=0 --out-fasta -t 8 --pipe \\\n",
    "        \"$PATH_R1\" \"$PATH_R2\" |\n",
    "        grep -E -e '^>' |\n",
    "        sed -E \\\n",
    "            -e 's/^>.*::bead=([0-9]+)::\\[(human|mouse)\\]\\[(human|mouse)_rc\\]/\\1,\\2,\\3/' \\\n",
    "            -e 's/human/h/g' -e 's/mouse/m/g' |\n",
    "        sort |\n",
    "        uniq -c |\n",
    "        sed -E -e 's/^\\s+([0-9]+)\\s+/\\1,/' |\n",
    "        pigz -p 4 > \"$DIR_PROC/oligos.csv.gz\"\n",
    "        # columns = count, bead, species, species2\n",
    "\n",
    "    # in theory, could convert this table into binary format for greater speed and space efficiency\n",
    "    # - for example, represent bead # and count values as unsigned 64-bit integers, and\n",
    "    #   species and species2 as booleans (0 = human, 1 = mouse).\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f1b3ec-955b-41b3-b005-acee4f276d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df_beads' not in locals().keys() or reprocess:\n",
    "    df_oligos = pd.read_csv(\n",
    "        os.path.join(DIR_PROC, 'oligos.csv.gz'),\n",
    "        sep=',',\n",
    "        header=None,\n",
    "        names=['count', 'bead', 'species', 'species2'],\n",
    "        index_col='bead',\n",
    "        dtype={\n",
    "            'count': int,\n",
    "            'bead': int,\n",
    "            'species': DTYPE_SPECIES_ABBREV,\n",
    "            'species2': DTYPE_SPECIES_ABBREV\n",
    "        }\n",
    "    )\n",
    "    assert (df_oligos['species'] == df_oligos['species2']).all()\n",
    "    df_oligos = (\n",
    "        df_oligos\n",
    "        .pivot(columns='species', values='count')\n",
    "        .fillna(0)\n",
    "        .astype(int)\n",
    "        .rename(columns={'h': 'human', 'm': 'mouse'})\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0b4b0c-128b-4327-bff4-03f23232c53a",
   "metadata": {},
   "source": [
    "Total counts of human and mouse oligos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9210a557-cdb6-446b-85e8-2fa6ec339a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df_beads' not in locals().keys() or reprocess:\n",
    "    display(df_oligos.sum(axis=0))\n",
    "else:\n",
    "    display(df_beads[['human oligo', 'mouse oligo']].sum(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5300a3-8a01-4757-a233-b52a1078b59a",
   "metadata": {},
   "source": [
    "## Chromatin read processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c6b5ac-3a2e-4b0f-b278-f0f063e4264a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_config_split_chromatin = os.path.join(DIR_AUX, 'splitcode_config-chromatin.tsv')\n",
    "path_keep_chromatin = os.path.join(DIR_AUX, 'keep-chromatin.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da85d25-05b4-4a56-a28a-233bdc376467",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s {DIR_PROC} {path_config_split_chromatin} {path_keep_chromatin} {reprocess}\n",
    "DIR_PROC=\"$1\"\n",
    "PATH_CONFIG=\"$2\"\n",
    "PATH_KEEP=\"$3\"\n",
    "reprocess=\"$4\"\n",
    "\n",
    "PATH_R1=\"$DIR_PROC/R1_bead-barcode.fastq.gz\"\n",
    "PATH_R2=\"$DIR_PROC/R2_bead-barcode.fastq.gz\"\n",
    "\n",
    "if [ \"$reprocess\" = True ] || [ ! -f \"$DIR_PROC/CTCF_R1.fastq.gz\" ]; then\n",
    "    # change working directory to DIR_PROC so that the split files are generated in that directory\n",
    "    cd \"$DIR_PROC\"\n",
    "\n",
    "    splitcode -c \"$PATH_CONFIG\" \\\n",
    "        --nFastqs=2 -t 8 --keep=\"$PATH_KEEP\" --keep-r1-r2 --gzip --no-output --no-outb \\\n",
    "        \"$PATH_R1\" \"$PATH_R2\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fc9626-d310-4a06-9cf4-d554112578d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s {DIR_PROC} {DIR_AUX} {DIR_SCRIPTS}\n",
    "DIR_PROC=\"$1\"\n",
    "DIR_AUX=\"$2\"\n",
    "DIR_SCRIPTS=\"$3\"\n",
    "\n",
    "source ~/.bashrc\n",
    "conda activate snakemake\n",
    "\n",
    "snakemake \\\n",
    "    --snakefile \"${DIR_SCRIPTS}/Snakefile\" \\\n",
    "    --directory \"$DIR_PROC\" \\\n",
    "    --configfile \"${DIR_SCRIPTS}/config.yaml\" \\\n",
    "    --dag |\n",
    "dot -Tpdf > \"${DIR_SCRIPTS}/dag.pdf\"\n",
    "\n",
    "snakemake \\\n",
    "    --snakefile \"${DIR_SCRIPTS}/Snakefile\" \\\n",
    "    --directory \"$DIR_PROC\" \\\n",
    "    --configfile \"${DIR_SCRIPTS}/config.yaml\" \\\n",
    "    --filegraph |\n",
    "dot -Tpdf > \"${DIR_SCRIPTS}/filegraph.pdf\"\n",
    "\n",
    "snakemake \\\n",
    "    --snakefile \"${DIR_SCRIPTS}/Snakefile\" \\\n",
    "    --directory \"$DIR_PROC\" \\\n",
    "    --configfile \"${DIR_SCRIPTS}/config.yaml\" \\\n",
    "    --rulegraph |\n",
    "dot -Tpdf > \"${DIR_SCRIPTS}/rulegraph.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0371c1-d2eb-4fce-8fe3-a4bb24165235",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s {DIR_PROC} {DIR_AUX} {DIR_SCRIPTS}\n",
    "DIR_PROC=\"$1\"\n",
    "DIR_AUX=\"$2\"\n",
    "DIR_SCRIPTS=\"$3\"\n",
    "\n",
    "source ~/.bashrc\n",
    "conda activate snakemake\n",
    "\n",
    "snakemake \\\n",
    "    --snakefile \"${DIR_SCRIPTS}/Snakefile\" \\\n",
    "    --directory \"$DIR_PROC\" \\\n",
    "    --configfile \"${DIR_SCRIPTS}/config.yaml\" \\\n",
    "    --use-conda \\\n",
    "    --conda-frontend conda \\\n",
    "    --printshellcmds \\\n",
    "    --rerun-incomplete \\\n",
    "    -j 250 \\\n",
    "    --cluster-config \"${DIR_SCRIPTS}/cluster.yaml\" \\\n",
    "    --cluster \"sbatch -c {cluster.cpus} \\\n",
    "    -t {cluster.time} -N {cluster.nodes} \\\n",
    "    --mem {cluster.mem} \\\n",
    "    --output {cluster.output} \\\n",
    "    --error {cluster.error}\" \\\n",
    "    --cluster-cancel scancel \\\n",
    "    &> \"${DIR_PROC}/snakemake.log\" &"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068d1e21-15bb-4b0e-9345-9d52b86abf56",
   "metadata": {},
   "source": [
    "## Read counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f353b056-bf7d-4768-90b9-97569b85d84f",
   "metadata": {},
   "source": [
    "| Stage                                            | Read (pair) count | Proportion of parent stage | Proportion of total |\n",
    "|--------------------------------------------------|-------------------|----------------------------|---------------------|\n",
    "| `Total`                                          | 77,012,366        |                            |                     |\n",
    "| `- Identifiable bead barcode`                    | 52,726,577        | 68.5%                      | 68.5%               |\n",
    "| `  - Oligo`                                      | 40,021,181        | 75.9%                      | 52.0%               |\n",
    "| `    - Human (bc6)`                              | 19,581,303        | 48.9%                      | 25.4%               |\n",
    "| `    - Mouse (bc7)`                              | 20,439,878        | 51.1%                      | 26.5%               |\n",
    "| `  - Chromatin`                                  | 8,356,710         | 15.8%                      | 10.9%               |\n",
    "| `    - CTCF`                                     | 4,355,241         | 52.1%                      | 5.7%                |\n",
    "| `      - R1 aligned`                             | 2,905,324         | 66.7%                      | 3.8%                |\n",
    "| `      - Paired-end aligned`                     | 2,704,050         | 62.1%                      | 3.5%                |\n",
    "| `        - Human`                                | 1,619,655         | 59.9%                      | 2.1%                |\n",
    "| `          - Not blacklisted and not duplicated` | 1,306,880         | 80.7%                      | 1.7%                |\n",
    "| `        - Mouse`                                | 1,084,395         | 40.1%                      | 1.4%                |\n",
    "| `          - Not blacklisted and not duplicated` | 864,102           | 79.7%                      | 1.1%                |\n",
    "| `    - H3K4me3`                                  | 4,001,469         | 47.9%                      | 5.2%                |\n",
    "| `      - R1 aligned`                             | 2,774,469         | 69.3%                      | 3.6%                |\n",
    "| `      - Paired-end aligned`                     | 2,583,686         | 64.6%                      | 3.4%                |\n",
    "| `        - Human`                                | 1,591,404         | 61.6%                      | 2.1%                |\n",
    "| `          - Not blacklisted and not duplicated` | 1,280,355         | 80.5%                      | 1.7%                |\n",
    "| `        - Mouse`                                | 992,282           | 38.4%                      | 1.3%                |\n",
    "| `          - Not blacklisted and not duplicated` | 788,879           | 79.5%                      | 1.0%                |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a25d17-cdcd-4608-b765-426e4e397c59",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29e98af-e4d8-4ecd-8a57-c57360617f00",
   "metadata": {},
   "source": [
    "Load filtered and deduplicated chromatin read alignment coordinates and counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cd6436-bc96-4a6b-a495-df6a2c78b303",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chromatin = []\n",
    "for target in TARGETS:\n",
    "    for species in SPECIES:\n",
    "        for alignment_type in ALIGNMENT_TYPES:\n",
    "            path_chromatin_counts = os.path.join(DIR_PROC, f'{target}-{alignment_type}_{species}_filtered_dedup_counts.bed.gz')\n",
    "            df_chromatin.append(\n",
    "                pd.read_csv(path_chromatin_counts, sep='\\t', names=['chr', 'start', 'end', 'bead', 'count'])\n",
    "                .assign(target=target, species=species, alignment_type=alignment_type)\n",
    "                .astype({'target': DTYPE_TARGET, 'species': DTYPE_SPECIES, 'alignment_type': DTYPE_ALIGNMENT})\n",
    "            )\n",
    "df_chromatin = pd.concat(df_chromatin, axis=0, ignore_index=True).astype({'chr': 'category'})\n",
    "df_chromatin['length'] = df_chromatin['end'] - df_chromatin['start']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd168a8-9a41-4444-96bc-21b8a629e031",
   "metadata": {},
   "source": [
    "Paired end vs. read 1-only alignment counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dad5cb-b91f-4517-afb3-04541c54cf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(\n",
    "    (\n",
    "        df_chromatin\n",
    "        .groupby(['target', 'species', 'alignment_type'], observed=True)\n",
    "        .size()\n",
    "        .rename('count')\n",
    "        .reset_index()\n",
    "        .pipe(lambda df: df.assign(**{'target-species': df['target'].str.cat(df['species'], sep='-')}))\n",
    "    ),\n",
    "    x='target-species',\n",
    "    y='count',\n",
    "    hue='alignment_type',\n",
    ")\n",
    "ax.set_title('Deduplicated reads per species, target, and alignment type')\n",
    "ax.figure.savefig(\n",
    "    os.path.join(DIR_RESULTS, 'paired-end vs. read 1-only alignment counts.png'),\n",
    "    dpi=300,\n",
    "    bbox_inches='tight'\n",
    ")\n",
    "ax.figure.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae32794-1120-4324-a898-4e87a19117c0",
   "metadata": {},
   "source": [
    "## Insert length distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af99239-7d48-4ce4-b31f-57a9d844eccc",
   "metadata": {},
   "source": [
    "Insert length distribution of aligned, properly paired reads after ENCODE blacklist filtering and deduplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14477211-79b6-42bc-ad6b-9d32466615b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, sharex=True, sharey='row', constrained_layout=True)\n",
    "\n",
    "mask_PE = df_chromatin['alignment_type'] == 'PE'\n",
    "\n",
    "# insert length by species\n",
    "sns.ecdfplot(\n",
    "    df_chromatin.loc[mask_PE],\n",
    "    x='length',\n",
    "    hue='species',\n",
    "    ax=axs[0, 0]\n",
    ")\n",
    "sns.histplot(\n",
    "    df_chromatin.loc[mask_PE],\n",
    "    x='length',\n",
    "    # auto binning can lead to artifactual periodic peaks in the histogram --> need to manually set binwidth\n",
    "    # - can verify no actual periodic peaks by manually looking at values in the df_chromatin table\n",
    "    binwidth=5,\n",
    "    hue='species',\n",
    "    ax=axs[1, 0]\n",
    ")\n",
    "\n",
    "# insert length by target\n",
    "sns.ecdfplot(\n",
    "    df_chromatin.loc[mask_PE],\n",
    "    x='length',\n",
    "    hue='target',\n",
    "    ax=axs[0, 1]\n",
    ")\n",
    "sns.histplot(\n",
    "    df_chromatin.loc[mask_PE],\n",
    "    x='length',\n",
    "    binwidth=5,\n",
    "    hue='target',\n",
    "    ax=axs[1, 1]\n",
    ")\n",
    "\n",
    "sns.move_legend(axs[0, 0], loc='lower right')\n",
    "sns.move_legend(axs[0, 1], loc='lower right')\n",
    "sns.move_legend(axs[1, 0], loc='upper right')\n",
    "sns.move_legend(axs[1, 1], loc='upper right')\n",
    "\n",
    "axs[1, 0].set_xlim(0, 1000)\n",
    "axs[1, 0].set_xlabel('length (bp)')\n",
    "axs[1, 0].set_ylabel('Count of deduplicated reads')\n",
    "axs[0, 0].set_title('Insert length by species')\n",
    "axs[0, 1].set_title('Insert length by target')\n",
    "\n",
    "fig.suptitle('Chromatin fragmentation size')\n",
    "fig.savefig(os.path.join(DIR_RESULTS, 'chromatin fragmentation size.png'), bbox_inches='tight', dpi=300)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e31189-b21a-4d69-bc77-514bca339882",
   "metadata": {},
   "source": [
    "## Visualize complexity estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80004f72-786a-4a92-bd11-322e66e7be09",
   "metadata": {},
   "source": [
    "Load complexity curves generated by preseq, and generate complexity curves using my own Poisson models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa29774-886f-4958-b7d3-a2ef2e8f3f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chromatin_complexity_curves = []\n",
    "df_chromatin_complexity_total = []\n",
    "for target in TARGETS:\n",
    "    for species in SPECIES:\n",
    "        for alignment_type in ALIGNMENT_TYPES:\n",
    "\n",
    "            # load complexity curves generated by preseq\n",
    "            path_chromatin_complexity_curve = os.path.join(\n",
    "                DIR_PROC,\n",
    "                f'{target}-{alignment_type}_{species}_filtered_dedup_complexity-curve.txt'\n",
    "            )\n",
    "            path_chromatin_complexity_total = os.path.join(\n",
    "                DIR_PROC,\n",
    "                f'{target}-{alignment_type}_{species}_filtered_dedup_complexity-total.txt'\n",
    "            )\n",
    "            df_chromatin_complexity_curves.append(\n",
    "                pd.read_csv(path_chromatin_complexity_curve, sep='\\t', header=0)\n",
    "                .rename(columns={\n",
    "                    'TOTAL_READS': 'total_reads',\n",
    "                    'EXPECTED_DISTINCT': 'expected_distinct',\n",
    "                    'LOWER_0.95CI': 'lower_ci',\n",
    "                    'UPPER_0.95CI': 'upper_ci'\n",
    "                })\n",
    "                .assign(target=target, species=species, alignment_type=alignment_type, model='preseq')\n",
    "            )\n",
    "            df_chromatin_complexity_total.append(\n",
    "                pd.read_csv(path_chromatin_complexity_total, sep='\\t', header=0)\n",
    "                .assign(target=target, species=species, alignment_type=alignment_type, model='preseq')\n",
    "                .squeeze()\n",
    "            )\n",
    "\n",
    "            # generate complexity curves using my own Poisson models\n",
    "            mask = (df_chromatin['species'] == species) & \\\n",
    "                   (df_chromatin['target'] == target) & \\\n",
    "                   (df_chromatin['alignment_type'] == alignment_type)\n",
    "            count_total = df_chromatin.loc[mask, 'count'].sum()\n",
    "            count_mean = df_chromatin.loc[mask, 'count'].mean()\n",
    "            M = int(estimate_library_complexity2(count_total, count_mean))\n",
    "            df_chromatin_complexity_total.append(\n",
    "                pd.Series(dict(\n",
    "                    target=target,\n",
    "                    species=species,\n",
    "                    alignment_type=alignment_type,\n",
    "                    model='zero-truncated Poisson',\n",
    "                    pop_size_estimate=M\n",
    "                ))\n",
    "            )\n",
    "            total_reads = np.linspace(1, int(3e7), 50, dtype=int)\n",
    "            df_chromatin_complexity_curves.append(\n",
    "                estimate_library_complexity_curve(total_reads, M)\n",
    "                .assign(target=target, species=species, alignment_type=alignment_type, model='Poisson')\n",
    "            )\n",
    "\n",
    "df_chromatin_complexity_curves = (\n",
    "    pd.concat(df_chromatin_complexity_curves, axis=0, ignore_index=True)\n",
    "    .astype({'target': DTYPE_TARGET, 'species': DTYPE_SPECIES, 'alignment_type': DTYPE_ALIGNMENT, 'model': 'category'})\n",
    ")\n",
    "df_chromatin_complexity_total = (\n",
    "    pd.concat(df_chromatin_complexity_total, axis=1, ignore_index=True).T\n",
    "    .astype({'target': DTYPE_TARGET, 'species': DTYPE_SPECIES, 'alignment_type': DTYPE_ALIGNMENT, 'model': 'category'})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c68300a-b98d-45c4-ab64-4698125ab4b3",
   "metadata": {},
   "source": [
    "Plot complexity curves, split by alignment type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece9e666-1378-4d9b-ba40-e54c59e4e4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 4), sharex=True, sharey=True, constrained_layout=True)\n",
    "axs[0].set_title('Alignment: paired end')\n",
    "axs[0].set_xlabel('Total reads')\n",
    "axs[0].set_ylabel('Expected unique reads')\n",
    "axs[1].set_title('Alignment: read 1 only')   \n",
    "\n",
    "def filter_df(df, filter_dict):\n",
    "    mask = np.ones(len(df), dtype=bool)\n",
    "    for col, value in filter_dict.items():\n",
    "        if col in df.columns:\n",
    "            mask &= (df[col] == value)\n",
    "    return df.loc[mask]\n",
    "\n",
    "i = 0\n",
    "for target in TARGETS:\n",
    "    for species in SPECIES:\n",
    "        color = f'C{i}'\n",
    "        i += 1\n",
    "        for model, ls in zip(('preseq', 'Poisson'), ('solid', 'dotted')):\n",
    "            mask_dict = dict(target=target, species=species, model=model, alignment_type='PE')\n",
    "            kwargs = dict(color=color, ls=ls, label=f'{target}, {species} ({model})')\n",
    "            axs[0].plot(\n",
    "                filter_df(df_chromatin_complexity_curves, mask_dict)['total_reads'],\n",
    "                filter_df(df_chromatin_complexity_curves, mask_dict)['expected_distinct'],\n",
    "                **kwargs\n",
    "            )\n",
    "            mask_dict = dict(target=target, species=species, model=model, alignment_type='R1')\n",
    "            axs[1].plot(\n",
    "                filter_df(df_chromatin_complexity_curves, mask_dict)['total_reads'],\n",
    "                filter_df(df_chromatin_complexity_curves, mask_dict)['expected_distinct'],\n",
    "                **kwargs\n",
    "            )\n",
    "            if model == 'Poisson':\n",
    "                kwargs = dict(color=color, ls='dashed', label=f'{target}, {species} (current reads)')\n",
    "                axs[0].axvline(\n",
    "                    filter_df(df_chromatin, mask_dict)['count'].sum(),\n",
    "                    **kwargs\n",
    "                )\n",
    "                axs[1].axvline(\n",
    "                    filter_df(df_chromatin, mask_dict)['count'].sum(),\n",
    "                    **kwargs\n",
    "                )\n",
    "axs[1].legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "fig.suptitle('Complexity curves')\n",
    "fig.savefig(\n",
    "    os.path.join(DIR_RESULTS, 'chromatin complexity curves.png'),\n",
    "    dpi=300,\n",
    "    bbox_inches='tight'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311770c4-0985-4fbc-9756-9f5deec316c6",
   "metadata": {},
   "source": [
    "Calculate estimated proportion of library complexity sequenced, based on paired-end alignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa9de45-6806-4d3b-89d2-d380665e3986",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "x = 1\n",
    "xlabels = []\n",
    "for target in TARGETS:\n",
    "    for species in SPECIES:\n",
    "        xlabels.append(f'{target}-{species}')\n",
    "        mask_dict = dict(target=target, species=species, alignment_type='PE', model='preseq')\n",
    "        complexity_estimate = filter_df(df_chromatin_complexity_total, mask_dict).squeeze()['pop_size_estimate']\n",
    "        complexity_observed = len(filter_df(df_chromatin, mask_dict))\n",
    "        ax.bar(x, complexity_observed, facecolor=f'C{x-1}')\n",
    "        ax.bar(x, complexity_estimate, facecolor=(0, 0, 0, 0), edgecolor=f'C{x-1}', linewidth=2, ls='dotted')\n",
    "        ax.text(\n",
    "            x,\n",
    "            complexity_observed + 0.2e6,\n",
    "            f'{complexity_observed / complexity_estimate:.1%}',\n",
    "            ha='center'\n",
    "        )\n",
    "        x += 1\n",
    "ax.set_xticks([1, 2, 3, 4], xlabels)\n",
    "ax.set_title('Proportion of estimated total chromatin molecules sequenced')\n",
    "\n",
    "legend_elements = [\n",
    "    matplotlib.patches.Patch(facecolor='black', label='sequenced'),\n",
    "    matplotlib.lines.Line2D([0], [0], color='black', lw=2, ls='dotted', label='estimated complexity')\n",
    "]\n",
    "ax.legend(handles=legend_elements, loc='best')\n",
    "\n",
    "fig.savefig(\n",
    "    os.path.join(DIR_RESULTS, 'proportion chromatin sequenced.png'),\n",
    "    dpi=300,\n",
    "    bbox_inches='tight'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d79f35-dad7-4b97-86ff-50a87f92c819",
   "metadata": {},
   "source": [
    "## Verify that alignment to combined human-mouse genome correctly distinguished chromatin species\n",
    "\n",
    "Note: I only perform this analysis on paired-end alignments, not on read 1-only alignments.\n",
    "\n",
    "Conclusion: alignment to the combined genome largely identified the correct species.\n",
    "- For >99.9% of read pairs, the alignment to the identified species genome gave an alignment score >= that of aligning to the combined genome, whereas alignment to the other species genome gave worse alignments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c267884-9f5f-45b2-8cde-e851a30059ef",
   "metadata": {},
   "source": [
    "Extract MAPQ and alignment scores (`AS:i:[#]` SAM tag) into table with columns:\n",
    "- aligned species using combined genome\n",
    "- protein target (CTCF or H3K4me3)\n",
    "- R1 MAPQ, combined genome\n",
    "- R2 MAPQ, combined genome\n",
    "- R1 MAPQ, human genome\n",
    "- R2 MAPQ, human genome\n",
    "- R1 MAPQ, mouse genome\n",
    "- R2 MAPQ, mouse genome\n",
    "- R1 AS, combined genome\n",
    "- R2 AS, combined genome\n",
    "- R1 AS, combined genome\n",
    "- R2 AS, combined genome\n",
    "- R1 AS, combined genome\n",
    "- R2 AS, combined genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b1b813-81ca-417a-b345-4f32ffa14062",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_r1_r2(\n",
    "    ref_r1: pysam.AlignedSegment,\n",
    "    ref_r2: pysam.AlignedSegment,\n",
    "    new_r1: pysam.AlignedSegment,\n",
    "    new_r2: pysam.AlignedSegment\n",
    "):\n",
    "    '''\n",
    "    Given the alignment of two read pairs of a query template (one pair as a reference alignment,\n",
    "    one pair as a new alignment), return reorder the reads from the new read pair (if necessary)\n",
    "    to match the order of reads from the reference alignment pair.\n",
    "\n",
    "    Approach\n",
    "    - Compare read sequence\n",
    "    - Compare read alignment orientations\n",
    "    '''\n",
    "    assert all(x.query_name == ref_r1.query_name for x in (ref_r2, new_r1, new_r2))\n",
    "    ref_seqs = (ref_r1.get_forward_sequence(), ref_r2.get_forward_sequence())\n",
    "    new_seqs = (new_r1.get_forward_sequence(), new_r2.get_forward_sequence())\n",
    "    if new_seqs[0] == new_seqs[1]:\n",
    "        # if read 1 and read 2 sequences are the same:\n",
    "        # - if both reads are unmapped, then the order is irrelevant\n",
    "        # - if only 1 read is mapped, then match it to the reference read 1 or read 2 by orientation\n",
    "        # - if both reads are mapped, then directly compare the alignments to the reference reads\n",
    "        if new_r1.is_unmapped and new_r2.is_unmapped:\n",
    "            return (new_r1, new_r2)\n",
    "        elif new_r1.is_unmapped:\n",
    "            if new_r2.is_reverse == ref_r1.is_reverse:\n",
    "                return (new_r2, new_r1)\n",
    "            else:\n",
    "                return (new_r1, new_r2)\n",
    "        elif new_r2.is_unmapped:\n",
    "            if new_r1.is_reverse == ref_r1.is_reverse:\n",
    "                return (new_r1, new_r2)\n",
    "            else:\n",
    "                return (new_r2, new_r1)\n",
    "        else:\n",
    "            if ref_r1.compare(new_r1) == 0:\n",
    "                return (new_r1, new_r2)\n",
    "            elif ref_r1.compare(new_r2) == 0:\n",
    "                return (new_r2, new_r1)\n",
    "            if new_r1.is_reverse and new_r2.is_reverse:\n",
    "                # no implementation yet for this edge case where read 1 and read 2 sequences are identical,\n",
    "                # they are both mapped using the same orientation, and their alignments are different from\n",
    "                # the reference alignments\n",
    "                raise ValueError\n",
    "    if new_seqs == ref_seqs:\n",
    "        # based on matching the read sequences, the ordering of the new read pair was already correct\n",
    "        return new_r1, new_r2\n",
    "    elif (new_seqs[1], new_seqs[0]) == ref_seqs:\n",
    "        # based on matching the read sequences, the ordering of the new read pair was flipped\n",
    "        return new_r2, new_r1\n",
    "    else:\n",
    "        # the code should never get here, which would mean that the new read sequences\n",
    "        # do not match the reference read sequences\n",
    "        raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a929c2cf-fe20-4671-b3e2-1b1345b955b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores = []\n",
    "for target in TARGETS:\n",
    "    for species in SPECIES:\n",
    "        scores = []\n",
    "        # these are all name-sorted BAM files\n",
    "        path_bam_combined = os.path.join(DIR_PROC, f'{target}-PE_{species}_filtered_dedup_sort-name.bam')\n",
    "        path_bam_human = os.path.join(DIR_PROC, f'{target}-PE_{species}_realign-human.bam')\n",
    "        path_bam_mouse = os.path.join(DIR_PROC, f'{target}-PE_{species}_realign-mouse.bam')\n",
    "        with pysam.AlignmentFile(path_bam_combined, 'rb', threads=n_proc) as fc, \\\n",
    "             pysam.AlignmentFile(path_bam_human, 'rb', threads=n_proc) as fh, \\\n",
    "             pysam.AlignmentFile(path_bam_mouse, 'rb', threads=n_proc) as fm:\n",
    "            for (r1c, r2c), (r1h, r2h), (r1m, r2m) in tqdm(zip(\n",
    "                grouper(fc.fetch(until_eof=True), 2, incomplete='strict'),\n",
    "                grouper(fh.fetch(until_eof=True), 2, incomplete='strict'),\n",
    "                grouper(fm.fetch(until_eof=True), 2, incomplete='strict'))):\n",
    "                r1h, r2h = match_r1_r2(r1c, r2c, r1h, r2h)\n",
    "                r1m, r2m = match_r1_r2(r1c, r2c, r1m, r2m)\n",
    "                scores.append(dict(\n",
    "                    MAPQ_combined_R1=r1c.mapping_quality,\n",
    "                    MAPQ_combined_R2=r2c.mapping_quality,\n",
    "                    MAPQ_human_R1=r1h.mapping_quality,\n",
    "                    MAPQ_human_R2=r2h.mapping_quality,\n",
    "                    MAPQ_mouse_R1=r1m.mapping_quality,\n",
    "                    MAPQ_mouse_R2=r2m.mapping_quality,\n",
    "                    AS_combined_R1=r1c.get_tag('AS') if r1c.has_tag('AS') else pd.NA,\n",
    "                    AS_combined_R2=r2c.get_tag('AS') if r2c.has_tag('AS') else pd.NA,\n",
    "                    AS_human_R1=r1h.get_tag('AS') if r1h.has_tag('AS') else pd.NA,\n",
    "                    AS_human_R2=r2h.get_tag('AS') if r2h.has_tag('AS') else pd.NA,\n",
    "                    AS_mouse_R1=r1m.get_tag('AS') if r1m.has_tag('AS') else pd.NA,\n",
    "                    AS_mouse_R2=r2m.get_tag('AS') if r2m.has_tag('AS') else pd.NA,\n",
    "                ))\n",
    "        scores = (\n",
    "            pd.DataFrame(scores)\n",
    "            .astype(pd.Int64Dtype())\n",
    "            .assign(target=target, species=species)\n",
    "            .astype(dict(target=DTYPE_TARGET, species=DTYPE_SPECIES))\n",
    "        )\n",
    "        df_scores.append(scores)\n",
    "df_scores = pd.concat(df_scores, axis=0, ignore_index=True)\n",
    "del scores\n",
    "gc.collect()\n",
    "df_scores.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab9fdbd-cb1c-4bac-a34e-07fab04bae88",
   "metadata": {},
   "source": [
    "Proportion of read pairs that may be ambiguous or misassigned - i.e., that have equal or higher alignment scores on the other genome than the one assigned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbc5d17-3ff6-4cfc-b53c-8ce05d3ecc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def misassigned_and_ambiguous(df):\n",
    "    mask_human = df['species'] == 'human'\n",
    "    mask_mouse = df['species'] == 'mouse'\n",
    "    d = {\n",
    "        'assigned human': mask_human.sum(),\n",
    "        'misassigned human': (mask_human & (df[['AS_human', 'AS_combined']].max(axis=1) < df['AS_mouse'])).sum(),\n",
    "        'ambiguous human': (mask_human & (df[['AS_human', 'AS_combined']].max(axis=1) == df['AS_mouse'])).sum(),\n",
    "        'assigned mouse': mask_mouse.sum(),\n",
    "        'misassigned mouse': (mask_mouse & (df[['AS_mouse', 'AS_combined']].max(axis=1) < df['AS_human'])).sum(),\n",
    "        'ambiguous mouse': (mask_mouse & (df[['AS_mouse', 'AS_combined']].max(axis=1) == df['AS_human'])).sum()\n",
    "    }\n",
    "    return d\n",
    "\n",
    "d = df_scores.assign(\n",
    "    AS_combined=df_scores['AS_combined_R1'] + df_scores['AS_combined_R1'],\n",
    "    AS_human=df_scores['AS_human_R1'] + df_scores['AS_human_R2'],\n",
    "    AS_mouse=df_scores['AS_mouse_R1'] + df_scores['AS_mouse_R2']\n",
    ").pipe(misassigned_and_ambiguous)\n",
    "\n",
    "print('proportion misassigned to human: {} / {} = {:.2%}'.format(\n",
    "    d['misassigned human'],\n",
    "    d['assigned human'],\n",
    "    d['misassigned human'] / d['assigned human']\n",
    "))\n",
    "\n",
    "print('proportion ambiguously assigned to human: {} / {} = {:.2%}'.format(\n",
    "    d['ambiguous human'],\n",
    "    d['assigned human'],\n",
    "    d['ambiguous human'] / d['assigned human']\n",
    "))\n",
    "\n",
    "print('proportion misassigned to mouse: {} / {} = {:.2%}'.format(\n",
    "    d['misassigned mouse'],\n",
    "    d['assigned mouse'],\n",
    "    d['misassigned mouse'] / d['assigned mouse']\n",
    "))\n",
    "\n",
    "print('proportion ambiguously assigned to mouse: {} / {} = {:.2%}'.format(\n",
    "    d['ambiguous mouse'],\n",
    "    d['assigned mouse'],\n",
    "    d['ambiguous mouse'] / d['assigned mouse']\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08415d3-16fc-48c6-bee8-92c2482b2b5e",
   "metadata": {},
   "source": [
    "For read pairs aligned (via the combined genome) to **human chromosomes**, visualize relationship between **alignment scores** on the combined genome versus individual species genomes. Here, I calculate the alignment score for the read pair as the sum of alignment scores of read 1 and read 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65222e2-1598-4832-90bd-7d52f184d375",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(8, 5), sharex=True, sharey=True, constrained_layout=True)\n",
    "mask_human_CTCF = (df_scores['species'] == 'human') & (df_scores['target'] == 'CTCF')\n",
    "mask_human_H3K4me3 = (df_scores['species'] == 'human') & (df_scores['target'] == 'H3K4me3')\n",
    "\n",
    "axs[0, 0].set_title('CTCF ChIP')\n",
    "axs[0, 0] = sns.histplot(\n",
    "    (\n",
    "        df_scores.loc[mask_human_CTCF]\n",
    "        .pipe(lambda df: df.assign(**{\n",
    "            'combined genomes': df['AS_combined_R1'] + df['AS_combined_R2'],\n",
    "            'human genome': df['AS_human_R1'] + df['AS_human_R2']\n",
    "        }))\n",
    "    ),\n",
    "    x='combined genomes',\n",
    "    y='human genome',\n",
    "    bins=30,\n",
    "    discrete=(True, True),\n",
    "    cbar=True, cbar_kws=dict(shrink=1, format=\"%.e\"),\n",
    "    ax=axs[0, 0]\n",
    ")\n",
    "axs[1, 0] = sns.histplot(\n",
    "    (\n",
    "        df_scores.loc[mask_human_CTCF]\n",
    "        .pipe(lambda df: df.assign(**{\n",
    "            'combined genomes': df['AS_combined_R1'] + df['AS_combined_R2'],\n",
    "            'mouse genome': df['AS_mouse_R1'] + df['AS_mouse_R2']\n",
    "        }))\n",
    "    ),\n",
    "    x='combined genomes',\n",
    "    y='mouse genome',\n",
    "    bins=30,\n",
    "    discrete=(True, True),\n",
    "    cbar=True, cbar_kws=dict(shrink=1, format=\"%.e\"),\n",
    "    ax=axs[1, 0]\n",
    ")\n",
    "\n",
    "axs[0, 1].set_title('H3K4me3 ChIP')\n",
    "axs[0, 1] = sns.histplot(\n",
    "    (\n",
    "        df_scores.loc[mask_human_H3K4me3]\n",
    "        .pipe(lambda df: df.assign(**{\n",
    "            'combined genomes': df['AS_combined_R1'] + df['AS_combined_R2'],\n",
    "            'human genome': df['AS_human_R1'] + df['AS_human_R2']\n",
    "        }))\n",
    "    ),\n",
    "    x='combined genomes',\n",
    "    y='human genome',\n",
    "    bins=30,\n",
    "    discrete=(True, True),\n",
    "    cbar=True, cbar_kws=dict(shrink=1, format=\"%.e\"),\n",
    "    ax=axs[0, 1]\n",
    ")\n",
    "axs[1, 1] = sns.histplot(\n",
    "    (\n",
    "        df_scores.loc[mask_human_H3K4me3]\n",
    "        .pipe(lambda df: df.assign(**{\n",
    "            'combined genomes': df['AS_combined_R1'] + df['AS_combined_R2'],\n",
    "            'mouse genome': df['AS_mouse_R1'] + df['AS_mouse_R2']\n",
    "        }))\n",
    "    ),\n",
    "    x='combined genomes',\n",
    "    y='mouse genome',\n",
    "    bins=30,\n",
    "    discrete=(True, True),\n",
    "    cbar=True, cbar_kws=dict(shrink=1, format=\"%.e\"),\n",
    "    ax=axs[1, 1]\n",
    ")\n",
    "\n",
    "fig.suptitle('Distribution of paired-end alignment scores of human-assigned reads')\n",
    "fig.savefig(\n",
    "    os.path.join(DIR_RESULTS, 'paired-end alignment scores, human.png'),\n",
    "    dpi=300,\n",
    "    bbox_inches='tight'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd4f53a-77e1-487d-93a7-d283d44a25cc",
   "metadata": {},
   "source": [
    "For read pairs aligned (via the combined genome) to **mouse chromosomes**, visualize relationship between **alignment scores** on the combined genome versus individual species genomes. Here, I calculate the alignment score for the read pair as the sum of alignment scores of read 1 and read 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c6a04f-c10c-4a2d-adee-26207c291dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(8, 5), sharex=True, sharey=True, constrained_layout=True)\n",
    "mask_mouse_CTCF = (df_scores['species'] == 'mouse') & (df_scores['target'] == 'CTCF')\n",
    "mask_mouse_H3K4me3 = (df_scores['species'] == 'mouse') & (df_scores['target'] == 'H3K4me3')\n",
    "\n",
    "axs[0, 0].set_title('CTCF ChIP')\n",
    "axs[0, 0] = sns.histplot(\n",
    "    (\n",
    "        df_scores.loc[mask_mouse_CTCF]\n",
    "        .pipe(lambda df: df.assign(**{\n",
    "            'combined genomes': df['AS_combined_R1'] + df['AS_combined_R2'],\n",
    "            'human genome': df['AS_human_R1'] + df['AS_human_R2']\n",
    "        }))\n",
    "    ),\n",
    "    x='combined genomes',\n",
    "    y='human genome',\n",
    "    bins=30,\n",
    "    discrete=(True, True),\n",
    "    cbar=True, cbar_kws=dict(shrink=1, format=\"%.e\"),\n",
    "    ax=axs[0, 0]\n",
    ")\n",
    "axs[1, 0] = sns.histplot(\n",
    "    (\n",
    "        df_scores.loc[mask_mouse_CTCF]\n",
    "        .pipe(lambda df: df.assign(**{\n",
    "            'combined genomes': df['AS_combined_R1'] + df['AS_combined_R2'],\n",
    "            'mouse genome': df['AS_mouse_R1'] + df['AS_mouse_R2']\n",
    "        }))\n",
    "    ),\n",
    "    x='combined genomes',\n",
    "    y='mouse genome',\n",
    "    bins=30,\n",
    "    discrete=(True, True),\n",
    "    cbar=True, cbar_kws=dict(shrink=1, format=\"%.e\"),\n",
    "    ax=axs[1, 0]\n",
    ")\n",
    "\n",
    "axs[0, 1].set_title('H3K4me3 ChIP')\n",
    "axs[0, 1] = sns.histplot(\n",
    "    (\n",
    "        df_scores.loc[mask_mouse_H3K4me3]\n",
    "        .pipe(lambda df: df.assign(**{\n",
    "            'combined genomes': df['AS_combined_R1'] + df['AS_combined_R2'],\n",
    "            'human genome': df['AS_human_R1'] + df['AS_human_R2']\n",
    "        }))\n",
    "    ),\n",
    "    x='combined genomes',\n",
    "    y='human genome',\n",
    "    bins=30,\n",
    "    discrete=(True, True),\n",
    "    cbar=True, cbar_kws=dict(shrink=1, format=\"%.e\"),\n",
    "    ax=axs[0, 1]\n",
    ")\n",
    "axs[1, 1] = sns.histplot(\n",
    "    (\n",
    "        df_scores.loc[mask_mouse_H3K4me3]\n",
    "        .pipe(lambda df: df.assign(**{\n",
    "            'combined genomes': df['AS_combined_R1'] + df['AS_combined_R2'],\n",
    "            'mouse genome': df['AS_mouse_R1'] + df['AS_mouse_R2']\n",
    "        }))\n",
    "    ),\n",
    "    x='combined genomes',\n",
    "    y='mouse genome',\n",
    "    bins=30,\n",
    "    discrete=(True, True),\n",
    "    cbar=True, cbar_kws=dict(shrink=1, format=\"%.e\"),\n",
    "    ax=axs[1, 1]\n",
    ")\n",
    "\n",
    "fig.suptitle('Distribution of paired-end alignment scores of mouse-assigned reads')\n",
    "fig.savefig(\n",
    "    os.path.join(DIR_RESULTS, 'paired-end alignment scores, mouse.png'),\n",
    "    dpi=300,\n",
    "    bbox_inches='tight'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f63073-1b49-45f3-8d1c-0d471ef7f871",
   "metadata": {},
   "source": [
    "For read pairs aligned (via the combined genome) to **human chromosomes**, visualize relationship between **mapping quality (MAPQ) scores** on the combined genome versus individual species genomes. Here, I calculate the mapping quality score for the read pair as the sum of mapping quality scores of read 1 and read 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b693bfbb-bc2b-4cb4-869c-f8519ecdc451",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(8, 5), sharex=True, sharey=True, constrained_layout=True)\n",
    "mask_human_CTCF = (df_scores['species'] == 'human') & (df_scores['target'] == 'CTCF')\n",
    "mask_human_H3K4me3 = (df_scores['species'] == 'human') & (df_scores['target'] == 'H3K4me3')\n",
    "\n",
    "axs[0, 0].set_title('CTCF ChIP')\n",
    "axs[0, 0] = sns.histplot(\n",
    "    (\n",
    "        df_scores.loc[mask_human_CTCF]\n",
    "        .pipe(lambda df: df.assign(**{\n",
    "            'combined genomes': df['MAPQ_combined_R1'] + df['MAPQ_combined_R2'],\n",
    "            'human genome': df['MAPQ_human_R1'] + df['MAPQ_human_R2']\n",
    "        }))\n",
    "    ),\n",
    "    x='combined genomes',\n",
    "    y='human genome',\n",
    "    bins=30,\n",
    "    discrete=(True, True),\n",
    "    cbar=True, cbar_kws=dict(shrink=1, format=\"%.e\"),\n",
    "    ax=axs[0, 0]\n",
    ")\n",
    "axs[1, 0] = sns.histplot(\n",
    "    (\n",
    "        df_scores.loc[mask_human_CTCF]\n",
    "        .pipe(lambda df: df.assign(**{\n",
    "            'combined genomes': df['MAPQ_combined_R1'] + df['MAPQ_combined_R2'],\n",
    "            'mouse genome': df['MAPQ_mouse_R1'] + df['MAPQ_mouse_R2']\n",
    "        }))\n",
    "    ),\n",
    "    x='combined genomes',\n",
    "    y='mouse genome',\n",
    "    bins=30,\n",
    "    discrete=(True, True),\n",
    "    cbar=True, cbar_kws=dict(shrink=1, format=\"%.e\"),\n",
    "    ax=axs[1, 0]\n",
    ")\n",
    "\n",
    "axs[0, 1].set_title('H3K4me3 ChIP')\n",
    "axs[0, 1] = sns.histplot(\n",
    "    (\n",
    "        df_scores.loc[mask_human_H3K4me3]\n",
    "        .pipe(lambda df: df.assign(**{\n",
    "            'combined genomes': df['MAPQ_combined_R1'] + df['MAPQ_combined_R2'],\n",
    "            'human genome': df['MAPQ_human_R1'] + df['MAPQ_human_R2']\n",
    "        }))\n",
    "    ),\n",
    "    x='combined genomes',\n",
    "    y='human genome',\n",
    "    bins=30,\n",
    "    discrete=(True, True),\n",
    "    cbar=True, cbar_kws=dict(shrink=1, format=\"%.e\"),\n",
    "    ax=axs[0, 1]\n",
    ")\n",
    "axs[1, 1] = sns.histplot(\n",
    "    (\n",
    "        df_scores.loc[mask_human_H3K4me3]\n",
    "        .pipe(lambda df: df.assign(**{\n",
    "            'combined genomes': df['MAPQ_combined_R1'] + df['MAPQ_combined_R2'],\n",
    "            'mouse genome': df['MAPQ_mouse_R1'] + df['MAPQ_mouse_R2']\n",
    "        }))\n",
    "    ),\n",
    "    x='combined genomes',\n",
    "    y='mouse genome',\n",
    "    bins=30,\n",
    "    discrete=(True, True),\n",
    "    cbar=True, cbar_kws=dict(shrink=1, format=\"%.e\"),\n",
    "    ax=axs[1, 1]\n",
    ")\n",
    "\n",
    "fig.suptitle('Distribution of paired-end MAPQ scores of human-assigned reads')\n",
    "fig.savefig(\n",
    "    os.path.join(DIR_RESULTS, 'paired-end MAPQ scores, human.png'),\n",
    "    dpi=300,\n",
    "    bbox_inches='tight'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60365052-05e3-4a44-88e7-a5fae0333982",
   "metadata": {},
   "source": [
    "For read pairs aligned (via the combined genome) to **mouse chromosomes**, visualize relationship between **mapping quality (MAPQ) scores** on the combined genome versus individual species genomes. Here, I calculate the mapping quality score for the read pair as the sum of mapping quality scores of read 1 and read 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d79790-d0be-467f-8306-1bcb6a127d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(8, 5), sharex=True, sharey=True, constrained_layout=True)\n",
    "mask_mouse_CTCF = (df_scores['species'] == 'mouse') & (df_scores['target'] == 'CTCF')\n",
    "mask_mouse_H3K4me3 = (df_scores['species'] == 'mouse') & (df_scores['target'] == 'H3K4me3')\n",
    "\n",
    "axs[0, 0].set_title('CTCF ChIP')\n",
    "axs[0, 0] = sns.histplot(\n",
    "    (\n",
    "        df_scores.loc[mask_mouse_CTCF]\n",
    "        .pipe(lambda df: df.assign(**{\n",
    "            'combined genomes': df['MAPQ_combined_R1'] + df['MAPQ_combined_R2'],\n",
    "            'human genome': df['MAPQ_human_R1'] + df['MAPQ_human_R2']\n",
    "        }))\n",
    "    ),\n",
    "    x='combined genomes',\n",
    "    y='human genome',\n",
    "    bins=30,\n",
    "    discrete=(True, True),\n",
    "    cbar=True, cbar_kws=dict(shrink=1, format=\"%.e\"),\n",
    "    ax=axs[0, 0]\n",
    ")\n",
    "axs[1, 0] = sns.histplot(\n",
    "    (\n",
    "        df_scores.loc[mask_mouse_CTCF]\n",
    "        .pipe(lambda df: df.assign(**{\n",
    "            'combined genomes': df['MAPQ_combined_R1'] + df['MAPQ_combined_R2'],\n",
    "            'mouse genome': df['MAPQ_mouse_R1'] + df['MAPQ_mouse_R2']\n",
    "        }))\n",
    "    ),\n",
    "    x='combined genomes',\n",
    "    y='mouse genome',\n",
    "    bins=30,\n",
    "    discrete=(True, True),\n",
    "    cbar=True, cbar_kws=dict(shrink=1, format=\"%.e\"),\n",
    "    ax=axs[1, 0]\n",
    ")\n",
    "\n",
    "axs[0, 1].set_title('H3K4me3 ChIP')\n",
    "axs[0, 1] = sns.histplot(\n",
    "    (\n",
    "        df_scores.loc[mask_mouse_H3K4me3]\n",
    "        .pipe(lambda df: df.assign(**{\n",
    "            'combined genomes': df['MAPQ_combined_R1'] + df['MAPQ_combined_R2'],\n",
    "            'human genome': df['MAPQ_human_R1'] + df['MAPQ_human_R2']\n",
    "        }))\n",
    "    ),\n",
    "    x='combined genomes',\n",
    "    y='human genome',\n",
    "    bins=30,\n",
    "    discrete=(True, True),\n",
    "    cbar=True, cbar_kws=dict(shrink=1, format=\"%.e\"),\n",
    "    ax=axs[0, 1]\n",
    ")\n",
    "axs[1, 1] = sns.histplot(\n",
    "    (\n",
    "        df_scores.loc[mask_mouse_H3K4me3]\n",
    "        .pipe(lambda df: df.assign(**{\n",
    "            'combined genomes': df['MAPQ_combined_R1'] + df['MAPQ_combined_R2'],\n",
    "            'mouse genome': df['MAPQ_mouse_R1'] + df['MAPQ_mouse_R2']\n",
    "        }))\n",
    "    ),\n",
    "    x='combined genomes',\n",
    "    y='mouse genome',\n",
    "    bins=30,\n",
    "    discrete=(True, True),\n",
    "    cbar=True, cbar_kws=dict(shrink=1, format=\"%.e\"),\n",
    "    ax=axs[1, 1]\n",
    ")\n",
    "\n",
    "fig.suptitle('Distribution of paired-end MAPQ scores of mouse-assigned reads')\n",
    "fig.savefig(\n",
    "    os.path.join(DIR_RESULTS, 'paired-end MAPQ scores, mouse.png'),\n",
    "    dpi=300,\n",
    "    bbox_inches='tight'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0dcf76-11af-4294-ac4c-946c2d5a1ed1",
   "metadata": {},
   "source": [
    "Proportion of read pairs with lower alignment scores (summed across read 1 and read 2) when aligned to their assigned genome than aligned to the combined genome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f19e5c-d6fc-443b-9f1f-743bda285628",
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_lower_score = []\n",
    "for species in SPECIES:\n",
    "    mask_denom = (df_scores['species'] == species)\n",
    "    mask_num = mask_denom & \\\n",
    "        ((df_scores[f'AS_{species}_R1'] + df_scores[f'AS_{species}_R2'] < df_scores['AS_combined_R1'] + df_scores['AS_combined_R2']) |\n",
    "         (df_scores[f'AS_{species}_R1'].isna() | df_scores[f'AS_{species}_R2'].isna()))\n",
    "    prop_lower_score.append({'species': species, 'lower score count': mask_num.sum(), 'total': mask_denom.sum(), 'new genome': species})\n",
    "    species2 = 'mouse' if species == 'human' else 'human'\n",
    "    mask_num2 = mask_denom & \\\n",
    "        ((df_scores[f'AS_{species2}_R1'] + df_scores[f'AS_{species2}_R2'] < df_scores['AS_combined_R1'] + df_scores['AS_combined_R2']) |\n",
    "         (df_scores[f'AS_{species2}_R1'].isna() | df_scores[f'AS_{species2}_R2'].isna()))\n",
    "    prop_lower_score.append({'species': species, 'lower score count': mask_num2.sum(), 'total': mask_denom.sum(), 'new genome': species2})\n",
    "prop_lower_score = pd.DataFrame(prop_lower_score)\n",
    "prop_lower_score['proportion'] = prop_lower_score['lower score count'] / prop_lower_score['total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf7eee2-d462-4492-860c-2b2cccf0a5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(6, 5), sharey=True, constrained_layout=True)\n",
    "sns.barplot(\n",
    "    prop_lower_score.loc[prop_lower_score['species'] == prop_lower_score['new genome']],\n",
    "    x='species',\n",
    "    y='proportion',\n",
    "    ax=axs[0]\n",
    ")\n",
    "axs[0].set_ylabel('\\n'.join((\n",
    "    'proportion of read pairs with lower alignment scores',\n",
    "    'to species-specific genome than to combined genome'\n",
    ")))\n",
    "axs[0].set_xlabel('species assigned\\nand used for realignment')\n",
    "\n",
    "sns.barplot(\n",
    "    prop_lower_score.loc[prop_lower_score['species'] != prop_lower_score['new genome']],\n",
    "    x='species',\n",
    "    y='proportion',\n",
    "    ax=axs[1]\n",
    ")\n",
    "axs[1].set_xlabel('species used for realignment\\n(opposite assigned)')\n",
    "\n",
    "for ax in axs:\n",
    "    for container in ax.containers:\n",
    "        ax.bar_label(container, fmt='{:.3%}')\n",
    "\n",
    "fig.savefig(\n",
    "    os.path.join(DIR_RESULTS, 'proportion of read pairs with lower alignment scores.png'),\n",
    "    dpi=300,\n",
    "    bbox_inches='tight'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e95f88-8a55-4915-9b3c-8ebc4b55c446",
   "metadata": {},
   "source": [
    "**For a read pair that Bowtie 2 aligned to a chromosome of species X in the combined genome, why would the read pair yield a lower alignment score when aligned directly to the genome of species X?**\n",
    "\n",
    "If the read pair truly came from species X, one possibility is that when read seeds were aligned to the combined genome, the number of seed hits exceeded the \"repetitive seeds\" threshold, prompting Bowtie 2 to use different (perhaps more optimal) seeds that eventually led to a better alignment to the species X genome. The initial seeds never exceeded the \"repetitive seeds\" threshold when aligned only against the species X genome, such that the more optimal seeds were never used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5cfa6a-4e9b-4c73-af8c-f760c4d5625a",
   "metadata": {},
   "source": [
    "## Molecules per bead"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28903cf5-5de4-4b78-9544-8389aa33ed8f",
   "metadata": {},
   "source": [
    "### Beads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d316d5-537f-4531-887a-c50be3335f16",
   "metadata": {},
   "source": [
    "Total number of bead barcodes identified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b183b5d-7a19-4c10-8540-160659d2a723",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_beads_total = !unpigz -c {os.path.join(DIR_PROC, 'mapping_bead-barcode.tsv.gz')} | wc -l\n",
    "n_beads_total = int(n_beads_total[0])\n",
    "print(n_beads_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2555748-189d-436f-b83d-f2762c4f7cb8",
   "metadata": {},
   "source": [
    "Number of beads with oligos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb65b2d-e1cb-4809-9622-d1415162fcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df_beads' not in locals().keys() or reprocess:\n",
    "    display(len(df_oligos))\n",
    "else:\n",
    "    display(((df_beads['human oligo'] > 0) | (df_beads['mouse oligo'] > 0)).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4329a610-6539-4999-9814-fcd2f8de322c",
   "metadata": {},
   "source": [
    "Number of beads with aligned, species-specific, non-blacklisted chromatin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658211d1-dab1-49f0-ad21-35a4d5382a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_chromatin['bead'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f93bd79-b35a-4cf7-a123-22cab6142ea3",
   "metadata": {},
   "source": [
    "Create table of oligo and chromatin counts for each bead.\n",
    "- The chromatin counts are deduplicated.\n",
    "- The oligo counts are not, since they do not have UMIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047c3cf5-cc7e-402a-91ba-86b5bb0450a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(path_bead_counts) or reprocess:\n",
    "    df_chromatin_counts = (\n",
    "        df_chromatin\n",
    "        .loc[df_chromatin['alignment_type'] == 'PE']\n",
    "        .groupby(['bead', 'target', 'species'], observed=True)\n",
    "        .size()\n",
    "        .rename('count')\n",
    "        .reset_index()\n",
    "        .pivot(index='bead', columns=['species', 'target'], values='count')\n",
    "        .fillna(0)\n",
    "        .astype(int)\n",
    "    )\n",
    "    df_chromatin_counts.columns = [' '.join(col).strip() for col in df_chromatin_counts.columns.values]\n",
    "\n",
    "    df_beads = (\n",
    "        df_oligos\n",
    "        .rename(columns={'human': 'human oligo', 'mouse': 'mouse oligo'})\n",
    "        .join(df_chromatin_counts, how='outer')\n",
    "        .fillna(0)\n",
    "        .astype(np.int32)\n",
    "    )\n",
    "\n",
    "    # because of its sparsity, saving this DataFrame in a compressed .npz format saves significant space\n",
    "    np.savez_compressed(\n",
    "        path_bead_counts,\n",
    "        index=df_beads.index.values,\n",
    "        values=df_beads.values\n",
    "    )\n",
    "elif 'df_beads' not in locals().keys():\n",
    "    df_beads = pd.DataFrame(\n",
    "        data=np.load(path_bead_counts)['values'],\n",
    "        index=pd.Index(np.load(path_bead_counts)['index'], name='bead'),\n",
    "        columns=['human oligo', 'mouse oligo', 'human H3K4me3', 'mouse H3K4me3', 'human CTCF', 'mouse CTCF'],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb4a199-2e71-4f17-a1b0-2e7690157394",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_beads.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5473b0f3-54e1-4e0a-9e8d-47dab119da9c",
   "metadata": {},
   "source": [
    "Sparsity (proportion of values that are zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c137b3-714e-4bb0-8b9f-b58f891199ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_beads.values == 0).sum().sum() / np.size(df_beads.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a1df41-6311-4bc3-a829-747049ddc7c8",
   "metadata": {},
   "source": [
    "Proportion of beads with any oligo or *filtered* (uniquely aligned and not blacklisted) chromatin molecule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cae346-c905-41ee-8ace-f05445f433d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Proportion of beads with any oligo or filtered chromatin molecule: {} / {} = {:.2%}'.format(\n",
    "    len(df_beads),\n",
    "    n_beads_total,\n",
    "    len(df_beads) / n_beads_total\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8139a574-aa99-472a-9161-485a0f2d4100",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLS_CHROMATIN = [col for col in df_beads.columns if 'CTCF' in col or 'H3K4me3' in col]\n",
    "COLS_OLIGO = [col for col in df_beads.columns if 'oligo' in col]\n",
    "COLS_HUMAN = [col for col in df_beads.columns if 'human' in col]\n",
    "COLS_MOUSE = [col for col in df_beads.columns if 'mouse' in col]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b83bfd-9550-4435-84b9-bfe2b6a90ebf",
   "metadata": {},
   "source": [
    "### Chromatin per bead"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f1c4ec-0860-413a-a7c5-59d94a5f1b50",
   "metadata": {},
   "source": [
    "Mean (filtered) chromatin per bead. Compare with estimated 0.75 chromatin per bead from library prep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f38106-584b-4999-9a0d-3a2ae8ac7a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('mean:', df_beads[COLS_CHROMATIN].sum(axis=1).mean())\n",
    "print('median:', df_beads[COLS_CHROMATIN].sum(axis=1).median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d05a83b-b5e9-4668-954f-7a91dba998e4",
   "metadata": {},
   "source": [
    "Chromatin per bead, stratified by species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a681510f-97d6-42ee-904a-9b86b82a20e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(12, 6), sharex=True, constrained_layout=True)\n",
    "\n",
    "df_chromatin_long = (\n",
    "    pd.DataFrame(\n",
    "        data=dict(\n",
    "            total=df_beads[COLS_CHROMATIN].sum(axis=1).values,\n",
    "            human=df_beads[['human H3K4me3', 'human CTCF']].sum(axis=1).values,\n",
    "            mouse=df_beads[['mouse H3K4me3', 'mouse CTCF']].sum(axis=1).values\n",
    "        ),\n",
    "        dtype=np.int32\n",
    "    ).melt(var_name='chromatin species', value_name='count')\n",
    "    .astype({'chromatin species': 'category'})\n",
    ")\n",
    "\n",
    "xscale = matplotlib.scale.SymmetricalLogScale(None, base=10, linthresh=2, linscale=0.2)\n",
    "symlog_transform = xscale.get_transform()\n",
    "symlog_transform_inverse = symlog_transform.inverted()\n",
    "bins = symlog_transform_inverse.transform(np.linspace(\n",
    "    symlog_transform.transform(-0.5),\n",
    "    symlog_transform.transform(df_chromatin_long['count'].max()),\n",
    "    30\n",
    "))\n",
    "bins = myclass(bins.shape, buffer=bins, dtype=float)\n",
    "\n",
    "sns.ecdfplot(\n",
    "    df_chromatin_long,\n",
    "    x='count',\n",
    "    hue='chromatin species',\n",
    "    ax=axs[0, 0]\n",
    ")\n",
    "axs[0, 0].set_ylabel('proportion of beads')\n",
    "sns.move_legend(axs[0, 0], loc='lower right')\n",
    "\n",
    "sns.ecdfplot(\n",
    "    df_chromatin_long,\n",
    "    x='count',\n",
    "    weights='count',\n",
    "    hue='chromatin species',\n",
    "    ax=axs[0, 1]\n",
    ")\n",
    "axs[0, 1].set_ylabel('proportion of chromatin reads')\n",
    "sns.move_legend(axs[0, 1], loc='lower right')\n",
    "\n",
    "sns.histplot(\n",
    "    df_chromatin_long,\n",
    "    x='count',\n",
    "    hue='chromatin species',\n",
    "    bins=bins,\n",
    "    alpha=0.3,\n",
    "    ax=axs[1, 0]\n",
    ")\n",
    "axs[1, 0].set_yscale('symlog', linthresh=10)\n",
    "axs[1, 0].set_ylabel('number of beads')\n",
    "axs[1, 0].set_xlabel(None)\n",
    "sns.move_legend(axs[1, 0], loc='upper right')\n",
    "\n",
    "sns.histplot(\n",
    "    df_chromatin_long,\n",
    "    x='count',\n",
    "    weights='count',\n",
    "    hue='chromatin species',\n",
    "    bins=bins,\n",
    "    alpha=0.3,\n",
    "    ax=axs[1, 1]\n",
    ")\n",
    "axs[1, 1].set_xscale(xscale)\n",
    "axs[1, 1].set_xlim(-1, None)\n",
    "axs[1, 1].set_xlabel(None)\n",
    "axs[1, 1].set_yscale('symlog', linthresh=10)\n",
    "axs[1, 1].set_ylabel('number of chromatin reads')\n",
    "sns.move_legend(axs[1, 1], loc='upper right')\n",
    "\n",
    "fig.supxlabel('number of chromatin molecules per bead')\n",
    "fig.suptitle('\\n'.join((\n",
    "    'Distribution of chromatin molecules per bead',\n",
    "    '(on beads with any oligo or filtered chromatin)'\n",
    ")))\n",
    "fig.savefig(\n",
    "    os.path.join(DIR_RESULTS, 'chromatin molecules per bead, by species.png'),\n",
    "    dpi=300,\n",
    "    bbox_inches='tight'\n",
    ")\n",
    "\n",
    "del df_chromatin_long\n",
    "gc.collect()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede1b7b6-d1ec-402a-a653-891b420e3e7b",
   "metadata": {},
   "source": [
    "Chromatin per bead, stratified by target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b93b34-1232-4eb6-81e4-0562222584a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(12, 6), sharex=True, constrained_layout=True)\n",
    "\n",
    "df_chromatin_long = (\n",
    "    pd.DataFrame(\n",
    "        data=dict(\n",
    "            total=df_beads[COLS_CHROMATIN].sum(axis=1).values,\n",
    "            CTCF=df_beads[['human CTCF', 'mouse CTCF']].sum(axis=1).values,\n",
    "            H3K4me3=df_beads[['human H3K4me3', 'mouse H3K4me3']].sum(axis=1).values\n",
    "        ),\n",
    "        dtype=np.int32\n",
    "    ).melt(var_name='chromatin target', value_name='count')\n",
    "    .astype({'chromatin target': 'category'})\n",
    ")\n",
    "\n",
    "xscale = matplotlib.scale.SymmetricalLogScale(None, base=10, linthresh=2, linscale=0.2)\n",
    "symlog_transform = xscale.get_transform()\n",
    "symlog_transform_inverse = symlog_transform.inverted()\n",
    "bins = symlog_transform_inverse.transform(np.linspace(\n",
    "    symlog_transform.transform(-0.5),\n",
    "    symlog_transform.transform(df_chromatin_long['count'].max()),\n",
    "    30\n",
    "))\n",
    "bins = myclass(bins.shape, buffer=bins, dtype=float)\n",
    "\n",
    "sns.ecdfplot(\n",
    "    df_chromatin_long,\n",
    "    x='count',\n",
    "    hue='chromatin target',\n",
    "    ax=axs[0, 0]\n",
    ")\n",
    "axs[0, 0].set_ylabel('proportion of beads')\n",
    "sns.move_legend(axs[0, 0], loc='lower right')\n",
    "\n",
    "sns.ecdfplot(\n",
    "    df_chromatin_long,\n",
    "    x='count',\n",
    "    weights='count',\n",
    "    hue='chromatin target',\n",
    "    ax=axs[0, 1]\n",
    ")\n",
    "axs[0, 1].set_ylabel('proportion of chromatin reads')\n",
    "sns.move_legend(axs[0, 1], loc='lower right')\n",
    "\n",
    "sns.histplot(\n",
    "    df_chromatin_long,\n",
    "    x='count',\n",
    "    hue='chromatin target',\n",
    "    bins=bins,\n",
    "    alpha=0.3,\n",
    "    ax=axs[1, 0]\n",
    ")\n",
    "axs[1, 0].set_yscale('symlog', linthresh=10)\n",
    "axs[1, 0].set_ylabel('number of beads')\n",
    "axs[1, 0].set_xlabel(None)\n",
    "sns.move_legend(axs[1, 0], loc='upper right')\n",
    "\n",
    "sns.histplot(\n",
    "    df_chromatin_long,\n",
    "    x='count',\n",
    "    weights='count',\n",
    "    hue='chromatin target',\n",
    "    bins=bins,\n",
    "    alpha=0.3,\n",
    "    ax=axs[1, 1]\n",
    ")\n",
    "axs[1, 1].set_xscale(xscale)\n",
    "axs[1, 1].set_xlim(-1, None)\n",
    "axs[1, 1].set_xlabel(None)\n",
    "axs[1, 1].set_yscale('symlog', linthresh=10)\n",
    "axs[1, 1].set_ylabel('number of chromatin reads')\n",
    "sns.move_legend(axs[1, 1], loc='upper right')\n",
    "\n",
    "fig.supxlabel('number of chromatin molecules per bead')\n",
    "fig.suptitle('\\n'.join((\n",
    "    'Distribution of chromatin molecules per bead',\n",
    "    '(on beads with any oligo or filtered chromatin)'\n",
    ")))\n",
    "fig.savefig(\n",
    "    os.path.join(DIR_RESULTS, 'chromatin molecules per bead, by target.png'),\n",
    "    dpi=300,\n",
    "    bbox_inches='tight'\n",
    ")\n",
    "\n",
    "del df_chromatin_long\n",
    "gc.collect()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d365dcde-7452-46ab-8aa8-945d889edaba",
   "metadata": {},
   "source": [
    "#### Species uniqueness on beads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9837cccf-78ab-4f87-b8c6-3167ef1edb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# each row is a bead\n",
    "# columns\n",
    "# - human: proportion of chromatin molecules on a bead assigned to human genome\n",
    "# - total: count of chromatin molecules on a bead\n",
    "df_chromatin_species_per_bead = (\n",
    "    df_beads[COLS_CHROMATIN]\n",
    "    .assign(total=df_beads[COLS_CHROMATIN].sum(axis=1))\n",
    "    .pipe(lambda df: df.assign(**{\n",
    "        'human': df[['human H3K4me3', 'human CTCF']].sum(axis=1) / df['total'],\n",
    "        'chromatin molecules per bead': pd.cut(\n",
    "            df['total'],\n",
    "            bins=[0, 1, 4, 16, 64, 256, 1024, np.inf],\n",
    "            right=True,\n",
    "            labels=['1', '2-4', '5-16', '17-64', '65-256', '257-1024', '1025+']\n",
    "    )}))\n",
    "    [['human', 'total', 'chromatin molecules per bead']]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4733aa59-52f6-4c20-8539-fdd587b60213",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, sharex=True, constrained_layout=True)\n",
    "sns.histplot(\n",
    "    (\n",
    "        df_chromatin_species_per_bead.loc[df_chromatin_species_per_bead['total'] > 1]\n",
    "        .pipe(lambda df: df.assign(**{\n",
    "            'chromatin molecules per bead': df['chromatin molecules per bead'].cat.remove_categories('1')\n",
    "        }))\n",
    "    ),\n",
    "    x='human',\n",
    "    stat='proportion',\n",
    "    multiple='stack',\n",
    "    common_norm=False,\n",
    "    hue='chromatin molecules per bead',\n",
    "    palette='viridis',\n",
    "    ax=axs[0]\n",
    ")\n",
    "sns.ecdfplot(\n",
    "    (\n",
    "        df_chromatin_species_per_bead.loc[df_chromatin_species_per_bead['total'] > 1]\n",
    "        .pipe(lambda df: df.assign(**{\n",
    "            'chromatin molecules per bead': df['chromatin molecules per bead'].cat.remove_categories('1')\n",
    "        }))\n",
    "    ),\n",
    "    x='human',\n",
    "    hue='chromatin molecules per bead',\n",
    "    palette='viridis',\n",
    "    legend=False,\n",
    "    ax=axs[1]\n",
    ")\n",
    "axs[0].set_ylabel('proportion of beads')\n",
    "axs[1].set_ylabel('proportion of beads')\n",
    "axs[1].set_xlabel('proportion of chromatin molecules on a bead\\nfrom human genome (vs. mouse genome)')\n",
    "axs[0].set_title('Distribution of chromatin species on beads')\n",
    "fig.savefig(\n",
    "    os.path.join(DIR_RESULTS, 'chromatin species on beads.png'),\n",
    "    dpi=300,\n",
    "    bbox_inches='tight'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f30c063-b7d1-41d4-91d3-57cdd8b77b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "for thresh in (1, 2, 3, 5, 10):\n",
    "    ax.ecdf(\n",
    "        df_chromatin_species_per_bead.loc[\n",
    "            df_chromatin_species_per_bead['total'] >= thresh,\n",
    "            'human'\n",
    "        ].map(lambda x: np.maximum(x, 1-x)).values,\n",
    "        label=thresh\n",
    "    )\n",
    "ax.legend(title='minimum chromatin per bead', loc='upper left', bbox_to_anchor=(1, 1))\n",
    "ax.set_xlabel('maximum species representation proportion')\n",
    "ax.set_ylabel('proportion of beads')\n",
    "ax.set_title('Chromatin species uniqueness on beads')\n",
    "fig.savefig(\n",
    "    os.path.join(DIR_RESULTS, 'chromatin species uniqueness on beads.png'),\n",
    "    dpi=300,\n",
    "    bbox_inches='tight'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c62104d-6329-405e-93ed-ed3c546c2b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = df_beads[COLS_CHROMATIN].values.sum(axis=1)\n",
    "total_human = df_beads[['human CTCF', 'human H3K4me3']].values.sum(axis=1)\n",
    "total_mouse = df_beads[['mouse CTCF', 'mouse H3K4me3']].values.sum(axis=1)\n",
    "mixed = (total_human > 0) & (total_mouse > 0)\n",
    "\n",
    "s = []\n",
    "for thresh in (0, 1, 2, 3, 5, 10):\n",
    "    mask_denom = (total >= thresh)\n",
    "    num = (mask_denom & mixed).sum()\n",
    "    denom = mask_denom.sum()\n",
    "    s.append({\n",
    "        'mixed beads': num,\n",
    "        'total beads': denom,\n",
    "        'proportion mixed': num / denom,\n",
    "        'minimum chromatin per bead': thresh\n",
    "    })\n",
    "\n",
    "del total, total_human, total_mouse, mixed, mask_denom\n",
    "gc.collect()\n",
    "pd.DataFrame(s).set_index('minimum chromatin per bead')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35547fd9-96bf-4a3e-a0a5-6d36aad750d5",
   "metadata": {},
   "source": [
    "#### Target uniqueness on beads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7a726c-5199-40f3-b5ec-7417ca1b9aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# each row is a bead\n",
    "# columns\n",
    "# - CTCF: proportion of chromatin molecules on a bead assigned to CTCF antibody\n",
    "# - total: count of chromatin molecules on a bead\n",
    "df_chromatin_targets_per_bead = (\n",
    "    df_beads[COLS_CHROMATIN]\n",
    "    .assign(total=df_beads[COLS_CHROMATIN].sum(axis=1))\n",
    "    .pipe(lambda df: df.assign(**{\n",
    "        'CTCF': df[['human CTCF', 'mouse CTCF']].sum(axis=1) / df['total'],\n",
    "        'chromatin molecules per bead': pd.cut(\n",
    "            df['total'],\n",
    "            bins=[0, 1, 4, 16, 64, 256, 1024, np.inf],\n",
    "            right=True,\n",
    "            labels=['1', '2-4', '5-16', '17-64', '65-256', '257-1024', '1025+']\n",
    "    )}))\n",
    "    [['CTCF', 'total', 'chromatin molecules per bead']]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e537fa9c-287d-4e30-bb4d-68e56a29dbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, sharex=True, constrained_layout=True)\n",
    "sns.histplot(\n",
    "    (\n",
    "        df_chromatin_targets_per_bead.loc[df_chromatin_targets_per_bead['total'] > 1]\n",
    "        .pipe(lambda df: df.assign(**{\n",
    "            'chromatin molecules per bead': df['chromatin molecules per bead'].cat.remove_categories('1')\n",
    "        }))\n",
    "    ),\n",
    "    x='CTCF',\n",
    "    stat='proportion',\n",
    "    multiple='stack',\n",
    "    common_norm=False,\n",
    "    hue='chromatin molecules per bead',\n",
    "    palette='viridis',\n",
    "    ax=axs[0]\n",
    ")\n",
    "sns.ecdfplot(\n",
    "    (\n",
    "        df_chromatin_targets_per_bead.loc[df_chromatin_targets_per_bead['total'] > 1]\n",
    "        .pipe(lambda df: df.assign(**{\n",
    "            'chromatin molecules per bead': df['chromatin molecules per bead'].cat.remove_categories('1')\n",
    "        }))\n",
    "    ),\n",
    "    x='CTCF',\n",
    "    hue='chromatin molecules per bead',\n",
    "    palette='viridis',\n",
    "    legend=False,\n",
    "    ax=axs[1]\n",
    ")\n",
    "axs[0].set_ylabel('proportion of beads')\n",
    "axs[1].set_ylabel('proportion of beads')\n",
    "axs[1].set_xlabel('proportion of chromatin molecules on a bead\\nfrom CTCF ChIP (vs. H3K4me3 ChIP)')\n",
    "axs[0].set_title('Distribution of chromatin targets on beads')\n",
    "fig.savefig(\n",
    "    os.path.join(DIR_RESULTS, 'chromatin targets on beads.png'),\n",
    "    dpi=300,\n",
    "    bbox_inches='tight'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce11d6d7-4018-4073-8fc8-7a8d083deaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "for thresh in (1, 2, 3, 5, 10):\n",
    "    ax.ecdf(\n",
    "        df_chromatin_targets_per_bead.loc[\n",
    "            df_chromatin_targets_per_bead['total'] >= thresh,\n",
    "            'CTCF'\n",
    "        ].map(lambda x: np.maximum(x, 1-x)).values,\n",
    "        label=thresh\n",
    "    )\n",
    "ax.legend(title='minimum chromatin per bead', loc='upper left', bbox_to_anchor=(1, 1))\n",
    "ax.set_xlabel('maximum target representation proportion')\n",
    "ax.set_ylabel('proportion of beads')\n",
    "ax.set_title('Chromatin target uniqueness on beads')\n",
    "fig.savefig(\n",
    "    os.path.join(DIR_RESULTS, 'chromatin target uniqueness on beads.png'),\n",
    "    dpi=300,\n",
    "    bbox_inches='tight'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5fcf7a-a976-43d2-82fe-7adf5bd7d405",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = df_beads[COLS_CHROMATIN].values.sum(axis=1)\n",
    "total_CTCF = df_beads[['human CTCF', 'mouse CTCF']].values.sum(axis=1)\n",
    "total_H3K4me3 = df_beads[['human H3K4me3', 'mouse H3K4me3']].values.sum(axis=1)\n",
    "mixed = (total_CTCF > 0) & (total_H3K4me3 > 0)\n",
    "\n",
    "s = []\n",
    "for thresh in (0, 1, 2, 3, 5, 10):\n",
    "    mask_denom = (total >= thresh)\n",
    "    num = (mask_denom & mixed).sum()\n",
    "    denom = mask_denom.sum()\n",
    "    s.append({\n",
    "        'mixed beads': num,\n",
    "        'total beads': denom,\n",
    "        'proportion mixed': num / denom,\n",
    "        'minimum chromatin per bead': thresh\n",
    "    })\n",
    "\n",
    "del total, total_CTCF, total_H3K4me3, mixed, mask_denom\n",
    "gc.collect()\n",
    "pd.DataFrame(s).set_index('minimum chromatin per bead')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff4872a-1f0f-4279-96b6-6f3f8c4cd97f",
   "metadata": {},
   "source": [
    "### Oligos per bead"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec21201-fa21-4492-b8e5-2486eb10db36",
   "metadata": {},
   "source": [
    "Mean (filtered) chromatin per bead. Compare with estimated 0.78 oligos per bead from library prep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265d22d8-3765-4137-93ea-ccb401a33851",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('mean:', df_beads[COLS_OLIGO].sum(axis=1).mean())\n",
    "print('median:', df_beads[COLS_OLIGO].sum(axis=1).median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ee50a4-2569-4451-9275-b54f1b467fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(12, 6), sharex=True, constrained_layout=True)\n",
    "\n",
    "# columns = oligo species, count\n",
    "df_oligos_long = (\n",
    "    df_beads[COLS_OLIGO]\n",
    "    .rename(columns={'human oligo': 'human', 'mouse oligo': 'mouse'})\n",
    "    .assign(total=df_beads[COLS_OLIGO].sum(axis=1))\n",
    "    .melt(var_name='oligo species', value_name='count')\n",
    "    .astype({'oligo species': 'category'})\n",
    ")\n",
    "\n",
    "xscale = matplotlib.scale.SymmetricalLogScale(None, base=10, linthresh=1, linscale=0.1)\n",
    "symlog_transform = xscale.get_transform()\n",
    "symlog_transform_inverse = symlog_transform.inverted()\n",
    "bins = symlog_transform_inverse.transform(np.linspace(\n",
    "    symlog_transform.transform(-0.6),\n",
    "    symlog_transform.transform(df_oligos_long['count'].max()),\n",
    "    30\n",
    "))\n",
    "bins = myclass(bins.shape, buffer=bins, dtype=float)\n",
    "\n",
    "sns.ecdfplot(\n",
    "    df_oligos_long,\n",
    "    x='count',\n",
    "    hue='oligo species',\n",
    "    ax=axs[0, 0]\n",
    ")\n",
    "axs[0, 0].set_ylabel('proportion of beads')\n",
    "sns.move_legend(axs[0, 0], loc='lower right')\n",
    "\n",
    "sns.ecdfplot(\n",
    "    df_oligos_long,\n",
    "    x='count',\n",
    "    weights='count',\n",
    "    hue='oligo species',\n",
    "    ax=axs[0, 1]\n",
    ")\n",
    "axs[0, 1].set_ylabel('proportion of oligo reads')\n",
    "sns.move_legend(axs[0, 1], loc='lower right')\n",
    "\n",
    "sns.histplot(\n",
    "    df_oligos_long,\n",
    "    x='count',\n",
    "    hue='oligo species',\n",
    "    bins=bins,\n",
    "    alpha=0.3,\n",
    "    ax=axs[1, 0]\n",
    ")\n",
    "axs[1, 0].set_yscale('symlog', linthresh=10)\n",
    "axs[1, 0].set_ylabel('number of beads')\n",
    "axs[1, 0].set_xlabel(None)\n",
    "sns.move_legend(axs[1, 0], loc='upper right')\n",
    "\n",
    "sns.histplot(\n",
    "    df_oligos_long,\n",
    "    x='count',\n",
    "    weights='count',\n",
    "    hue='oligo species',\n",
    "    bins=bins,\n",
    "    alpha=0.3,\n",
    "    ax=axs[1, 1]\n",
    ")\n",
    "axs[1, 1].set_xscale(xscale)\n",
    "axs[1, 1].set_xlim(-1, None)\n",
    "axs[1, 1].set_xlabel(None)\n",
    "axs[1, 1].set_yscale('symlog', linthresh=10)\n",
    "axs[1, 1].set_ylabel('number of oligo reads')\n",
    "sns.move_legend(axs[1, 1], loc='upper right')\n",
    "\n",
    "fig.supxlabel('number of oligo molecules per bead')\n",
    "fig.suptitle('\\n'.join((\n",
    "    'Distribution of oligo molecules per bead',\n",
    "    '(on beads with any oligo or filtered chromatin)'\n",
    ")))\n",
    "fig.savefig(\n",
    "    os.path.join(DIR_RESULTS, 'oligo molecules per bead.png'),\n",
    "    dpi=300,\n",
    "    bbox_inches='tight'\n",
    ")\n",
    "\n",
    "del df_oligos_long\n",
    "gc.collect()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a6e664-c5eb-42b7-a4b0-c7cc222254e3",
   "metadata": {},
   "source": [
    "#### Species uniqueness on beads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c072a9-0daa-42dd-a166-3fd48f255a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# each row is a bead\n",
    "# columns\n",
    "# - human: proportion of human oligos on a bead\n",
    "# - total: count of oligo molecules on a bead\n",
    "df_oligo_species_per_bead = (\n",
    "    df_beads[COLS_OLIGO]\n",
    "    .assign(total=df_beads[COLS_OLIGO].sum(axis=1))\n",
    "    .pipe(lambda df: df.assign(**{\n",
    "        'human': df['human oligo'] / df['total'],\n",
    "        'oligo molecules per bead': pd.cut(\n",
    "            df['total'],\n",
    "            bins=[0, 1, 4, 16, 64, 256, 1024, np.inf],\n",
    "            right=True,\n",
    "            labels=['1', '2-4', '5-16', '17-64', '65-256', '257-1024', '1025+']\n",
    "    )}))\n",
    "    [['human', 'total', 'oligo molecules per bead']]\n",
    ")\n",
    "\n",
    "# df_oligo_species_per_bead = (\n",
    "#     df_oligos\n",
    "#     .assign(total=df_oligos.sum(axis=1))\n",
    "#     .pipe(lambda df: df.assign(**{\n",
    "#         'human': df['human'] / df['total'],\n",
    "#         'mouse': df['mouse'] / df['total'],\n",
    "#         'oligo molecules per bead': pd.cut(\n",
    "#             df['total'],\n",
    "#             bins=[0, 1, 4, 16, 64, 256, 1024, np.inf],\n",
    "#             right=True,\n",
    "#             labels=['1', '2-4', '5-16', '17-64', '65-256', '257-1024', '1025+']\n",
    "#         )\n",
    "#     }))\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f6338e-b4d7-4675-9a13-b6a979a14ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, sharex=True, constrained_layout=True)\n",
    "sns.histplot(\n",
    "    df_oligo_species_per_bead.loc[df_oligo_species_per_bead['total'] > 1]\n",
    "    .pipe(lambda df: df.assign(**{\n",
    "        'oligo molecules per bead': df['oligo molecules per bead'].cat.remove_categories('1')\n",
    "    })),\n",
    "    x='human',\n",
    "    stat='proportion',\n",
    "    multiple='stack',\n",
    "    common_norm=False,\n",
    "    hue='oligo molecules per bead',\n",
    "    palette='viridis',\n",
    "    ax=axs[0]\n",
    ")\n",
    "sns.ecdfplot(\n",
    "    df_oligo_species_per_bead.loc[df_oligo_species_per_bead['total'] > 1]\n",
    "    .pipe(lambda df: df.assign(**{\n",
    "        'oligo molecules per bead': df['oligo molecules per bead'].cat.remove_categories('1')\n",
    "    })),\n",
    "    x='human',\n",
    "    hue='oligo molecules per bead',\n",
    "    palette='viridis',\n",
    "    legend=False,\n",
    "    ax=axs[1]\n",
    ")\n",
    "axs[0].set_ylabel('proportion of beads')\n",
    "axs[1].set_ylabel('proportion of beads')\n",
    "axs[1].set_xlabel('proportion of human oligos out of all oligo on a bead')\n",
    "axs[0].set_title('Distribution of oligo species on beads with >= 2 oligos')\n",
    "fig.savefig(\n",
    "    os.path.join(DIR_RESULTS, 'oligo species on beads.png'),\n",
    "    dpi=300,\n",
    "    bbox_inches='tight'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4fa9bf-c95c-4d6c-b7bb-0586af3dc411",
   "metadata": {},
   "source": [
    "### Bivariate distribution of oligos and chromatin per bead"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d53106-1784-4039-9076-1eeb3b237070",
   "metadata": {},
   "source": [
    "Total chromatin vs. total oligo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5fc82c-e5c3-4a0a-8064-e547c9ba40d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_molecules_per_bead = pd.DataFrame({\n",
    "    'chromatin per bead': df_beads[COLS_CHROMATIN].sum(axis=1).values,\n",
    "    'oligos per bead': df_beads[COLS_OLIGO].sum(axis=1).values\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64234d1c-b21c-4ddc-af82-d006e832821b",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.jointplot(\n",
    "    df_total_molecules_per_bead.loc[\n",
    "        (df_total_molecules_per_bead['chromatin per bead'] < 40) & \\\n",
    "        (df_total_molecules_per_bead['oligos per bead'] < 100)\n",
    "    ],\n",
    "    x='chromatin per bead',\n",
    "    y='oligos per bead',\n",
    "    kind='hist',\n",
    "    discrete=True,\n",
    "    marginal_kws=dict(bins=25)\n",
    ")\n",
    "g.figure.suptitle('Bivariate distribution of oligo and chromatin molecules per bead', y=1.05, fontsize='medium')\n",
    "g.figure.set_size_inches(4, 4)\n",
    "g.savefig(\n",
    "    os.path.join(DIR_RESULTS, 'distribution of molecules per bead, zoom.png'),\n",
    "    dpi=300\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbc9cf5-1ceb-4817-9926-d5f93c51cc5e",
   "metadata": {},
   "source": [
    "(human oligo or mouse oligo) vs. (human CTCF, mouse CTCF, human H3K4me3, or mouse H3K4me3 chromatin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b439eb65-f377-46e5-aa4f-8caf3962b908",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.pairplot(\n",
    "    df_beads,\n",
    "    x_vars=COLS_CHROMATIN,\n",
    "    y_vars=COLS_OLIGO,\n",
    "    kind='hist',\n",
    "    plot_kws=dict(\n",
    "        discrete=True,\n",
    "        binrange=((0, 20), (0, 50)),\n",
    "        cbar=True\n",
    "    )\n",
    ")\n",
    "g.figure.suptitle('Bivariate distribution of oligo and chromatin molecules per bead', y=1.05)\n",
    "g.savefig(\n",
    "    os.path.join(DIR_RESULTS, 'distribution of molecules per bead, facetted, zoom.png'),\n",
    "    dpi=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb836596-0502-4b4b-be96-59fcf9030cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.pairplot(\n",
    "    df_beads,\n",
    "    x_vars=COLS_CHROMATIN,\n",
    "    y_vars=COLS_OLIGO,\n",
    "    kind='hist',\n",
    "    plot_kws=dict(\n",
    "        discrete=True,\n",
    "        binrange=((0, 10), (0, 15)),\n",
    "        cbar=True\n",
    "    )\n",
    ")\n",
    "g.figure.suptitle('Bivariate distribution of oligo and chromatin molecules per bead', y=1.05)\n",
    "g.savefig(\n",
    "    os.path.join(DIR_RESULTS, 'distribution of molecules per bead, facetted, zoom2.png'),\n",
    "    dpi=300\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fa6eb3-0a12-4f72-9bfd-13beb6fabfa2",
   "metadata": {},
   "source": [
    "## Mixing analysis\n",
    "\n",
    "Note: only performed using paired-end alignments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b24423-d8fb-46d0-b77e-8c44f92bf1b4",
   "metadata": {},
   "source": [
    "### Beads with only 1 chromatin species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f9147b-843b-4996-ad7f-5aa579fb94da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index = bead\n",
    "# columns = chromatin species, chromatin count, human oligo count, mouse oligo count\n",
    "df_single_chromatin_species_beads = (\n",
    "    df_beads\n",
    "    .assign(**{\n",
    "        'human chromatin': df_beads[['human H3K4me3', 'human CTCF']].sum(axis=1),\n",
    "        'mouse chromatin': df_beads[['mouse H3K4me3', 'mouse CTCF']].sum(axis=1)\n",
    "    })\n",
    "    .drop(columns=COLS_CHROMATIN)\n",
    "    .pipe(lambda df: df.loc[(df['human chromatin'] == 0) ^ (df['mouse chromatin'] == 0)])\n",
    "    .pipe(lambda df: df.assign(**{\n",
    "        'chromatin species': (df['human chromatin'] == 0).map(dict({True: 'mouse', False: 'human'})).astype(DTYPE_SPECIES),\n",
    "        'chromatin count': df['human chromatin'] + df['mouse chromatin']\n",
    "    }))\n",
    "    .drop(columns=['human chromatin', 'mouse chromatin'])\n",
    "    .rename(columns={'human oligo': 'human oligo count', 'mouse oligo': 'mouse oligo count'})\n",
    ")\n",
    "\n",
    "# df_single_chromatin_species_beads = (\n",
    "#     df_chromatin.loc[df_chromatin['alignment_type'] == 'PE', ['bead', 'species']]\n",
    "#     .groupby('bead')\n",
    "#     .filter(lambda g: len(g['species'].unique()) == 1)\n",
    "#     .groupby('bead')\n",
    "#     ['species'].agg(['first', 'size'])\n",
    "#     .rename(columns={'size': 'chromatin count', 'first': 'chromatin species'})\n",
    "#     .merge(df_oligos, how='left', left_index=True, right_index=True)\n",
    "#     .fillna({'human': 0, 'mouse': 0})\n",
    "#     .astype({'human': int, 'mouse': int})\n",
    "#     .rename(columns={'human': 'human oligo count', 'mouse': 'mouse oligo count'})\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62d568d-4ebd-4e0b-ab31-28bf4ba8014b",
   "metadata": {},
   "source": [
    "Oligo counts for single-chromatin-species beads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3bc70f-4243-42b8-adf3-2c9c65602f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "ax = sns.scatterplot(\n",
    "    (\n",
    "        df_single_chromatin_species_beads\n",
    "        .groupby(['chromatin species', 'human oligo count', 'mouse oligo count'], observed=True)\n",
    "        .size()\n",
    "        .rename('bead count')\n",
    "        .reset_index()\n",
    "        .rename(columns={'chromatin species': 'bead chromatin species'})\n",
    "        # x-jitter human oligo counts for visualization\n",
    "        .pipe(lambda df: df.assign(**{\n",
    "            'human oligo count': df['human oligo count'] + 0.2 * (df['bead chromatin species'] == 'human').astype(float) - 0.1\n",
    "        }))\n",
    "    ),\n",
    "    x='human oligo count',\n",
    "    y='mouse oligo count',\n",
    "    hue='bead chromatin species',\n",
    "    size='bead count',\n",
    "    sizes=(10, 50),\n",
    "    ax=ax\n",
    ")\n",
    "# ax.set_aspect('equal')\n",
    "ax.set_title('Oligo counts for single-chromatin-species beads')\n",
    "ax.xaxis.set_major_locator(matplotlib.ticker.MaxNLocator(integer=True))\n",
    "sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 1))\n",
    "fig.savefig(\n",
    "    os.path.join(DIR_RESULTS, 'single-chromatin-species-beads_mixing.png'),\n",
    "    bbox_inches='tight',\n",
    "    dpi=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dfa892-3ac3-41c3-bfa4-e351abcb8c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "ax = sns.scatterplot(\n",
    "    (\n",
    "        df_single_chromatin_species_beads\n",
    "        .groupby(['chromatin species', 'human oligo count', 'mouse oligo count'], observed=True)\n",
    "        .size()\n",
    "        .rename('bead count')\n",
    "        .reset_index()\n",
    "        .rename(columns={'chromatin species': 'bead chromatin species'})\n",
    "        # remove beads with no oligos\n",
    "        .pipe(lambda df: df.loc[(df['human oligo count'] + df['mouse oligo count']) > 0])\n",
    "        # x-jitter human oligo counts for visualization\n",
    "        .pipe(lambda df: df.assign(**{\n",
    "            'human oligo count': df['human oligo count'] + 0.2 * (df['bead chromatin species'] == 'human').astype(float) - 0.1\n",
    "        }))\n",
    "    ),\n",
    "    x='human oligo count',\n",
    "    y='mouse oligo count',\n",
    "    hue='bead chromatin species',\n",
    "    size='bead count',\n",
    "    sizes=(10, 150)\n",
    ")\n",
    "ax.set_xlim((-0.5, 10.5))\n",
    "ax.set_ylim((-0.5, 10.5))\n",
    "ax.set_aspect('equal')\n",
    "ax.set_title('Oligo counts for single-chromatin-species beads')\n",
    "ax.xaxis.set_major_locator(matplotlib.ticker.MaxNLocator(integer=True))\n",
    "sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 1))\n",
    "fig.savefig(\n",
    "    os.path.join(DIR_RESULTS, 'single-chromatin-species-beads_mixing-zoom.png'),\n",
    "    bbox_inches='tight',\n",
    "    dpi=300\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea6c357-ec7c-4b2e-94ec-df2e6f4feda3",
   "metadata": {},
   "source": [
    "Distribution of oligos on beads with single chromatin species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0654aa-33fe-4812-aa8d-292560086fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 4), constrained_layout=True)\n",
    "for i, species in enumerate(SPECIES):\n",
    "    axs[i].set_title(f'beads with {species}-only chromatin')\n",
    "    sns.barplot(\n",
    "        # bead, chromatin count, oligo count, oligo species\n",
    "        (\n",
    "            df_single_chromatin_species_beads\n",
    "            .loc[df_single_chromatin_species_beads['chromatin species'] == species]\n",
    "            .reset_index()\n",
    "            .rename(columns={'human oligo count': 'human', 'mouse oligo count': 'mouse'})\n",
    "            .melt(\n",
    "                id_vars=['bead', 'chromatin count'],\n",
    "                value_vars=['human', 'mouse'],\n",
    "                var_name='oligo species',\n",
    "                value_name='oligo count'\n",
    "            )\n",
    "        ),\n",
    "        x='chromatin count',\n",
    "        y='oligo count',\n",
    "        hue='oligo species',\n",
    "        errorbar='se',\n",
    "        ax=axs[i]\n",
    "    )\n",
    "fig.savefig(\n",
    "    os.path.join(DIR_RESULTS, 'single-chromatin-species-beads_oligo-counts.png'),\n",
    "    bbox_inches='tight',\n",
    "    dpi=300\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc1e322-1eae-4b71-a2ed-4fc25668d51c",
   "metadata": {},
   "source": [
    "### Beads with only 1 chromatin species and 1 chromatin target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129c9fdc-7e92-4651-80e1-e80616ac829a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index = bead\n",
    "# columns = chromatin target, chromatin species, chromatin count, human oligo count, mouse oligo count\n",
    "df_single_chromatin_species_target_beads = (\n",
    "    df_beads\n",
    "    .loc[(df_beads[COLS_CHROMATIN] > 0).sum(axis=1) == 1]\n",
    "    .pipe(lambda df: df.assign(**{\n",
    "        'chromatin count': df[COLS_CHROMATIN].sum(axis=1),\n",
    "        'chromatin target': (\n",
    "            (df['human CTCF'] + df['mouse CTCF'] == 0)\n",
    "            .map(dict({True: 'H3K4me3', False: 'CTCF'}))\n",
    "            .astype(DTYPE_TARGET)\n",
    "        ),\n",
    "        'chromatin species': (\n",
    "            (df['human CTCF'] + df['human H3K4me3'] == 0)\n",
    "            .map(dict({True: 'mouse', False: 'human'}))\n",
    "            .astype(DTYPE_SPECIES)\n",
    "        )\n",
    "    }))\n",
    "    .drop(columns=COLS_CHROMATIN)\n",
    "    .rename(columns={'human oligo': 'human oligo count', 'mouse oligo': 'mouse oligo count'})\n",
    ")\n",
    "\n",
    "# df_single_chromatin_species_target_beads = (\n",
    "#     df_chromatin.loc[df_chromatin['alignment_type'] == 'PE', ['bead', 'species', 'target']]\n",
    "#     .groupby('bead')\n",
    "#     .filter(lambda g: (len(g['species'].unique()) == 1) and (len(g['target'].unique()) == 1))\n",
    "#     .rename(columns={'species': 'chromatin species'})\n",
    "#     .groupby(['bead', 'chromatin species', 'target'], observed=True)\n",
    "#     .size()\n",
    "#     .rename('chromatin count')\n",
    "#     .reset_index()\n",
    "#     .merge(df_oligos, how='left', left_on='bead', right_index=True)\n",
    "#     .fillna({'human': 0, 'mouse': 0})\n",
    "#     .astype({'human': int, 'mouse': int})\n",
    "#     .rename(columns={'human': 'human oligo count', 'mouse': 'mouse oligo count'})\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde2a5a0-831a-4ded-8627-650ae283525d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_beads_mixed = (\n",
    "    (df_single_chromatin_species_target_beads['human oligo count'] > 0) & \\\n",
    "    (df_single_chromatin_species_target_beads['mouse oligo count'] > 0)\n",
    ").sum()\n",
    "n_chromatin_mixed = df_single_chromatin_species_target_beads.loc[\n",
    "    ((df_single_chromatin_species_target_beads['human oligo count'] > 0) &\n",
    "     (df_single_chromatin_species_target_beads['mouse oligo count'] > 0)),\n",
    "    'chromatin count'\n",
    "].sum()\n",
    "n_beads_1_oligos = (df_single_chromatin_species_target_beads[['human oligo count', 'mouse oligo count']].sum(axis=1) > 0).sum()\n",
    "n_beads_2_oligos = (df_single_chromatin_species_target_beads[['human oligo count', 'mouse oligo count']].sum(axis=1) > 1).sum()\n",
    "n_beads_lt_80 = (\n",
    "    ((df_single_chromatin_species_target_beads['chromatin species'] == 'human') & \n",
    "     (df_single_chromatin_species_target_beads[['human oligo count', 'mouse oligo count']].sum(axis=1) > 0) & \n",
    "     ((df_single_chromatin_species_target_beads['human oligo count'] < 4 * df_single_chromatin_species_target_beads['mouse oligo count']) |\n",
    "      (df_single_chromatin_species_target_beads['human oligo count'] == 0)\n",
    "     )\n",
    "    ) | \n",
    "    ((df_single_chromatin_species_target_beads['chromatin species'] == 'mouse') & \n",
    "     (df_single_chromatin_species_target_beads[['human oligo count', 'mouse oligo count']].sum(axis=1) > 0) & \n",
    "     ((df_single_chromatin_species_target_beads['mouse oligo count'] < 4 * df_single_chromatin_species_target_beads['human oligo count']) |\n",
    "      (df_single_chromatin_species_target_beads['mouse oligo count'] == 0)\n",
    "     )\n",
    "    )\n",
    ").sum()\n",
    "\n",
    "print('Proportion of single-chromatin-species single-target beads with both mouse and human oligos: {} / {} = {:.2%}'.format(\n",
    "    n_beads_mixed,\n",
    "    len(df_single_chromatin_species_target_beads),\n",
    "    n_beads_mixed / len(df_single_chromatin_species_target_beads)\n",
    "))\n",
    "print('Proportion of single-chromatin-species single-target beads with both mouse and human oligos, out of those with 2+ oligos: {} / {} = {:.2%}'.format(\n",
    "    n_beads_mixed,\n",
    "    n_beads_2_oligos,\n",
    "    n_beads_mixed / n_beads_2_oligos\n",
    "))\n",
    "print('Proportion of single-chromatin-species single-target beads where the correct species oligo represents < 80% of oligos, out of those with 1+ oligos: {} / {} = {:.2%}'.format(\n",
    "    n_beads_lt_80,\n",
    "    n_beads_1_oligos,\n",
    "    n_beads_lt_80 / n_beads_1_oligos\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013378a6-7895-4228-a4ec-cf0271bf5ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6), sharex=True, sharey=True, constrained_layout=True)\n",
    "axs[0] = sns.scatterplot(\n",
    "    (\n",
    "        df_single_chromatin_species_target_beads\n",
    "        .loc[df_single_chromatin_species_target_beads['chromatin target'] == 'CTCF']\n",
    "        .groupby(['chromatin species', 'human oligo count', 'mouse oligo count'], observed=True)\n",
    "        .size()\n",
    "        .rename('bead count')\n",
    "        .reset_index()\n",
    "        .rename(columns={'chromatin species': 'bead chromatin species'})\n",
    "        # x-jitter human oligo counts for visualization\n",
    "        .pipe(lambda df: df.assign(**{\n",
    "            'human oligo count': df['human oligo count'] + 0.2 * (df['bead chromatin species'] == 'human').astype(float) - 0.1\n",
    "        }))\n",
    "    ),\n",
    "    x='human oligo count',\n",
    "    y='mouse oligo count',\n",
    "    hue='bead chromatin species',\n",
    "    size='bead count',\n",
    "    sizes=(10, 50),\n",
    "    ax=axs[0]\n",
    ")\n",
    "# ax.set_aspect('equal')\n",
    "axs[0].set_title('Oligo counts for single-chromatin-species CTCF beads')\n",
    "axs[0].xaxis.set_major_locator(matplotlib.ticker.MaxNLocator(integer=True))\n",
    "sns.move_legend(axs[0], \"upper left\", bbox_to_anchor=(1, 1))\n",
    "\n",
    "axs[1] = sns.scatterplot(\n",
    "    (\n",
    "        df_single_chromatin_species_target_beads\n",
    "        .loc[df_single_chromatin_species_target_beads['chromatin target'] == 'H3K4me3']\n",
    "        .groupby(['chromatin species', 'human oligo count', 'mouse oligo count'], observed=True)\n",
    "        .size()\n",
    "        .rename('bead count')\n",
    "        .reset_index()\n",
    "        .rename(columns={'chromatin species': 'bead chromatin species'})\n",
    "        # x-jitter human oligo counts for visualization\n",
    "        .pipe(lambda df: df.assign(**{\n",
    "            'human oligo count': df['human oligo count'] + 0.2 * (df['bead chromatin species'] == 'human').astype(float) - 0.1\n",
    "        }))\n",
    "    ),\n",
    "    x='human oligo count',\n",
    "    y='mouse oligo count',\n",
    "    hue='bead chromatin species',\n",
    "    size='bead count',\n",
    "    sizes=(10, 50),\n",
    "    ax=axs[1]\n",
    ")\n",
    "axs[1].set_title('Oligo counts for single-chromatin-species H3K4me3 beads')\n",
    "axs[1].xaxis.set_major_locator(matplotlib.ticker.MaxNLocator(integer=True))\n",
    "sns.move_legend(axs[1], \"upper left\", bbox_to_anchor=(1, 1))\n",
    "\n",
    "fig.savefig(\n",
    "    os.path.join(DIR_RESULTS, 'single-chromatin-species_single-target_beads_mixing.png'),\n",
    "    bbox_inches='tight',\n",
    "    dpi=300\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea5bb75-d48d-44a0-8143-6896bde4be8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6), sharex=True, sharey=True, constrained_layout=True)\n",
    "axs[0] = sns.scatterplot(\n",
    "    (\n",
    "        df_single_chromatin_species_target_beads\n",
    "        .loc[df_single_chromatin_species_target_beads['chromatin target'] == 'CTCF']\n",
    "        .pipe(lambda df: df.loc[(df['human oligo count'] + df['mouse oligo count']) > 0])\n",
    "        .groupby(['chromatin species', 'human oligo count', 'mouse oligo count'], observed=True)\n",
    "        .size()\n",
    "        .rename('bead count')\n",
    "        .reset_index()\n",
    "        .rename(columns={'chromatin species': 'bead chromatin species'})\n",
    "        # x-jitter human oligo counts for visualization\n",
    "        .pipe(lambda df: df.assign(**{\n",
    "            'human oligo count': df['human oligo count'] + 0.2 * (df['bead chromatin species'] == 'human').astype(float) - 0.1\n",
    "        }))\n",
    "    ),\n",
    "    x='human oligo count',\n",
    "    y='mouse oligo count',\n",
    "    hue='bead chromatin species',\n",
    "    size='bead count',\n",
    "    sizes=(10, 50),\n",
    "    ax=axs[0]\n",
    ")\n",
    "axs[0].set_title('Oligo counts for single-chromatin-species CTCF beads')\n",
    "axs[0].xaxis.set_major_locator(matplotlib.ticker.MaxNLocator(integer=True))\n",
    "sns.move_legend(axs[0], \"upper left\", bbox_to_anchor=(1, 1))\n",
    "\n",
    "axs[1] = sns.scatterplot(\n",
    "    (\n",
    "        df_single_chromatin_species_target_beads\n",
    "        .loc[df_single_chromatin_species_target_beads['chromatin target'] == 'H3K4me3']\n",
    "        .pipe(lambda df: df.loc[(df['human oligo count'] + df['mouse oligo count']) > 0])\n",
    "        .groupby(['chromatin species', 'human oligo count', 'mouse oligo count'], observed=True)\n",
    "        .size()\n",
    "        .rename('bead count')\n",
    "        .reset_index()\n",
    "        .rename(columns={'chromatin species': 'bead chromatin species'})\n",
    "        # x-jitter human oligo counts for visualization\n",
    "        .pipe(lambda df: df.assign(**{\n",
    "            'human oligo count': df['human oligo count'] + 0.2 * (df['bead chromatin species'] == 'human').astype(float) - 0.1\n",
    "        }))\n",
    "    ),\n",
    "    x='human oligo count',\n",
    "    y='mouse oligo count',\n",
    "    hue='bead chromatin species',\n",
    "    size='bead count',\n",
    "    sizes=(10, 50),\n",
    "    ax=axs[1]\n",
    ")\n",
    "axs[1].set_title('Oligo counts for single-chromatin-species H3K4me3 beads')\n",
    "axs[1].xaxis.set_major_locator(matplotlib.ticker.MaxNLocator(integer=True))\n",
    "sns.move_legend(axs[1], \"upper left\", bbox_to_anchor=(1, 1))\n",
    "\n",
    "axs[1].set_xlim((-0.5, 10.5))\n",
    "axs[1].set_ylim((-0.5, 10.5))\n",
    "\n",
    "fig.savefig(\n",
    "    os.path.join(DIR_RESULTS, 'single-chromatin-species_single-target_beads_mixing-zoom.png'),\n",
    "    bbox_inches='tight',\n",
    "    dpi=300\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25225136-0822-437b-a5d0-06005043c84c",
   "metadata": {},
   "source": [
    "## Motif analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f77f1f-1b93-45b6-94a0-c194677a1d76",
   "metadata": {},
   "source": [
    "Considerations\n",
    "- Need to perform peak calling before motif analysis\n",
    "  - I have too many reads to directly perform motif analysis (XSTREME crashed)\n",
    "- Which aligned reads to perform peak calling on\n",
    "  - Reads aligning to highly conserved regions between mouse and human genomes (which may include conserved CTCF binding sites or promoter regions normally marked by H3K4me3) may have been filtered out by the pipeline. Consequently, motif analysis performed on reads filtered for with high mapping quality to the combined genome is likely very conservative.\n",
    "    - Consequently, to increase sensitivity (but at the expense of false positive alignment of reads), I could align all reads to each individual species genomes, and perform peak calling on those alignments.\n",
    "  - I ended up using the read pairs that aligned uniquely to the combined genome. HOMER's documentation, however, is unclear about the right or best way to provide paired-end alignments. I tried both of the following options, with similar (but not identical) results:\n",
    "    - Directly supply BAM file to `makeTagDirectory`\n",
    "    - Convert paired-end alignment BAM file to a BED file without strand information, and supply that to `makeTagDirectory`\n",
    "- Software tools\n",
    "  - Enrichment of known motifs: SEA (MEME suite), Homer\n",
    "  - Motif discovery: MEME and STREME (MEME suite), Homer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131fb662-0982-4601-8da1-4f5ce1c9e741",
   "metadata": {},
   "source": [
    "Main result\n",
    "- CTCF ChIP: very successful, regardless of the input format used for Homer peak calling\n",
    "  - Homer, known motifs: detected in >70% of called peaks across both species\n",
    "  - Homer, *de novo* motifs: the most similar known motif to the top de novo motif in each analysis was a known CTCF motif (not shown above; see Homer's output in the results directory)\n",
    "  - MEME, *de novo* motifs: the most similar known motif to the top de novo motif in each analysis was a known CTCF motif.\n",
    "- H3K4me3 ChIP\n",
    "  - Homer, known motifs: no significant enrichment\n",
    "  - Homer, *de novo* motifs: while a few significant motifs were found, they were not consistent between input formats, suggesting that they were not robust enrichments.\n",
    "  - MEME, *de novo* motifs: a few significant motifs found using both input formats; not sure if these are biologically meaningful for HEK293 and mESC cell types\n",
    "\n",
    "XSTREME's known motif enrichment analysis program SEA crashed (log: `Bad file name. FATAL: Template does not contain data section.`).\n",
    "- This appears to be an issue with bioconda's version of MEME. See [Google Groups](https://groups.google.com/g/meme-suite/c/AcbDls6e5VY/m/k4G7HJWQAAAJ), [GitHub bioconda issue](https://github.com/bioconda/bioconda-recipes/issues/22909), [Biostars](https://www.biostars.org/p/401084/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03a1ab8-8447-43c7-91f9-545ba7a7c853",
   "metadata": {},
   "source": [
    "### Peak calling metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71ee883-b655-4789-8d11-f1fa6342483b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_count_overlap_script = os.path.join(DIR_SCRIPTS, 'count_overlap_reads.sh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b08f2f8-c924-4268-9dca-7e42001215a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for target in TARGETS:\n",
    "    for species in SPECIES:\n",
    "        path_bed = os.path.join(DIR_PROC, f'{target}-PE_{species}_filtered_dedup_counts.bed.gz')\n",
    "        path_bam = os.path.join(DIR_PROC, f'{target}-PE_{species}_filtered_dedup.bam')\n",
    "        for input_format in ['BED', 'BAM']:\n",
    "            path_peaks = os.path.join(DIR_PROC, f'{target}_{species}_tagdir-{input_format}', 'peaks.bed')\n",
    "            if input_format == 'BED':\n",
    "                n_reads = 0 # read pairs\n",
    "                with gzip.open(path_bed, 'rt') as f:\n",
    "                    for line in f:\n",
    "                        if line.strip() != '':\n",
    "                            n_reads += 1\n",
    "            else:\n",
    "                n_reads = int(pysam.samtools.view(path_bam, \"-c\").strip()) / 2\n",
    "                assert n_reads % 1 == 0\n",
    "                n_reads = int(n_reads)\n",
    "            n_reads_in_peaks_any_overlap = !'{path_count_overlap_script}' '{path_peaks}' '{path_bed}'\n",
    "            n_reads_in_peaks_any_overlap = int(n_reads_in_peaks_any_overlap[0])\n",
    "            n_reads_in_peaks_complete_overlap = !'{path_count_overlap_script}' '{path_peaks}' '{path_bed}' -F 1\n",
    "            n_reads_in_peaks_complete_overlap = int(n_reads_in_peaks_complete_overlap[0])\n",
    "            n_reads_used = -1\n",
    "            n_reads_in_peaks = -1\n",
    "            n_peaks = -1\n",
    "            n_lines_peakfile = 0\n",
    "            with open(path_peaks, 'rt') as f:\n",
    "                for line in f:\n",
    "                    if line.startswith('# Total tags = '):\n",
    "                        n_reads_used = float(line.split(' = ')[1].strip())\n",
    "                    elif line.startswith('# Total tags in peaks = '):\n",
    "                        n_reads_in_peaks = float(line.split(' = ')[1].strip())\n",
    "                    elif line.startswith('# total peaks = '):\n",
    "                        n_peaks = float(line.split(' = ')[1].strip())\n",
    "                    elif (not line.strip() == '') and (not line.startswith('#')):\n",
    "                        n_lines_peakfile += 1\n",
    "            results.append({\n",
    "                'target': target,\n",
    "                'species': species,\n",
    "                'input_format': input_format,\n",
    "                'n_reads': n_reads,\n",
    "                'n_reads_used': n_reads_used,\n",
    "                'n_reads_in_peaks': n_reads_in_peaks,\n",
    "                'n_peaks': n_peaks,\n",
    "                'n_lines_peakfile': n_lines_peakfile,\n",
    "                'n_reads_in_peaks_any_overlap': n_reads_in_peaks_any_overlap,\n",
    "                'n_reads_in_peaks_complete_overlap': n_reads_in_peaks_complete_overlap\n",
    "            })\n",
    "df_peaks_results = pd.DataFrame(results)\n",
    "df_peaks_results['FRiP'] = df_peaks_results['n_reads_in_peaks'] / df_peaks_results['n_reads']\n",
    "df_peaks_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f0330d-2910-4a1c-be5f-84e00ef43616",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(\n",
    "    kind='bar',\n",
    "    data=df_peaks_results,\n",
    "    x='target',\n",
    "    y='n_peaks',\n",
    "    hue='input_format',\n",
    "    col='species',\n",
    "    errorbar=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2b00f1-40c8-4dc5-a325-c486dbcec241",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(\n",
    "    kind='bar',\n",
    "    data=df_peaks_results,\n",
    "    x='target',\n",
    "    y='FRiP',\n",
    "    hue='input_format',\n",
    "    col='species',\n",
    "    errorbar=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bc55d3-4bbf-42e5-a664-bd4a7069aa91",
   "metadata": {},
   "source": [
    "Interpretation\n",
    "- Number of peaks detected and FRiP values appear to depend more on sequencing depth (there are more uniquely aligned human reads than mouse reads) than on target.\n",
    "- Whether BAM or BED format is used as input to Homer does not seem to predict which one yields more detected peaks or FRiP scores.\n",
    "- I am not sure how Homer calculates its \"Total tags in peaks\" value, which is slightly smaller than the count of running `bedtools intersect` on the peak file and input file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be907289-70f7-47c7-b63f-b1ba14dd5c3f",
   "metadata": {},
   "source": [
    "### Most enriched motif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea3aaea-42af-40f0-9b36-9bbe24a0fb0f",
   "metadata": {},
   "source": [
    "#### Homer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c4ae23-537e-4775-a256-b504b93e930e",
   "metadata": {},
   "source": [
    "Get the top known motif found by Homer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b307ef-c75e-4815-9cb7-655d34c5c247",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_motif_homer = []\n",
    "for target in TARGETS:\n",
    "    for species in SPECIES:\n",
    "        for input_format in ['BED', 'BAM']:\n",
    "            path_known_motifs = os.path.join(DIR_RESULTS, f'{target}_{species}_homer-motifs-{input_format}', 'knownResults.txt')\n",
    "            result = (\n",
    "                pd.read_csv(path_known_motifs, sep='\\t', header=0)\n",
    "                .drop(columns=['Log P-value'])\n",
    "                .assign(target=target, species=species, input_format=input_format)\n",
    "                .iloc[0]\n",
    "            )\n",
    "            result['# of Target Sequences'] =  int(re.search(\n",
    "                'of (\\d+)\\)',\n",
    "                result.index[\n",
    "                    result.index.str.startswith('# of Target Sequences with Motif')\n",
    "                ].item()\n",
    "            ).groups()[0])\n",
    "            result['# of Background Sequences'] =  int(re.search(\n",
    "                'of (\\d+)\\)',\n",
    "                result.index[\n",
    "                    result.index.str.startswith('# of Background Sequences with Motif')\n",
    "                ].item()\n",
    "            ).groups()[0])\n",
    "            df_top_motif_homer.append(result.drop(index=result.index[result.index.str.contains('of \\d+\\)', regex=True)]))\n",
    "df_top_motif_homer = (\n",
    "    pd.concat(df_top_motif_homer, axis=1, ignore_index=True).T\n",
    "    .pipe(lambda df: df[['target', 'species', 'input_format'] + [x for x in df.columns if x not in ['target', 'species', 'input_format']]].copy())\n",
    ")\n",
    "df_top_motif_homer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f27c1c-be2d-4a82-bbad-258c4b5c6352",
   "metadata": {},
   "source": [
    "#### XSTREME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0126e5fc-3b8a-4c8c-9258-b8e1dd51620f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xstreme_all = []\n",
    "for target in TARGETS:\n",
    "    for species in SPECIES:\n",
    "        for input_format in ['BED', 'BAM']:\n",
    "            path_known_motifs = os.path.join(DIR_RESULTS, f'{target}_{species}-{input_format}_XSTREME', 'xstreme.tsv')\n",
    "            result = pd.read_csv(path_known_motifs, sep='\\t', header=0, comment='#').assign(target=target, species=species, input_format=input_format)\n",
    "            df_xstreme_all.append(result)\n",
    "df_xstreme_all = pd.concat(df_xstreme_all, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b698b87-8645-41f2-8bbe-d0ab7335ca8f",
   "metadata": {},
   "source": [
    "Motifs enriched regardless of input format (BED or BAM) used to for Homer peak calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6827d1ed-498f-4c90-91c9-e9146114368f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_colwidth', 1000):\n",
    "    display(\n",
    "        df_xstreme_all\n",
    "        .groupby(['target', 'species'], group_keys=True, observed=True)\n",
    "        [['input_format', 'SIM_MOTIF']]\n",
    "        .apply(lambda g: '; '.join(set(g.loc[g['input_format'] == 'BED', 'SIM_MOTIF']) & set(g.loc[g['input_format'] == 'BAM', 'SIM_MOTIF'])))\n",
    "        .rename('motifs found using both import formats')\n",
    "        .reset_index()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4810ef-d4b5-4633-a44f-3b1f337a10c4",
   "metadata": {},
   "source": [
    "Show the top *de novo* motifs found by XSTREME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6f4ea7-14f8-464a-a6c6-78eb8ed86c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df_xstreme_all\n",
    "    .groupby(['target', 'species', 'input_format'])\n",
    "    .first()\n",
    "    [['CONSENSUS', 'SITES', 'EVALUE', 'SIM_MOTIF']]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d71f3b-12ef-4bde-be83-77c91c1f26d0",
   "metadata": {},
   "source": [
    "## Annotation analysis\n",
    "\n",
    "Are the chromatin fragments enriched for known annotations (promoters, enhancers, other regulatory elements)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0ce68d-df09-4e1d-970f-b876a669487f",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Image(os.path.join(DIR_RESULTS, 'profile-scaled-gene human.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b205df33-bc2f-49d1-a164-94976943b6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Image(os.path.join(DIR_RESULTS, 'profile-scaled-gene mouse.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b047d1ba-7328-4c43-9caf-ddb376ac9739",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Image(os.path.join(DIR_RESULTS, 'profile-TSS human.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716311ea-c59e-426b-a69d-aa92e41e5bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Image(os.path.join(DIR_RESULTS, 'profile-TSS mouse.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6223ae8f-82f5-4d3d-85f6-0549491bdff3",
   "metadata": {},
   "source": [
    "[GREAT](http://great.stanford.edu) version 4.0.4 analysis of the H3K4me3 ChIP peak BED files (generated from BAM input) did not find any statistically significant enriched GO terms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6401c953-8e5c-434f-9c3b-284c3e75385e",
   "metadata": {},
   "source": [
    "# Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60451bc-f5a5-4df4-8cbc-0482a97335b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s {DIR_PROC} {DIR_AUX} {DIR_SCRIPTS}\n",
    "DIR_PROC=\"$1\"\n",
    "DIR_AUX=\"$2\"\n",
    "DIR_SCRIPTS=\"$3\"\n",
    "\n",
    "source ~/.bashrc\n",
    "conda activate snakemake\n",
    "\n",
    "snakemake \\\n",
    "    --snakefile \"${DIR_SCRIPTS}/Snakefile\" \\\n",
    "    --configfile \"${DIR_SCRIPTS}/config.yaml\" \\\n",
    "    --directory \"$DIR_PROC\" \\\n",
    "    -j 1 \\\n",
    "    clean"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
